from __future__ import print_function
import os
data_path = ['data']

import pandas as pd

# Import the data using the file path
# filepath = os.sep.join(data_path + ['Orange_Telecom_Churn_Data.csv'])
data = pd.read_csv('./data/Orange_Telecom_Churn_Data.csv')

data.head(1).T

# Remove extraneous columns
data.drop(['state', 'area_code', 'phone_number'], axis=1, inplace=True)

data.columns

from sklearn.preprocessing import LabelBinarizer

lb = LabelBinarizer()

for col in ['intl_plan', 'voice_mail_plan', 'churned']:
    data[col] = lb.fit_transform(data[col])

# Mute the sklearn warning
import warnings
warnings.filterwarnings('ignore', module='sklearn')

from sklearn.preprocessing import MinMaxScaler

msc = MinMaxScaler()

data = pd.DataFrame(msc.fit_transform(data),  # this is an np.array, not a dataframe.
                    columns=data.columns)

# Get a list of all the columns that don't contain the label
x_cols = [x for x in data.columns if x != 'churned']

# Split the data into two dataframes
X_data = data[x_cols]
y_data = data['churned']

# # alternatively:
# X_data = data.copy()
# y_data = X_data.pop('churned')

from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier(n_neighbors=3)

knn = knn.fit(X_data, y_data)

y_pred = knn.predict(X_data)

# Function to calculate the % of values that were correctly predicted

def accuracy(real, predict):
    return sum(y_data == y_pred) / float(real.shape[0])

print(accuracy(y_data, y_pred))

#Student writes code here

knn = KNeighborsClassifier(n_neighbors=3, weights='distance')

knn = knn.fit(X_data, y_data)

y_pred = knn.predict(X_data)

print(accuracy(y_data, y_pred))

#Student writes code here

list =[]
for k in range(1,20):
    knn = KNeighborsClassifier(n_neighbors=k,p=2)
    knn = knn.fit(X_data, y_data)
    y_pred = knn.predict(X_data)
    list.append(accuracy(y_data, y_pred))    

print(list)

import matplotlib.pyplot as plt
%matplotlib inline


plt.xlabel('k')
plt.ylabel('accuracy')
plt.plot(list)
