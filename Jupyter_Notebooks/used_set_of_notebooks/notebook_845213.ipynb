{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "278d5908",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook trains and evaluates a PyTorch CNN-model on the task of classifying images from the CIFAR10 dataset https://www.cs.toronto.edu/~kriz/cifar.html. I made it with the intent of learning PyTorch and it is based on the \"Training a Classifier\" tutorial from the PyTorch web site https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html. The source code can be found at https://github.com/CarlFredriksson/image_classification_using_pytorch.\n",
    "\n",
    "Let us start by importing some modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe6afdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669024b2",
   "metadata": {},
   "source": [
    "# Prepare Data\n",
    "\n",
    "The output of torchvision datasets are PILImage images with pixel values in the range [0,1]. We need to transform the images to PyTorch tensors and normalize their pixel values to be in the range [-1,1]. The transform `RandomHorizontalFlip` is a form of data augmentation that increases the size of training set by randomly flipping images horizontally with a given probability (0.5 by default) every time they are loaded. Increasing the size of the training set generally helps reduce overfitting and adding the `RandomHorizontalFlip` increased the final test accuracy. However, I tried a couple of the other data augmentation transforms and did not see an improvement in performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e631fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "# Prepare test data\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=128, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "print('Number of training examples:', len(train_set))\n",
    "print('Number of test examples:', len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28de32ff",
   "metadata": {},
   "source": [
    "# Display Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52680fdd",
   "metadata": {},
   "source": [
    "Let us display some images from the training set to see what we are working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b70a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5 # Un-normalize\n",
    "    np_img = img.numpy()\n",
    "    plt.imshow(np.transpose(np_img, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f063b924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some random training images\n",
    "NUM_IMAGES_TO_SHOW = 5\n",
    "data_iter = iter(train_loader)\n",
    "images, labels = data_iter.next()\n",
    "imshow(torchvision.utils.make_grid(images[:NUM_IMAGES_TO_SHOW]))\n",
    "print('Labels:', ' '.join(f'{classes[labels[i]]}' for i in range(NUM_IMAGES_TO_SHOW)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda015b7",
   "metadata": {},
   "source": [
    "# Create Model\n",
    "\n",
    "I tried several simple CNN-models and ended up with the one below. It does not achieve state of the art performance by any means but it is decent. The model uses the common pattern of convolutional layers (+ ReLU activation function) that increase the number of channels but does not change the dimensions (height and width) followed by max pooling layers for dimensionality reduction (downsampling). A famous architecture that use this pattern is VGG16, introduced in (Simonyan, Zisserman, 2014, https://arxiv.org/abs/1409.1556). However, VGG16 is much deeper and has multiple convolutional layers per pooling layer. At the time of writing this notebook there is no option to specify `padding='SAME'` as in TensorFlow, which means that we have to do the padding calculations ourselves. Let $H_{in}, W_{in}$ be the height and width of the input and $H_{out}, W_{out}$ be the height and width of the output. Then\n",
    "\n",
    "$$\n",
    "H_{out} = \\frac{H_{in} + 2 \\times \\text{padding}[0] - \\text{dilation}[0] \\times (\\text{kernel_size}[0] - 1) - 1}{\\text{stride}[0]} + 1 \\\\\n",
    "W_{out} = \\frac{W_{in} + 2 \\times \\text{padding}[1] - \\text{dilation}[1] \\times (\\text{kernel_size}[1] - 1) - 1}{\\text{stride}[1]} + 1\n",
    "$$\n",
    "\n",
    "When `padding[0] = padding[1]`, `kernel_size[0] = kernel_size[1]`, `dilation[0] = dilation[1] = 1` (default), and `stride[0] = stride[1] = 1` (default), the equations can be reduced to\n",
    "\n",
    "$$\n",
    "H_{out} = H_{in} + 2 \\times \\text{padding} - \\text{kernel_size} + 1 \\\\\n",
    "W_{out} = W_{in} + 2 \\times \\text{padding} - \\text{kernel_size} + 1\n",
    "$$\n",
    "\n",
    "A dropout layer is added between the first and second fully connected layers to reduce overfitting. Note that there is no need to add a soft-max layer after the last fully connected layer, since it is added automatically by `torch.nn.CrossEntropyLoss()` during training and it is not needed during inference because argmax does not get affected by applying soft-max.  If cuda is available, the network is moved to the gpu by `net.to(device)`. This can radically reduce training time, depending on what gpu you have available. I trained the model for 100 epochs using a batch size of 128 on both an \"Intel Core i7-4790S\" cpu and an \"NVIDIA GeForce RTX 2070 SUPER\" gpu. Training on the cpu takes about 2.5 hours and training on the gpu takes about 20 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e3e1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 5, padding=2)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 5, padding=2)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x size: N x 3 x 32 x 32\n",
    "        x = F.relu(self.conv1(x))  # N x 16 x 32 x 32\n",
    "        x = self.pool(x) # N x 16 x 16 x 16\n",
    "        x = F.relu(self.conv2(x)) # N x 32 x 16 x 16\n",
    "        x = self.pool(x) # N x 32 x 8 x 8\n",
    "        x = F.relu(self.conv3(x)) # N x 64 x 8 x 8\n",
    "        x = self.pool(x) # N x 64 x 4 x 4\n",
    "        x = x.view(-1, 64 * 4 * 4) # N x 1024\n",
    "        x = F.relu(self.fc1(x)) # N x 128\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x)) # N x 64\n",
    "        x = self.fc3(x) # N x 10\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d5b213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "net = Net()\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "net.to(device)\n",
    "print('Device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a3d524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad456e1",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af7e743",
   "metadata": {},
   "source": [
    "Now it is time to train the model. One thing to note is that we need to move the input and labels to the same device the neural network is running on by using `to(device)`. Another thing to remember is to zero the gradients each iteration by calling `optimizer.zero_grad()`. This is necessary because `loss.backward()` accumulates gradients (sums them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f9ec49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_test_accuracy():\n",
    "    num_total = len(test_set)\n",
    "    num_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = net(images)\n",
    "            predictions = torch.argmax(outputs.data, 1)\n",
    "            num_correct += (predictions == labels).sum().item()\n",
    "    return num_correct / num_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510e7cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of iterations per epoch:', len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6676f097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "NUM_EPOCHS = 100\n",
    "loss_per_epoch = np.zeros(NUM_EPOCHS)\n",
    "accuracy_per_epoch = np.zeros(NUM_EPOCHS)\n",
    "test_accuracy_per_epoch = np.zeros(NUM_EPOCHS)\n",
    "print('Starting training')\n",
    "start_time = time.perf_counter()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        predictions = torch.argmax(outputs.data, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_per_epoch[epoch] += loss.item() / len(train_loader)\n",
    "        accuracy_per_epoch[epoch] += (predictions == labels).sum().item() / len(train_set)\n",
    "    # Compute test accuracy\n",
    "    net.train(False)\n",
    "    test_accuracy_per_epoch[epoch] = compute_test_accuracy()\n",
    "    net.train(True)\n",
    "\n",
    "    # Print statistics\n",
    "    print('Epoch [{}/{}] loss: {:.5f} accuracy: {:.2f}% test accuracy: {:.2f}%'.format(\n",
    "        epoch, NUM_EPOCHS - 1, loss_per_epoch[epoch],\n",
    "        100 * accuracy_per_epoch[epoch],\n",
    "        100 * test_accuracy_per_epoch[epoch]))\n",
    "elapsed_time = time.perf_counter() - start_time\n",
    "print(f'Finished training - elapsed_time: {elapsed_time:.0f} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8433c027",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "ax[0].plot(np.arange(NUM_EPOCHS), loss_per_epoch)\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[0].set_ylabel('Cross entropy loss')\n",
    "ax[1].plot(np.arange(NUM_EPOCHS), 100 * accuracy_per_epoch, label='Training accuracy')\n",
    "ax[1].plot(np.arange(NUM_EPOCHS), 100 * test_accuracy_per_epoch, label='Test accuracy')\n",
    "ax[1].set_xlabel('Epoch')\n",
    "ax[1].set_ylabel('Accuracy %')\n",
    "ax[1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26d1ebb",
   "metadata": {},
   "source": [
    "# Save and Load Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b839a1e4",
   "metadata": {},
   "source": [
    "You obviously do not need to load the saved model if you run the whole notebook, but I included the cell for future reference and to be able to test a saved model without having to train a new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28da55c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "save_path = './nn_cifar10.pth'\n",
    "torch.save(net.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa57595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved model\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load(save_path))\n",
    "net.to(device)\n",
    "print(net.training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e16754",
   "metadata": {},
   "source": [
    "# Test Model\n",
    "\n",
    "Let us test the model on a few images, compute the test accuracy, and compute the test accuracy per class. We need to make sure that the model is in evaluation mode to disable the dropout layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41715682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that the model is in eval mode\n",
    "net.eval()\n",
    "print(net.training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906747c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some test images\n",
    "data_iter = iter(test_loader)\n",
    "images, labels = data_iter.next()\n",
    "imshow(torchvision.utils.make_grid(images[:NUM_IMAGES_TO_SHOW]))\n",
    "print('Labels:', ' '.join(f'{classes[labels[i]]}' for i in range(NUM_IMAGES_TO_SHOW)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fd0530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict classes for the random test images\n",
    "outputs = net(images.to(device))\n",
    "predictions = torch.argmax(outputs, 1)\n",
    "print('predictions:', ' '.join(f'{classes[predictions[i]]}' for i in range(NUM_IMAGES_TO_SHOW)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d064bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of the model on the {} test images: {}%'.format(\n",
    "    len(test_set), 100 * compute_test_accuracy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606c97c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the accuracy per class\n",
    "class_correct = np.zeros(len(classes))\n",
    "class_total = np.zeros(len(classes))\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = net(images)\n",
    "        predictions = torch.argmax(outputs, 1)\n",
    "        predictions_correct = (predictions == labels).squeeze()\n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += predictions_correct[i].item()\n",
    "            class_total[label] += 1\n",
    "for i in range(len(classes)):\n",
    "    print('Accuracy of {}: [{:.0f}/{:.0f}] {:.1f}%'.format(\n",
    "        classes[i], class_correct[i], class_total[i], 100 * class_correct[i] / class_total[i]))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
