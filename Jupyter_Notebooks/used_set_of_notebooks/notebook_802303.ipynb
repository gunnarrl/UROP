{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2301452f",
   "metadata": {},
   "source": [
    "# Find Lane Markings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f12c17",
   "metadata": {},
   "source": [
    "### Define a class to receive the characteristics of each line detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f20cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define a class to receive the characteristics of each line detection\n",
    "class Line():\n",
    "    def __init__(self,image_shape):\n",
    "        self.maxx = image_shape[0]\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        # x values of the last n fits of the line\n",
    "        #self.recent_xfitted = [] \n",
    "        #self.recent_yfitted = []\n",
    "        self.recent_fits = []\n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        #self.bestx = None     \n",
    "        #self.besty = None\n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None\n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = [np.array([False])]  \n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "        self.radius_of_curvature_array = []\n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "        self.line_base_pos_array = []\n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float') \n",
    "        #x values for detected line pixels\n",
    "        self.allx = None  \n",
    "        #y values for detected line pixels\n",
    "        self.ally = None\n",
    "        \n",
    "    #getters and setters\n",
    "        \n",
    "    def set_line(self, pointsx, pointsy):\n",
    "        assert (type(pointsy) is np.ndarray) and (type(pointsx) == np.ndarray)\n",
    "        assert pointsy.size > 0\n",
    " \n",
    "        self.allx = pointsx\n",
    "        self.ally = pointsy\n",
    "        \n",
    "        if self.allx.size > 0:\n",
    "            self.detected=True\n",
    "            self.current_fit = np.polyfit(self.ally, self.allx, 2)\n",
    "            self.radius_of_curvature_array.append(self.__calculate_curvature())\n",
    "            if len(self.radius_of_curvature_array) >=15:\n",
    "                self.radius_of_curvature = np.mean(self.radius_of_curvature_array)\n",
    "                self.radius_of_curvature_array.pop(0)\n",
    "            self.line_base_pos_array.append(self.__calculate_dist())\n",
    "            if len(self.line_base_pos_array) >= 15:\n",
    "                self.line_base_pos= np.mean(self.line_base_pos_array)\n",
    "                self.line_base_pos_array.pop(0)\n",
    "            \n",
    "            if self.best_fit is None :\n",
    "                self.best_fit = self.current_fit\n",
    "        else:\n",
    "            self.detected=False\n",
    "            self.current_fit = [np.array([False])]\n",
    "            self.radius_of_curvature = None   \n",
    "            self.line_base_pos = None\n",
    "            self.best_fit = None\n",
    "    \n",
    "    def get_curvature(self):\n",
    "        return self.radius_of_curvature\n",
    "    \n",
    "    def get_distance(self):\n",
    "        return self.line_base_pos\n",
    "            \n",
    "    def get_fit(self):\n",
    "        return self.best_fit\n",
    "        #return self.current_fit\n",
    "    \n",
    "    #predicate methods\n",
    "    def is_detected(self):\n",
    "        return self.detected\n",
    "    \n",
    "    #other public methods\n",
    "    \n",
    "    def is_similar_to(self, other_line, curv_thresh = 500, dist_offset =0.5):\n",
    "        if self.get_curvature() is not None and other_line.get_curvature() is not None:\n",
    "            similar_curvatures = np.abs(self.get_curvature() - other_line.get_curvature()) <= curv_thresh\n",
    "            similar_distances = np.abs(self.get_distance()) - np.abs(other_line.get_distance()) <= dist_offset\n",
    "            return similar_curvatures and similar_distances\n",
    "        else : return False\n",
    "    \n",
    "    #appends x values to x values list, refreshes the moving average of the polynomial coefficients\n",
    "    def update_average(self):\n",
    "        #append y values\n",
    "        self.recent_fits.append(self.current_fit)\n",
    "        if len(self.recent_fits) > 15:\n",
    "            remove = self.recent_fits.pop(0)\n",
    "        if len(self.recent_fits)>1:\n",
    "            self.best_fit = np.mean(self.recent_fits,axis=0)\n",
    "        else: \n",
    "            self.best_fit = self.current_fit\n",
    "    \n",
    "    #private methods\n",
    "    \n",
    "    def __calculate_curvature(self):\n",
    "        ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "        xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "        fit = np.polyfit(self.ally*ym_per_pix, self.allx*xm_per_pix, 2)\n",
    "        y_eval = np.max(self.ally)\n",
    "        curvature_radius = ((1 + (2*fit[0]*y_eval*ym_per_pix + fit[1])**2)**1.5) / np.absolute(2*fit[0])\n",
    "        return curvature_radius\n",
    "    \n",
    "    def __calculate_dist(self):\n",
    "        xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "        midpoint = xm_per_pix*self.maxx/2  #midpoint assuming camera is centered\n",
    "        \n",
    "        #get the x value for the lowest y in the image (the one with the highest y value)\n",
    "        sort_indices= self.ally.argsort()\n",
    "        x=self.allx[sort_indices]\n",
    "        return xm_per_pix*x[-1] - midpoint\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e038dd4d",
   "metadata": {},
   "source": [
    "### Function that corrects distorsion\n",
    "returns: undistorted image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a30b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "#correct distorsion\n",
    "\n",
    "def calibrate(calibration_images_path='camera_cal/cal*.jpg'):\n",
    "    # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    objp = np.zeros((6*9,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:9, 0:6].T.reshape(-1,2)\n",
    "\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = [] # 3d points in real world space\n",
    "    imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "    # Make a list of calibration images\n",
    "    images = glob.glob(calibration_images_path)\n",
    "\n",
    "    # Step through the list and search for chessboard corners\n",
    "    for idx, fname in enumerate(images):\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (9,6), None)\n",
    "\n",
    "        # If found, add object points, image points\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    # Do camera calibration given object points and image points\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size,None,None)\n",
    "    return ret, mtx, dist\n",
    "\n",
    "def undistort(img,mtx,dist):\n",
    "    dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55de2a9a",
   "metadata": {},
   "source": [
    "### Function that applies a series of thresholds to an image to detect what seems to be lane markings\n",
    "returns: a filtered binary image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69940b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply thresholds\n",
    "\n",
    "#apply a simple HSV threshold, leveraging H layer. \n",
    "def hls_thresh(image):\n",
    "    hls = cv2.cvtColor(image, cv2.COLOR_BGR2HLS)\n",
    "\n",
    "    thresh = {'L': (180,255),\n",
    "              'S': (180,255)}  \n",
    "    \n",
    "    S = hls[:,:,2]\n",
    "    L = hls[:,:,1]\n",
    "\n",
    "    binary_S = np.zeros_like(S)\n",
    "    binary_S[(S > thresh['S'][0]) & (S <= thresh['S'][1])] = 1\n",
    "    \n",
    "    binary_L = np.zeros_like(L)\n",
    "    binary_L[(L > thresh['L'][0]) & (L <= thresh['L'][1])] = 1\n",
    "    \n",
    "    combined_hls = np.zeros_like(S)\n",
    "    combined_hls[(binary_S == 1) | (binary_L == 1)] = 1 \n",
    "    \n",
    "    return combined_hls\n",
    "\n",
    "def abs_sobel_thresh(img, orient='x', thresh= [0,255], sobel_kernel=3):\n",
    "    \n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    gray= cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # 2) Take the derivative in x or y given orient = 'x' or 'y'\n",
    "    if orient == 'x' : \n",
    "        gradient = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    elif orient == 'y' :\n",
    "        gradient= cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    else: \n",
    "        raise ValueError('orient must be either x or y')\n",
    "        \n",
    "    # 3) Take the absolute value of the derivative or gradient\n",
    "    img= np.absolute(gradient)\n",
    "    \n",
    "    # 4) Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "    img = np.uint(255*img/np.max(img))\n",
    "    \n",
    "    # 5) Create a mask of 1's where the scaled gradient magnitude \n",
    "    grad_binary= np.zeros_like(img)\n",
    "    grad_binary[(img >=  thresh[0]) & (img <= thresh[1])] = 1\n",
    "    \n",
    "            # is > thresh_min and < thresh_max\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    return grad_binary\n",
    "\n",
    "#returns: a binary image with emphasis on lane lines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026aa926",
   "metadata": {},
   "source": [
    "### Function that takes a perspective binary image and returns a birdseye version\n",
    "returns: birdseye view of lane markings (binary) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30b1e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply perspective transform\n",
    "\n",
    "def warper(img, src, dst):\n",
    "\n",
    "    # Compute and apply perpective transform\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    warped = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_NEAREST)  # keep same size as input image\n",
    "\n",
    "    return warped,M,Minv\n",
    "#returns: a birds eye version of the binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38850ed",
   "metadata": {},
   "source": [
    "### Takes a birdseye view and finds lane patterns using sample window search, returns a list of right and left points to be used for polynomial fit\n",
    "returns: x and y points for left and right lane markings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a37ea1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#when the image is new or when the markings have been lost from previous frame, apply sample window search to fit a polynomial \n",
    "#returns an image with lane markings drawn on original image\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "\n",
    "\n",
    "def find_points_using_windows(binary_warped, nwindows = 9, margin = 100, minpix = 50):\n",
    "\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "    # Create an output image to draw on and  visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "    \n",
    "    # Set height of windows\n",
    "    window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    \n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),\n",
    "        (0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),\n",
    "        (0,255,0), 2) \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "    return leftx,lefty,rightx,righty\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d3aa16",
   "metadata": {},
   "source": [
    "### Function that uses existing polynomial to find lane markings in a region around polynomial\n",
    "returns a new polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a04249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# refresh polynomial\n",
    "# returns polynomial\n",
    "\n",
    "def refresh_polynomials(left_fit, right_fit, binary_warped):\n",
    "\n",
    "    # Assume you now have a new warped binary image \n",
    "    # from the next frame of video (also called \"binary_warped\")\n",
    "    # It's now much easier to find line pixels!\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    margin = 100\n",
    "    left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + \n",
    "    left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + \n",
    "    left_fit[1]*nonzeroy + left_fit[2] + margin))) \n",
    "\n",
    "    right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + \n",
    "    right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + \n",
    "    right_fit[1]*nonzeroy + right_fit[2] + margin)))  \n",
    "\n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    \n",
    "    return leftx,lefty,rightx,righty\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d348d2a2",
   "metadata": {},
   "source": [
    "## Pipeline applying transformations to image frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53edefc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in a thresholded image for now...\n",
    "warped = mpimg.imread('warped_example.jpg')\n",
    "plt.figure()\n",
    "plt.imshow(warped,cmap='gray')\n",
    "\n",
    "right_L = Line(warped.shape)\n",
    "left_L = Line(warped.shape)\n",
    "\n",
    "def get_lane_lines(warped,left_line,right_line,nwindows = 9, margin = 100, minpix = 50):\n",
    "    # window settings\n",
    "    #window_width = 50 \n",
    "    #window_height = 80 # Break image into 9 vertical layers since image height is 720\n",
    "    #margin = 100 # How much to slide left and right for searching\n",
    "\n",
    "    #find lane markings and fit polynomial \n",
    "    #if no existing or valid polynomial : use window slide\n",
    "    if not right_line.is_detected() or not left_line.is_detected(): \n",
    "        # Fit a second order polynomial to each\n",
    "        leftx,lefty,rightx,righty= find_points_using_windows(warped,nwindows, margin, minpix=50)  \n",
    "\n",
    "    else : \n",
    "        left_fit = left_line.get_fit()\n",
    "        right_fit = right_line.get_fit()\n",
    "\n",
    "        leftx,lefty,rightx,righty= refresh_polynomials(left_fit,right_fit,warped)\n",
    "        if leftx.size ==0 or rightx.size == 0:\n",
    "            leftx,lefty,rightx,righty=find_points_using_windows(warped,nwindows, margin, minpix=50)\n",
    "            \n",
    "    left_line.set_line(leftx,lefty)\n",
    "    right_line.set_line(rightx,righty)\n",
    "\n",
    "    left_fit = left_line.get_fit()\n",
    "    right_fit = right_line.get_fit()\n",
    "  \n",
    "    return left_line, right_line\n",
    "\n",
    "left_line,right_line=get_lane_lines(warped,left_L,right_L)\n",
    "\n",
    "#get data for plot\n",
    "ploty = left_line.ally\n",
    "left_fit = left_line.get_fit()\n",
    "left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "right_fit = right_line.get_fit()\n",
    "right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "# Plot up the data\n",
    "plt.plot(left_fitx, ploty, color='green', linewidth=3)\n",
    "plt.plot(right_fitx, ploty, color='green', linewidth=3)\n",
    "plt.xlim(0, 1280)\n",
    "plt.ylim(0, 720)\n",
    "plt.gca().invert_yaxis() # to visualize as we do the images\n",
    "\n",
    "#print('left line dist: ',left_line.get_distance(),'\\nright line dist: ',right_line.get_distance())\n",
    "#print('is similar: ',right_line.is_similar_to(left_line))\n",
    "#calculate radius of curvature\n",
    "\n",
    "#return radius of curvature\n",
    "\n",
    "#unapply perspective transform and visual representation of result and append curvature results to image\n",
    "#returns an image with lane markings drawn on original image\n",
    "\n",
    "#display frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c316efea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test for mentoring purposes\n",
    "plt.imshow(warped, cmap='gray')\n",
    "leftx,lefty,rightx,righty= find_points_using_windows(warped,9, 100, minpix=50)\n",
    "nonzero = warped.nonzero()\n",
    "nonzeroy = np.array(nonzero[0])\n",
    "nonzerox = np.array(nonzero[1])\n",
    "margin = 100\n",
    "print(warped.shape)\n",
    "left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + \n",
    "left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + \n",
    "left_fit[1]*nonzeroy + left_fit[2] + margin))) \n",
    "\n",
    "right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + \n",
    "right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + \n",
    "right_fit[1]*nonzeroy + right_fit[2] + margin)))\n",
    "\n",
    "px=  (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2])\n",
    "plt.plot(px,nonzeroy, color='red', linewidth = 4)\n",
    "plt.plot(px+100,nonzeroy, color='yellow', linewidth = 4)\n",
    "plt.plot(px-100,nonzeroy, color='yellow', linewidth = 4)\n",
    "plt.scatter([nonzerox],[nonzeroy],color='green', linewidth = .1)\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "#select pixels within the yellow lines\n",
    "#fit a new polynomial to these pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fde1689",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find calibration matrix\n",
    "ret, mtx, dist = calibrate(calibration_images_path='camera_cal/cal*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafe8987",
   "metadata": {},
   "outputs": [],
   "source": [
    "### test all functions\n",
    "\n",
    "#get a random frame from the video to test : \n",
    "cap = cv2.VideoCapture('./project_video.mp4')\n",
    "width= cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "length = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "try:\n",
    "    assert length > 0 \n",
    "except AssertionError as e :\n",
    "    raise ValueError('the length of the video file appears to be zero')\n",
    "\n",
    "#pick and display a random frame\n",
    "#fr = np.random.randint(length)\n",
    "fr =200\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES,fr)\n",
    "ret, frame= cap.read()\n",
    "if ret:\n",
    "    plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('original image')\n",
    "    plt.axis('off')\n",
    "cap.release()\n",
    "\n",
    "def image_pipeline(frame,left_marker,right_marker, debug=False):\n",
    "    #apply pipeline to random frame, print every step\n",
    "    #1. undistort \n",
    "   \n",
    "    frame=  undistort(frame,mtx,dist)\n",
    "    \n",
    "    #display original image\n",
    "    if debug: \n",
    "        plt.figure()\n",
    "        plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis('off')\n",
    "        plt.imsave('undistorted.png',cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        plt.title('undistorted image')\n",
    "\n",
    "    #threshold\n",
    "    binary_hls=  hls_thresh(frame)     #apply filter based on HLS color space\n",
    "    binary_dir_thresh = abs_sobel_thresh(frame, thresh=[20,100], sobel_kernel=15)  #apply directional threshold\n",
    "    binary_image = np.zeros_like(binary_hls)  #merge two previous filters\n",
    "    binary_image[(binary_hls == 1) | (binary_dir_thresh == 1)] = 1 \n",
    "    binary_image=  binary_image * 255\n",
    "    \n",
    "    #display thresholded image\n",
    "    if debug: \n",
    "        plt.figure()\n",
    "        plt.imshow(binary_image,cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.title('thresholded binary image')\n",
    "        \n",
    "    #perspective transform\n",
    "    img_size = binary_image.shape[::-1]\n",
    "    src= np.float32([[600,450],[700,450],[200,img_size[1]],[1200,img_size[1]]])\n",
    "    \n",
    "    dx = img_size[0] / 5\n",
    "    dy=5\n",
    "    dst = np.float32([[0+dx,0+dy],\n",
    "        [img_size[0]-dx,0+dy],\n",
    "        [0+dx,img_size[1]-dy],\n",
    "        [img_size[0]-dx,img_size[1]-dy]])\n",
    "    \n",
    "    warped_binary,M,Minv= warper(binary_image, src, dst)\n",
    "    print(src,dst)\n",
    "    #display warped image with source and destination lines overlaid\n",
    "    if debug:\n",
    "        black=np.dstack((binary_image,binary_image,binary_image))\n",
    "        pts = src.reshape((-1,1,2))\n",
    "        cv2.polylines(black,[pts.astype(np.int32)[np.array([0,1,3,2])]],True,(0,255,255),5)\n",
    "        pts = dst.reshape((-1,1,2))\n",
    "        cv2.polylines(black,[pts.astype(np.int32)[np.array([0,1,3,2])]],True,(255,0,0),5)\n",
    "    \n",
    "        plt.figure()\n",
    "        plt.imshow(black)\n",
    "        plt.title('source and destination')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(warped_binary,cmap='gray')\n",
    "        plt.title('warped result')\n",
    "\n",
    "    #curvature calculation\n",
    "    \n",
    "    ## This is where the lane marking object get updated\n",
    "    left_line,right_line=get_lane_lines(warped_binary,left_marker,right_marker)\n",
    "    #run sanity checks \n",
    "    if left_marker.is_similar_to(right_marker): \n",
    "        #print(\"marker was updated\")\n",
    "        left_marker.update_average()\n",
    "        right_marker.update_average()\n",
    "    \n",
    "    \n",
    "    \n",
    "    #plot lines on warped binary\n",
    "    \n",
    "    ploty = left_line.ally\n",
    "    left_fit = left_line.get_fit()\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fit = right_line.get_fit()\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "        \n",
    "    if debug:\n",
    "        plt.plot(left_fitx, ploty, color='green', linewidth=3)\n",
    "        plt.plot(right_fitx, ploty, color='green', linewidth=3)\n",
    "        plt.xlim(0, 1280)\n",
    "        plt.ylim(0, 720)\n",
    "        plt.gca().invert_yaxis() # to visualize as we do the images\n",
    "\n",
    "    #unwrap and draw green zone on original frame\n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(warped_binary).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (frame.shape[1], frame.shape[0])) \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(frame, 1, newwarp, 0.3, 0)\n",
    "    \n",
    "    if debug:\n",
    "        plt.figure()\n",
    "        plt.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis('off')\n",
    "        plt.title('unwarped result')\n",
    "    \n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    \n",
    "    if right_marker.get_curvature() is not None:\n",
    "        cv2.putText(result,'Curvature: '+format(right_marker.get_curvature(),'2.0f')+'m',(10,100), font, 2,(255,255,255),2,cv2.LINE_AA)\n",
    "    if left_marker.get_distance() is not None and right_marker.get_distance() is not None:\n",
    "        cv2.putText(result,'Distance L: '+format(left_marker.get_distance(),'2.2f')+'m R:'+format(right_marker.get_distance(),'2.2f')+'m',(10,200), font, 2,(255,255,255),2,cv2.LINE_AA)\n",
    "    return result\n",
    "    \n",
    "#rl = Line(frame.shape[0:2][::-1])\n",
    "#ll = Line(frame.shape[0:2][::-1])\n",
    "img = image_pipeline(frame,ll,rl,debug=True)\n",
    "plt.figure()\n",
    "plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5638b35",
   "metadata": {},
   "source": [
    "### Process video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50251586",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rl.recent_fits)\n",
    "print(len(ll.recent_fits))\n",
    "print(rl.best_fit)\n",
    "print(rl.current_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae21d3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "#todo : it is not convenient not to be able to pass arguments to the function that processes the frame... find another way to edit video ???\n",
    "rl = Line(frame.shape[0:2][::-1])\n",
    "ll = Line(frame.shape[0:2][::-1])\n",
    "def process_image(frame):\n",
    "    return image_pipeline(frame,ll,rl,debug=False)\n",
    "    \n",
    "video_output = 'video_output.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "#clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(6,8)\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "#clip1 = VideoFileClip(\"challenge_video.mp4\")\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(video_output, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fa754d",
   "metadata": {},
   "source": [
    "### Display video inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388c2136",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "#play result\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
