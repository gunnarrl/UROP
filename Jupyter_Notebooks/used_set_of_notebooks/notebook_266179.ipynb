{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de4f056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import plistlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f09ad49",
   "metadata": {},
   "source": [
    "# Ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af61fd43",
   "metadata": {},
   "source": [
    "Read ground truth annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bcba15",
   "metadata": {},
   "outputs": [],
   "source": [
    "trues = pd.read_csv(\"./AnnotationExample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46ad2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "trues.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92380d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "trues[\"x1_true\"] = trues[\"x_1\"]\n",
    "trues[\"y1_true\"] = trues[\"y_1\"]\n",
    "trues[\"x2_true\"] = trues[\"x_1\"] + trues[\"width\"]\n",
    "trues[\"y2_true\"] = trues[\"y_1\"] + trues[\"height\"]\n",
    "trues = trues[[\"image_id\", \"x1_true\", \"x2_true\", \"y1_true\", \"y2_true\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44c50e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trues.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c197ccc1",
   "metadata": {},
   "source": [
    "All the images have exactly one face annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78abec6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trues.groupby(\"image_id\").count()[\"x1_true\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6936e85e",
   "metadata": {},
   "source": [
    "# CoreML predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dab235",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./PredictionExample.plist\", \"rb\") as f:\n",
    "    preds_coreml = pd.DataFrame(plistlib.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c2f588",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_coreml.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d05304",
   "metadata": {},
   "source": [
    "Percentage of cases where exactly one face was predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f632f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "(preds_coreml[\"confidences\"].apply(len) == 1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50326b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_coreml[\"file\"] = preds_coreml[\"file\"].str[7:]\n",
    "preds_coreml[\"image_id\"] = preds_coreml[\"file\"].str.split(\"/\").str[-1]\n",
    "preds_coreml[\"x1_coreml\"] = preds_coreml[\"bboxes\"].str[0].str[0]\n",
    "preds_coreml[\"x2_coreml\"] = preds_coreml[\"bboxes\"].str[0].str[1]\n",
    "preds_coreml[\"y1_coreml\"] = 1 - preds_coreml[\"bboxes\"].str[0].str[3]\n",
    "preds_coreml[\"y2_coreml\"] = 1 - preds_coreml[\"bboxes\"].str[0].str[2]\n",
    "preds_coreml[\"image_id\"] = preds_coreml[\"file\"].str.split(\"/\").str[-1]\n",
    "preds_coreml = preds_coreml[[\"image_id\", \"x1_coreml\", \"x2_coreml\", \"y1_coreml\", \"y2_coreml\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239bb3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_coreml.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcefde22",
   "metadata": {},
   "source": [
    "# Merge predictions and GT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880a4df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(preds_coreml, trues, on=\"image_id\", how=\"inner\", suffixes=(\"_coreml\", \"_true\"))\n",
    "merged = merged.sort_values(\"image_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3498d1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f86c632",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6e6839",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/Users/vovacher/Downloads/CelebA/images/img_celeba.7z/img_celeba/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e649ec66",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f877b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(os.path.join(base_path, merged.iloc[i][\"image_id\"]))\n",
    "draw = ImageDraw.Draw(img)\n",
    "draw.rectangle(((merged.iloc[i][\"x1_true\"], merged.iloc[i][\"y1_true\"]), \n",
    "                (merged.iloc[i][\"x2_true\"], merged.iloc[i][\"y2_true\"])), \n",
    "               outline=\"green\", width=3)\n",
    "draw.rectangle(((merged.iloc[i][\"x1_coreml\"] * img.size[0], merged.iloc[i][\"y1_coreml\"] * img.size[1]),\n",
    "                (merged.iloc[i][\"x2_coreml\"] * img.size[0], merged.iloc[i][\"y2_coreml\"] * img.size[1])),\n",
    "               outline=\"red\", width=3)\n",
    "print(\"Green = GT\\nRed   = CoreML\")\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b165be45",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a983cdf",
   "metadata": {},
   "source": [
    "\"Intersection over Union\" metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998ed5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iou(boxes1, boxes2):\n",
    "\n",
    "    x11, y11, x12, y12 = np.split(boxes1, 4, axis=1)\n",
    "    x21, y21, x22, y22 = np.split(boxes2, 4, axis=1)\n",
    "\n",
    "    xa = np.maximum(x11, np.transpose(x21))\n",
    "    ya = np.maximum(y11, np.transpose(y21))\n",
    "    xb = np.minimum(x12, np.transpose(x22))\n",
    "    yb = np.minimum(y12, np.transpose(y22))\n",
    "\n",
    "    inter_area = np.maximum((xb - xa + 1), 0) * np.maximum((yb - ya + 1), 0)\n",
    "\n",
    "    box_a_area = (x12 - x11 + 1) * (y12 - y11 + 1)\n",
    "    box_b_area = (x22 - x21 + 1) * (y22 - y21 + 1)\n",
    "\n",
    "    iou = inter_area / (box_a_area + np.transpose(box_b_area) - inter_area)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60ad503",
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo(x):\n",
    "    img = Image.open(os.path.join(base_path, x[\"image_id\"]))\n",
    "    iou_coreml = get_iou(np.array([[x[\"x1_true\"], x[\"y1_true\"], \n",
    "                                    x[\"x2_true\"], x[\"y2_true\"]]]), \n",
    "                         np.array([[x[\"x1_coreml\"] * img.size[0], x[\"y1_coreml\"] * img.size[1], \n",
    "                                    x[\"x2_coreml\"] * img.size[0], x[\"y2_coreml\"] * img.size[1]]]))[0][0]\n",
    "    return iou_coreml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac3a06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[\"iou_coreml\"] = merged.apply(foo, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee826d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[\"iou_coreml\"].mean()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
