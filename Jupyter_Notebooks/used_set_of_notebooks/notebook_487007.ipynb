{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4210dabc",
   "metadata": {},
   "source": [
    "![header](../header.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156f0616",
   "metadata": {},
   "source": [
    "# Guia de Processamento Digital de Imagens em linguagem de programação Python\n",
    "\n",
    "## Estudo de caso em Reconhecimento Automático de Placas Veiculares\n",
    "\n",
    "### Descrição\n",
    "\n",
    "Esse guia é composto de diversos notebooks que têm por principal objetivo apresentar o desenvolvimento de algoritmos em linguagem python com uso da biblioteca de visão computacional OpenCV. Para isso, toma como exemplo um estudo de caso em reconhecimento automático de placas veiculares. As imagens utilizadas são do [SSIG-ALPR Database](http://www.smartsenselab.dcc.ufmg.br/ssig-alpr-database).\n",
    "\n",
    "### Notebook número 11\n",
    "\n",
    "Esse notebook tem por objetivo utilizar as técnicas aprendidas como método de comparação de imagens. As seguintes formas de comparação serão estudadas:\n",
    "\n",
    "1. Template Matching\n",
    "1. Comparação de Histograma\n",
    "\n",
    "Nesse caso, o primeiro passo a ser dado é a importação das bibliotecas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f941330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from os import listdir, path\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622d71d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcoes uteis \n",
    "\n",
    "# Funcao de leitura de imagens\n",
    "def pdiguide_imgRead(path,convert=True,show=False):\n",
    "    # Essa funcao cria uma lista de imagens dado o caminho (path) de um diretório.\n",
    "    # Se \"convert\" é Verdadeiro, a função irá realizar a conversão das imagens de RGB para Grayscale\n",
    "    # Se \"show\" é Verdadeiro, a função irá exibir as imagens carregadas\n",
    "    \n",
    "    img = [] # lista de imagens em tons de cinza\n",
    "\n",
    "    number_of_files = len(listdir(path))#a função listdir forma uma lista com todos os arquivos\n",
    "\n",
    "    if(show):\n",
    "        plt.figure(figsize=[15,10]) #define a existencia de uma figura e define o seu tamanho\n",
    "\n",
    "    #A cada iteração uma imagem é carregada e convertida para tons de cinza, \n",
    "    #ao passo que é armazenada nos vetores acima\n",
    "    for i in range(0,number_of_files): \n",
    "        img.append(cv2.imread(path + str(i+1) + '.png'))\n",
    "        if(convert):\n",
    "            img[i]=(cv2.cvtColor(img[i],cv2.COLOR_RGB2GRAY))\n",
    "\n",
    "        #Exibe as imagens\n",
    "        if(show):\n",
    "            plt.subplot(1+number_of_files/5,5,i+1)\n",
    "            plt.imshow(img[i],cmap='gray'),plt.xticks([]),plt.yticks([]) \n",
    "            #xticks e yticks controlam as escalas exibidas, nesse caso, serão nulas.\n",
    "            \n",
    "    print(\"Leitura finalizada, total de imagens lidas = \",len(img))\n",
    "    return img #retorna a lista de imagens\n",
    "    \n",
    "# Funcao apenas para exibicao da lista de imagens\n",
    "def pdiguide_show(list_of_imgs, columns, titles=None):\n",
    "    # Essa funcao exibe as imagens dado uma lista de imagens.\n",
    "    number_of_files = len(list_of_imgs)\n",
    "    for i in range(0,number_of_files): \n",
    "        plt.subplot(1+number_of_files/columns,columns,i+1) \n",
    "        plt.imshow(list_of_imgs[i],cmap='gray'),plt.xticks([]),plt.yticks([]) \n",
    "        if titles != None: plt.title(titles[i])\n",
    "            \n",
    "# Funcao para calcular e exibir o histograma de uma imagem \n",
    "def pdiguide_histogram(img,nbins,show=False):\n",
    "    # Essa funcao calcula o histograma de um vetor 2D (imagem grayscale)\n",
    "    # com valores inteiros entre 0-255.\n",
    "    # Essa imagem retorna um vetor 1D com o histograma e os pontos \n",
    "    # que representam o bin_edges para plotagem do histograma.\n",
    "    # Caso show seja verdadeiro ela mesmo irá plotar o histograma\n",
    "    h, bin_edges = np.histogram(img.ravel(), nbins,(0,255))\n",
    "    if show:\n",
    "        w=256./nbins\n",
    "        bin_centers = bin_edges[1:]-(w/2)\n",
    "        plt.bar(bin_centers, h, width=w)\n",
    "    \n",
    "    return h, bin_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d301df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leitura das imagens\n",
    "path = '../Data/'\n",
    "img = pdiguide_imgRead(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0a0797",
   "metadata": {},
   "source": [
    "Vamos utilizar um dos algoritmos do [Notebook 10](Notebook10-RepresentacaoDescricao.ipynb) para montar um conjunto de imagem de placas aos quais vamos comparar entre si. Os parâmetros foram reajustados para permitir uma passagem maior de falsas placas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02c6246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algoritmo do notebook de descrição e representação\n",
    "def make_plates_images(img):\n",
    "    '''Cria alguns candidatos a placas'''\n",
    "    crops = []\n",
    "    c = 0 \n",
    "    car_blur = cv2.blur(img,(5,5))\n",
    "    _,bin_car = cv2.threshold(car_blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    contours,hierarquia = cv2.findContours(bin_car.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = sorted(contours, key = cv2.contourArea, reverse = True)[:40]\n",
    "    for index in range(0,len(cnts)):\n",
    "        x1,y1,w,h = cv2.boundingRect(cnts[index])\n",
    "        ar = h/w \n",
    "        if(ar >= 0.2 and ar <= 0.5):\n",
    "            x2 = x1+w\n",
    "            y2 = y1+h\n",
    "            crops.append(img.copy()[y1:y2,x1:x2].astype(np.uint8))\n",
    "    return crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a46109",
   "metadata": {},
   "outputs": [],
   "source": [
    "plates2 = []\n",
    "for i in range(2):\n",
    "    plates2.append(make_plates_images(img[i]))\n",
    "\n",
    "plates = []\n",
    "for plate in plates2:\n",
    "    for i in range(len(plate)):\n",
    "        plates.append(plate[i])\n",
    "    \n",
    "plt.figure(figsize=(20,3))\n",
    "for i in range(len(plates)):\n",
    "    plt.subplot(1+len(plates)/10,10,i+1)\n",
    "    plt.imshow(plates[i],cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae7ec9a",
   "metadata": {},
   "source": [
    "####  Comparação de Imagens - Template Matching\n",
    "\n",
    "Existem diversas técnicas para comparar duas imagens. Para imagens do mesmo tamnho um método simples é o módulo da diferença entre elas, caso queira obter uma medida de dissimilaridade entre as imagens, basta somar os valores dos pixels da matriz de diferença resultante.\n",
    "\n",
    "Entretanto, no nosso caso estamos considerando imagens com tamanhos distintos. Como então comparar essas imagens? O template matching pode ser útil em situações onde o objeto que intereça possui dimensões similares ao template. Vamos tentar usar o template matching como forma de comparar as imagens e vê o que acontece. Em princípio, utilizaremos como template a imagem da placa da figura 2 (no intervalo de 0 a 19)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a267f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 2\n",
    "template = img[ind][650:677,1373:1460]\n",
    "plt.figure(figsize=(10,6))\n",
    "pdiguide_show([img[ind],template],2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d196bbab",
   "metadata": {},
   "source": [
    "Vamos definir uma função que gera um score a partir do template matching. Para o score vamos apenas pegar o valor que o próprio template matching usa para localizar a região de maior similaridade ou menor dissimilaridade. Para facilita vamos utilizar somente o método de similaridade do coeficiente de correlação. Entretanto, fique a disposição para testar com outros métodos, lembrando que se o método é de dissimilaridade use o valor mínimo, caso contrário, valor máximo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75893d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definicao de uma lista com os metodos usados pelo Template Matching do OpenCV\n",
    "methods = ['cv2.TM_CCOEFF', 'cv2.TM_CCOEFF_NORMED', 'cv2.TM_CCORR', \n",
    "           'cv2.TM_CCORR_NORMED', 'cv2.TM_SQDIFF', 'cv2.TM_SQDIFF_NORMED']\n",
    "\n",
    "def template_Match_comparison(image,template):\n",
    "    \n",
    "    meth = 'cv2.TM_CCOEFF'\n",
    "    img2 = image.copy() # copia a imagem original para img2\n",
    "    method = eval(meth) # associa as strings em métodos as suas contantes do OpenCV\n",
    "    \n",
    "    # Aplicando o template Matching\n",
    "    match = cv2.matchTemplate(img2,template,method) \n",
    "\n",
    "    # Extraindo os pontos de máxima e mínimo globais\n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(match)\n",
    "     \n",
    "    return max_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89badc2",
   "metadata": {},
   "source": [
    "De modo a garantir que a imagem template seja sempre menor que a imagem comparada, vamos adicionar um pad de zeros as imagens que forem menores que o template, i.e., vamos adicionar zero a borda das imagens para torná-las maior que o template. Lembre-se porém que isso não é o ideal visto que para um bom template matching o objeto que se procura e a imagem template tem que ter dimensões similares. Em outras palavras o template matching é sensível a escala. Caso queira uma solução diferenciada, busque pos abordagens pirâmidais ou similares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dade6de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_plates = []\n",
    "fator_multip = 1\n",
    "for plate in plates:\n",
    "    while(plate.shape[0] <= fator_multip*template.shape[0]): # enquanto o número de linhas for menor\n",
    "        zero_pad_y = np.zeros(plate.shape[1],np.uint8)\n",
    "        # adicione uma linha de zeros e mesmo tamanho ao final da imagem \n",
    "        plate = np.vstack((plate.copy(),zero_pad_y))         \n",
    "    while(plate.shape[1] <= fator_multip*template.shape[1]): # enquanto o número de coluna for menor\n",
    "        zero_pad_x = np.zeros([plate.shape[0],1],np.uint8)\n",
    "        # adicione uma coluna de zeros e mesmo tamanho ao final da imagem\n",
    "        plate = np.hstack((plate.copy(),zero_pad_x))\n",
    "    pad_plates.append(plate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad169972",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for plate in pad_plates:\n",
    "    results.append(template_Match_comparison(plate,template))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344366d0",
   "metadata": {},
   "source": [
    "`Results` é uma lista contendo um score para cada imagem. Vamos agora plotar a imagem que possui o maior score, já que o método usado foi de similaridade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f4bd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "pdiguide_show([template,pad_plates[np.argmax(results)]],2,['Template','Most Similar image'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1718dd4c",
   "metadata": {},
   "source": [
    "Podemos acreditar que essa imagem foi a melhor selecionada, pois houve um melhor casamento entre o tamanho do template e o tamanho da placa na imagem. Vamos visualizar as três iagens mais similares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e38cde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "edit_results = results.copy()\n",
    "top = 3\n",
    "to_plot = []\n",
    "to_plot.append(template)\n",
    "titles = []\n",
    "titles.append('template')\n",
    "\n",
    "for i in range(top):\n",
    "    to_plot.append(pad_plates[np.argmax(edit_results)])\n",
    "    edit_results[np.argmax(edit_results)] = 0\n",
    "    titles.append('Top '+str(i+1))\n",
    "\n",
    "plt.figure(figsize=(15,4))\n",
    "pdiguide_show(to_plot,top+1,titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5a11bc",
   "metadata": {},
   "source": [
    "Observa-se que as duas primeiras imagens realmente condizem a placas, a partir da terceira, o algoritmo já se comporta de forma diferente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84080791",
   "metadata": {},
   "source": [
    "#### Comparação de Imagens - Comparação de Histogramas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea58674",
   "metadata": {},
   "source": [
    "A comparação de histogramas é uma abordagem para determinar similaridades e dissimilaridades entre os valores dos pixels de duas imagens. Entretanto, por se tratar de histograma não considera a distribuição espacial dos pixels. Vamos fazer alguns testes com essa abordagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1710dd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins = 128\n",
    "s = len(plates)\n",
    "hists = []\n",
    "plt.figure(figsize=(20,35))\n",
    "for i in range(s):\n",
    "    plt.subplot(s/6+1,6,i+1)\n",
    "    #eq = cv2.equalizeHist(plates[i])\n",
    "    h,_ = pdiguide_histogram(plates[i],nbins,show=True)\n",
    "    if(i == 2 or i == 26): \n",
    "        plt.title('Histograma da placa')\n",
    "    elif(i == 22):\n",
    "        plt.title('Histograma do placa+ruido')\n",
    "    else:\n",
    "        plt.title('Histograma do ruido')\n",
    "    hists.append(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd02603",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 0\n",
    "template = img[ind][760:800,370:500]\n",
    "plt.figure(figsize=(10,6))\n",
    "pdiguide_show([img[ind],template],2)\n",
    "\n",
    "# Calculando e adequando o histograma do template\n",
    "#eq_template = cv2.equalizeHist(template)\n",
    "plt.figure(figsize=(5,3))\n",
    "h_temp,_ = pdiguide_histogram(template,nbins,show=True)\n",
    "hist_template = h_temp.ravel().astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83fa991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metodos de similaridade e dissimilaridade do OpenCV para comparação de histogramas\n",
    "methods = ['cv2.HISTCMP_CORREL','cv2.HISTCMP_CHISQR','cv2.HISTCMP_INTERSECT',\n",
    "           'cv2.HISTCMP_BHATTACHARYYA', 'cv2.HISTCMP_CHISQR_ALT', 'cv2.HISTCMP_KL_DIV']\n",
    "\n",
    "# Declarando dicionário de comparação\n",
    "comparison={}\n",
    "\n",
    "for compare_method in methods:\n",
    "    scores = []\n",
    "    for h in hists:\n",
    "        value = cv2.compareHist(hist_template, h.ravel().astype('float32'), eval(compare_method))\n",
    "        scores.append(value)\n",
    "    comparison[compare_method] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c4bf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_chosen = []\n",
    "for compare_method in methods:\n",
    "    if compare_method == 'cv2.HISTCMP_CORREL' or compare_method == 'cv2.HISTCMP_INTERSECT' :\n",
    "        index = np.argmax(comparison[compare_method])\n",
    "    else:\n",
    "        index = np.argmin(comparison[compare_method])\n",
    "    img_chosen.append(plates[index])\n",
    "\n",
    "plt.figure(figsize=(20,4))\n",
    "pdiguide_show(img_chosen,ft,methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07337507",
   "metadata": {},
   "source": [
    "O objetivo principal com esse notebook era mostrar formas de comparar imagem e introduzir conceitos como similaridade e dissimilaridade. Além desses métodos existem outras formas de comparar imagens. \n",
    "\n",
    "Observe que tentamos reconhecer, ou classificar se uma imagem é de placa ou não. Para isso levamos em consideração a imagem de uma placa. Outras abordagens poderiam ser exploradas para esse problemas de classificar se é placa ou não, como exemplo: \n",
    "\n",
    "- uso de técnicas de componentes conexos ou segmentação por região para tentar identificar caracteres na placa\n",
    "- uso de contornos para detectar a região retangular da placa ou ainda identificar os caracteres\n",
    "- de forma semelhante, uso da transformada de Hough para detectar caracteres e retângulos\n",
    "- traçar uma espécie de histograma cujo eixo x seja a coluna da imagem e o eixo y o valor do pixel na linha central da imagem. A ideia é observar a existência de transições entre a placa e o caractere.\n",
    "- entre outras formas, fica abertos para descobri-las e/ou inventá-las.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5804b60f",
   "metadata": {},
   "source": [
    "### Referências\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
