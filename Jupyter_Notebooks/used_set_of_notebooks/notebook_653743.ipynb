{"cells":[{"cell_type":"markdown","id":"773ede8e","metadata":{"id":"773ede8e"},"source":["# Adult preprocessing\n","\n","This notebook contains all preprocessing of the [Adult dataset](https://archive.ics.uci.edu/ml/datasets/Adult)"]},{"cell_type":"code","execution_count":null,"id":"0c1a13f4","metadata":{"id":"0c1a13f4"},"outputs":[],"source":["from pathlib import Path\n","\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler"]},{"cell_type":"markdown","id":"7ca1492c","metadata":{"id":"7ca1492c"},"source":["The column names are available in the [`adult.names`](https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names) file which contains lots of additional information. We hard code them here for convenience."]},{"cell_type":"code","execution_count":null,"id":"f91232c3","metadata":{"id":"f91232c3"},"outputs":[],"source":["names = [\n","    \"age\",\n","    \"workclass\",\n","    \"fnlwgt\",\n","    \"education\",\n","    \"education_num\",\n","    \"marital_status\",\n","    \"occupation\",\n","    \"relationship\",\n","    \"race\",\n","    \"sex\",\n","    \"capital_gain\",\n","    \"capital_loss\",\n","    \"hours_per_week\",\n","    \"native_country\",\n","    \"salary\",\n","]"]},{"cell_type":"markdown","id":"ad402e39","metadata":{"id":"ad402e39"},"source":["Data contains a \"native country\" feature. Other than USA and Mexico, many of the features have low numbers of observations, so we group them into a single category using this function."]},{"cell_type":"code","execution_count":null,"id":"d63bf7e2","metadata":{"id":"d63bf7e2"},"outputs":[],"source":["def clean_string(s):\n","    \"\"\"\n","    Helper function that strips leading / trailing whitespace, lower\n","    cases, and replaces hyphens with underscores.\n","    \"\"\"\n","    return s.strip().lower().replace(\"-\", \"_\")\n","\n","\n","def parse_native_country(country):\n","    \"\"\"\n","    Group countries other than United-States and Mexico into single\n","    \"other\" category\"\n","    \"\"\"\n","    country = clean_string(country)\n","    if country == \"united_states\" or country == \"mexico\":\n","        return country\n","    return \"other\""]},{"cell_type":"markdown","id":"fe030d15","metadata":{"id":"fe030d15"},"source":["Load train set and apply some basic preprocessing. Categorical features are left as strings for now to be one-hot encoded shortly. We drop `fnlwgt` as it represents census weights that are not relevant to our analysis, and `education-num` as it duplicates data present in the `education` feature which we use instead."]},{"cell_type":"code","execution_count":null,"id":"344431f5","metadata":{"id":"344431f5"},"outputs":[],"source":["train = (\n","    pd.read_csv(\n","        \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\",\n","        header=None,\n","        na_values=[\" ?\"],\n","        names=names,\n","    )\n","    .drop(columns=[\"fnlwgt\", \"education_num\"])\n","    # drop all rows with missing values\n","    .dropna()\n","    .reset_index(drop=True)\n","    # simple preprocessing on columns\n","    .assign(\n","        # clean all string columns\n","        education=lambda df: df.education.map(clean_string),\n","        marital_status=lambda df: df.marital_status.map(clean_string),\n","        occupation=lambda df: df.occupation.map(clean_string),\n","        race=lambda df: df.race.map(clean_string),\n","        relationship=lambda df: df.relationship.map(clean_string),\n","        workclass=lambda df: df.workclass.map(clean_string),\n","        # clean and aggregate native_country\n","        native_country=lambda df: df.native_country.map(parse_native_country),\n","        # encode binary features as integers\n","        salary=lambda df: (df.salary == \" >50K\").astype(np.int32),\n","        sex=lambda df: (df.sex == \" Male\").astype(np.int32),\n","    )\n",")"]},{"cell_type":"markdown","id":"42692099","metadata":{"id":"42692099"},"source":["Load test set and apply similar basic preprocessing. Note `adult.test` file has an extra line at the start of the file we ignore, and that the `salary` column is coded differently to `adult.data` in a subtle way (has an extra `.`)."]},{"cell_type":"code","execution_count":null,"id":"ab6a5fce","metadata":{"id":"ab6a5fce"},"outputs":[],"source":["test = (\n","    pd.read_csv(\n","        \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\",\n","        header=None,\n","        na_values=[\" ?\"],\n","        skiprows=1,\n","        names=names,\n","    )\n","    .drop(columns=[\"fnlwgt\", \"education_num\"])\n","    # drop all rows with missing values\n","    .dropna()\n","    .reset_index(drop=True)\n","    # simple preprocessing on columns\n","    .assign(\n","        # clean all string columns\n","        education=lambda df: df.education.map(clean_string),\n","        marital_status=lambda df: df.marital_status.map(clean_string),\n","        occupation=lambda df: df.occupation.map(clean_string),\n","        race=lambda df: df.race.map(clean_string),\n","        relationship=lambda df: df.relationship.map(clean_string),\n","        workclass=lambda df: df.workclass.map(clean_string),\n","        # clean and aggregate native_country\n","        native_country=lambda df: df.native_country.map(parse_native_country),\n","        # encode binary features as integers\n","        # note extra '.' in test set not present in train set\n","        salary=lambda df: (df.salary == \" >50K.\").astype(np.int32),\n","        sex=lambda df: (df.sex == \" Male\").astype(np.int32),\n","    )\n",")"]},{"cell_type":"markdown","id":"6231cee5","metadata":{"id":"6231cee5"},"source":["Sanity check that categories in categorical variables are the same for train and test sets."]},{"cell_type":"code","execution_count":null,"id":"65860fec","metadata":{"id":"65860fec"},"outputs":[],"source":["assert set(train.education) == set(test.education)\n","assert set(train.race) == set(test.race)\n","assert set(train.relationship) == set(test.relationship)\n","assert set(train.marital_status) == set(test.marital_status)"]},{"cell_type":"code","execution_count":null,"id":"3051a0cf","metadata":{"id":"3051a0cf"},"outputs":[],"source":["one_hot_features = [\n","    \"workclass\",\n","    \"education\",\n","    \"occupation\",\n","    \"race\",\n","    \"relationship\",\n","    \"marital_status\",\n","    \"native_country\",\n","]\n","\n","cts_features = [\"age\", \"capital_gain\", \"capital_loss\", \"hours_per_week\"]\n","\n","binary_features = [\"sex\", \"salary\"]"]},{"cell_type":"markdown","id":"7e7f4567","metadata":{"id":"7e7f4567"},"source":["We one-hot encode categorical features. We'll keep both one-hot encodings and the original categorical encodings for now, as we want to construct two versions of the data, one for training the model on, and one for making visualisations."]},{"cell_type":"code","execution_count":null,"id":"bf2fd385","metadata":{"id":"bf2fd385"},"outputs":[],"source":["train[\"race\"].value_counts()"]},{"cell_type":"code","execution_count":null,"id":"27ec21f6","metadata":{"id":"27ec21f6"},"outputs":[],"source":["train_df = pd.concat(\n","    [train, pd.get_dummies(train.loc[:, one_hot_features], dtype=np.int32)],\n","    axis=1,\n",")\n","\n","test_df = pd.concat(\n","    [test, pd.get_dummies(test.loc[:, one_hot_features], dtype=np.int32)],\n","    axis=1,\n",")"]},{"cell_type":"markdown","id":"614c87be","metadata":{"id":"614c87be"},"source":["Sanity check that the columns are the same (including order)."]},{"cell_type":"code","execution_count":null,"id":"e0891614","metadata":{"id":"e0891614"},"outputs":[],"source":["assert train_df.columns.tolist() == test_df.columns.tolist()"]},{"cell_type":"markdown","id":"af1df771","metadata":{"id":"af1df771"},"source":["We further split the train set to create a validation set."]},{"cell_type":"code","execution_count":null,"id":"01047040","metadata":{"id":"01047040"},"outputs":[],"source":["train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)"]},{"cell_type":"markdown","id":"34994f99","metadata":{"id":"34994f99"},"source":["Save all splits to disk without one-hot encodings. This version of the data will be used for exploration and making plots."]},{"cell_type":"code","execution_count":null,"id":"4c1b6fb7","metadata":{"id":"4c1b6fb7"},"outputs":[],"source":["artifacts_dir = Path(\"../../artifacts\")"]},{"cell_type":"code","execution_count":null,"id":"5ed021f1","metadata":{"id":"5ed021f1"},"outputs":[],"source":["# override data_dir in source notebook\n","# this is stripped out for the hosted notebooks\n","artifacts_dir = Path(\"../../../artifacts\")"]},{"cell_type":"code","execution_count":null,"id":"371a5432","metadata":{"id":"371a5432"},"outputs":[],"source":["data_dir = artifacts_dir / \"data\" / \"adult\""]},{"cell_type":"code","execution_count":null,"id":"7a464817","metadata":{"id":"7a464817"},"outputs":[],"source":["original_features = cts_features + one_hot_features + binary_features\n","\n","train_df[original_features].to_csv(\n","    data_dir / \"processed\" / \"train.csv\", index=False\n",")\n","val_df[original_features].to_csv(\n","    data_dir / \"processed\" / \"val.csv\", index=False\n",")\n","test_df[original_features].to_csv(\n","    data_dir / \"processed\" / \"test.csv\", index=False\n",")"]},{"cell_type":"markdown","id":"170237cd","metadata":{"id":"170237cd"},"source":["We now scale the continuous features and drop the categorical encodings, which will be used for model training."]},{"cell_type":"code","execution_count":null,"id":"af7c4e61","metadata":{"id":"af7c4e61"},"outputs":[],"source":["ss = StandardScaler()\n","\n","train_df[cts_features] = ss.fit_transform(train_df[cts_features])\n","val_df[cts_features] = ss.transform(val_df[cts_features])\n","test_df[cts_features] = ss.transform(test_df[cts_features])"]},{"cell_type":"code","execution_count":null,"id":"27ded8e7","metadata":{"id":"27ded8e7"},"outputs":[],"source":["train_df.drop(columns=one_hot_features).to_csv(\n","    data_dir / \"processed\" / \"train-one-hot.csv\", index=False\n",")\n","val_df.drop(columns=one_hot_features).to_csv(\n","    data_dir / \"processed\" / \"val-one-hot.csv\", index=False\n",")\n","test_df.drop(columns=one_hot_features).to_csv(\n","    data_dir / \"processed\" / \"test-one-hot.csv\", index=False\n",")"]}],"metadata":{"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}