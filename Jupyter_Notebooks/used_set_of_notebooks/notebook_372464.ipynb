{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0f86be2",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/AlsoSprachZarathushtra/Quick-Draw-Recognition/blob/master/(2_2)StrokeColor_MobileNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad5b5ac",
   "metadata": {},
   "source": [
    "# Connect Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dedcaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d79e3b7",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ac3e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPool2D\n",
    "from tensorflow.keras.layers import ReLU\n",
    "from tensorflow.keras.layers import Softmax\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.metrics import sparse_top_k_categorical_accuracy\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3ec7d4",
   "metadata": {},
   "source": [
    "# Parameters  and  Work-Space Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093ea726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "BATCH_SIZE = 200\n",
    "EPOCHS = 50\n",
    "STEPS_PER_EPOCH = 850\n",
    "VALIDATION_STEPS = 100\n",
    "EVALUATE_STEPS = 850\n",
    "IMAGE_SIZE = 128\n",
    "LINE_SIZE = 3\n",
    "\n",
    "\n",
    "# load path\n",
    "TRAIN_DATA_PATH = 'gdrive/My Drive/QW/Data/Data_10000/All_classes_10000.csv'\n",
    "VALID_DATA_PATH = 'gdrive/My Drive/QW/Data/My_test_data/My_test_data.csv'\n",
    "LABEL_DICT_PATH = 'gdrive/My Drive/QW/Data/labels_dict.npy'\n",
    "\n",
    "# save path\n",
    "CKPT_PATH = 'gdrive/My Drive/QW/Notebook/Quick Draw/Thesis_pre_research/(2-2)Stroke_MobileNet/best_model_2_2.ckpt'\n",
    "LOSS_PLOT_PATH = 'gdrive/My Drive/QW/Notebook/Quick Draw/Thesis_pre_research/(2-2)Stroke_MobileNet/loss_plot_2_2.png'\n",
    "ACC_PLOT_PATH = 'gdrive/My Drive/QW/Notebook/Quick Draw/Thesis_pre_research/(2-2)Stroke_MobileNet/acc_plot_2_2.png'\n",
    "LOG_PATH = 'gdrive/My Drive/QW/Notebook/Quick Draw/Thesis_pre_research/(2-2)Stroke_MobileNet/Log_2_2.log'\n",
    "\n",
    "print('finish!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e810715",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d92f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(data, batch_size, choose_recognized):\n",
    "    data = data.sample(frac = 1)\n",
    "    while 1:\n",
    "        \n",
    "#         get columns' values named 'drawing', 'word' and 'recognized'\n",
    "        drawings = data[\"drawing\"].values\n",
    "        drawing_recognized = data[\"recognized\"].values\n",
    "        drawing_class = data[\"word\"].values\n",
    "      \n",
    "#         initialization\n",
    "        cnt = 0\n",
    "        data_X =[]\n",
    "        data_Y =[]\n",
    "        \n",
    "#         generate batch\n",
    "        for i in range(len(drawings)):\n",
    "            if choose_recognized:\n",
    "                if drawing_recognized[i] == 'False':    #Choose according to recognized value\n",
    "                    continue\n",
    "            draw = drawings[i]\n",
    "            label = drawing_class[i]\n",
    "            stroke_vec = literal_eval(draw)\n",
    "            img = np.zeros([256, 256])\n",
    "            x = []\n",
    "            for j in range(len(stroke_vec)): \n",
    "                line = np.array(stroke_vec[j]).T\n",
    "                cv2.polylines(img, [line], False, 255-(13*min(j,10)), LINE_SIZE)\n",
    "            img = cv2.resize(img, (IMAGE_SIZE,IMAGE_SIZE), interpolation = cv2.INTER_NEAREST)\n",
    "            img = img[:,:, np.newaxis]\n",
    "            x = img\n",
    "            y = labels2nums_dict[label]\n",
    "            data_X.append(x)\n",
    "            data_Y.append(y)\n",
    "            cnt += 1\n",
    "            if cnt==batch_size:        #generate a batch when cnt reaches batch_size \n",
    "                cnt = 0\n",
    "                yield (np.array(data_X), np.array(data_Y))\n",
    "                data_X = []\n",
    "                data_Y = []\n",
    "\n",
    "print('finish!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779688cf",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bbb7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a class named LossHitory \n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = {'batch':[], 'epoch':[]}\n",
    "        self.accuracy = {'batch':[], 'epoch':[]}\n",
    "        self.val_loss = {'batch':[], 'epoch':[]}\n",
    "        self.val_acc = {'batch':[], 'epoch':[]}\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses['batch'].append(logs.get('loss'))\n",
    "        self.accuracy['batch'].append(logs.get('acc'))\n",
    "        self.val_loss['batch'].append(logs.get('val_loss'))\n",
    "        self.val_acc['batch'].append(logs.get('val_acc'))\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses['epoch'].append(logs.get('loss'))\n",
    "        self.accuracy['epoch'].append(logs.get('acc'))\n",
    "        self.val_loss['epoch'].append(logs.get('val_loss'))\n",
    "        self.val_acc['epoch'].append(logs.get('val_acc'))\n",
    "\n",
    "    def loss_plot(self, loss_type, loss_fig_save_path, acc_fig_save_path):\n",
    "        iters = range(len(self.losses[loss_type]))\n",
    "        plt.figure('acc')\n",
    "        plt.plot(iters, self.accuracy[loss_type], 'r', label='train acc')\n",
    "        plt.plot(iters, self.val_acc[loss_type], 'b', label='val acc')\n",
    "        plt.grid(True)\n",
    "        plt.xlabel(loss_type)\n",
    "        plt.ylabel('acc')\n",
    "        plt.legend(loc=\"upper right\")\n",
    "        plt.savefig(acc_fig_save_path)\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        plt.figure('loss')\n",
    "        plt.plot(iters, self.losses[loss_type], 'g', label='train loss')\n",
    "        plt.plot(iters, self.val_loss[loss_type], 'k', label='val loss')\n",
    "        plt.grid(True)\n",
    "        plt.xlabel(loss_type)\n",
    "        plt.ylabel('loss')\n",
    "        plt.legend(loc=\"upper right\")\n",
    "        plt.savefig(loss_fig_save_path)\n",
    "        plt.show()\n",
    "        \n",
    "# create a object from LossHistory class\n",
    "History = LossHistory()\n",
    "\n",
    "print(\"finish!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a1d60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    CKPT_PATH, \n",
    "    verbose = 1, \n",
    "    monitor='val_acc', \n",
    "    mode = 'max', \n",
    "    save_best_only=True)\n",
    "\n",
    "print(\"finish!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4b5d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "ReduceLR = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=3,\n",
    "                      min_delta=0.005, mode='max', cooldown=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61060bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_logger = CSVLogger(LOG_PATH, separator=',', append=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482330fe",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dc96f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train data and valid data\n",
    "#  labels_dict and data path\n",
    "\n",
    "# labels convert into nums\n",
    "labels_dict = np.load(LABEL_DICT_PATH)\n",
    "labels2nums_dict = {v: k for k, v in enumerate(labels_dict)}\n",
    "\n",
    "# read csv \n",
    "train_data = pd.read_csv(TRAIN_DATA_PATH)\n",
    "valid_data = pd.read_csv(VALID_DATA_PATH)\n",
    "\n",
    "print('finish!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfa19fa",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d56c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MODEL = tf.keras.applications.MobileNet(\n",
    "        input_shape=(IMAGE_SIZE,IMAGE_SIZE,1),\n",
    "        alpha=1.0,\n",
    "        include_top=True,\n",
    "        weights=None,\n",
    "        classes=340\n",
    "        )\n",
    "MODEL.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf38786",
   "metadata": {},
   "source": [
    "# Complie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed45749",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MODEL\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('finish')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05b87a2",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b627ca73",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('start training')\n",
    "# callbacks = [History, cp_callback]\n",
    "\n",
    "history = model.fit_generator(generate_data(train_data, BATCH_SIZE, True),\n",
    "                              steps_per_epoch = STEPS_PER_EPOCH,\n",
    "                              epochs = EPOCHS,\n",
    "                              validation_data = generate_data(valid_data, BATCH_SIZE, False) ,\n",
    "                              validation_steps = VALIDATION_STEPS,\n",
    "                              verbose = 1,\n",
    "                              initial_epoch = 0,\n",
    "                              callbacks = [History,cp_callback,ReduceLR,csv_logger]\n",
    "                             )\n",
    "print(\"finish training\")\n",
    "\n",
    "History.loss_plot('epoch', LOSS_PLOT_PATH, ACC_PLOT_PATH)\n",
    "\n",
    "print('finish!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14db7542",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2563539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_3_accuracy(X, Y):\n",
    "        return sparse_top_k_categorical_accuracy(X, Y, 3)\n",
    "  \n",
    "def top_5_accuracy(X, Y):\n",
    "        return sparse_top_k_categorical_accuracy(X, Y, 5)\n",
    "  \n",
    "model_E = MODEL\n",
    "model_E.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=tf.train.AdamOptimizer(),\n",
    "              metrics=['accuracy',top_3_accuracy, top_5_accuracy])\n",
    "\n",
    "model_weights_path = CKPT_PATH\n",
    "model_E.load_weights(model_weights_path)\n",
    "print('finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2224da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model_E.evaluate_generator(\n",
    "    generate_data(valid_data, BATCH_SIZE, False),\n",
    "    steps = EVALUATE_STEPS,\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "print('loss:', result[0])\n",
    "print('top1 accuracy:', result[1])\n",
    "print('top3 accuracy:', result[2])\n",
    "print('top3 accuracy:', result[3])"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
