{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16ad0906",
   "metadata": {},
   "source": [
    "## How to read BigQuery data from TensorFlow 2.0 efficiently\n",
    "\n",
    "This notebook accompanies the article \n",
    "[\"How to read BigQuery data from TensorFlow 2.0 efficiently\"](https://medium.com/@lakshmanok/how-to-read-bigquery-data-from-tensorflow-2-0-efficiently-9234b69165c8)\n",
    "\n",
    "The example problem is to find credit card fraud from the dataset published in:\n",
    "<i>\n",
    "Andrea Dal Pozzolo, Olivier Caelen, Reid A. Johnson and Gianluca Bontempi. Calibrating Probability with Undersampling for Unbalanced Classification. In Symposium on Computational Intelligence and Data Mining (CIDM), IEEE, 2015\n",
    "</i>\n",
    "and available in BigQuery at <pre>bigquery-public-data.ml_datasets.ulb_fraud_detection</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ad70d2",
   "metadata": {},
   "source": [
    "## Benchmark Model\n",
    "\n",
    "In order to compare things, we will do a simple logistic regression in BigQuery ML.\n",
    "\n",
    "Note that we are using all the columns in the dataset as predictors (except for the Time and Class columns).\n",
    "The Time column is used to split the dataset 80:20 with the first 80% used for training and the last 20% used for evaluation.\n",
    "We will also have BigQuery ML automatically balance the weights.\n",
    "\n",
    "Because the Amount column has a huge range, we take the log of it in preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af13e7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# create output dataset\n",
    "bq mk advdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f467b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "CREATE OR REPLACE MODEL advdata.ulb_fraud_detection \n",
    "TRANSFORM(\n",
    "    * EXCEPT(Amount),\n",
    "    SAFE.LOG(Amount) AS log_amount\n",
    ")\n",
    "OPTIONS(\n",
    "    INPUT_LABEL_COLS=['class'],\n",
    "    AUTO_CLASS_WEIGHTS = TRUE,\n",
    "    DATA_SPLIT_METHOD='seq',\n",
    "    DATA_SPLIT_COL='Time',\n",
    "    MODEL_TYPE='logistic_reg'\n",
    ") AS\n",
    "\n",
    "SELECT \n",
    " *\n",
    "FROM `bigquery-public-data.ml_datasets.ulb_fraud_detection`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f820eac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "SELECT * FROM ML.EVALUATE(MODEL advdata.ulb_fraud_detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eba699a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "SELECT predicted_class_probs, Class\n",
    "FROM ML.PREDICT( MODEL advdata.ulb_fraud_detection,\n",
    "  (SELECT * FROM `bigquery-public-data.ml_datasets.ulb_fraud_detection` WHERE Time = 85285.0)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8ec235",
   "metadata": {},
   "source": [
    "## Find the breakoff point etc. for Keras\n",
    "\n",
    "When we do the training in Keras & TensorFlow, we need to find the place to split the dataset and how to weight the imbalanced data.\n",
    "(BigQuery ML did that for us because we specified 'seq' as the split method and auto_class_weights to be True)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01eb62e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "WITH counts AS (\n",
    "SELECT\n",
    "    APPROX_QUANTILES(Time, 5)[OFFSET(4)] AS train_cutoff\n",
    "    , COUNTIF(CLASS > 0) AS pos\n",
    "    , COUNTIF(CLASS = 0) AS neg\n",
    "FROM `bigquery-public-data`.ml_datasets.ulb_fraud_detection\n",
    ")\n",
    "\n",
    "SELECT\n",
    "   train_cutoff\n",
    "    , SAFE.LOG(SAFE_DIVIDE(pos,neg)) AS output_bias\n",
    "    , 0.5*SAFE_DIVIDE(pos + neg, pos) AS weight_pos\n",
    "    , 0.5*SAFE_DIVIDE(pos + neg, neg) AS weight_neg\n",
    "FROM counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ced3b0",
   "metadata": {},
   "source": [
    "The time cutoff is 144803 and the Keras model's output bias needs to be set at -6.36\n",
    "The class weights need to be 289.4 and 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb81983",
   "metadata": {},
   "source": [
    "## Training a TensorFlow/Keras model that reads from BigQuery\n",
    "\n",
    "Create the dataset from BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e9dec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow_io.bigquery import BigQueryClient\n",
    "from tensorflow_io.bigquery import BigQueryReadSession\n",
    "\n",
    "def features_and_labels(features):\n",
    "  label = features.pop('Class') # this is what we will train for\n",
    "  return features, label\n",
    "\n",
    "def read_dataset(client, row_restriction, batch_size=2048):\n",
    "    GCP_PROJECT_ID='ai-analytics-solutions'  # CHANGE\n",
    "    COL_NAMES = ['Time', 'Amount', 'Class'] + ['V{}'.format(i) for i in range(1,29)]\n",
    "    COL_TYPES = [dtypes.float64, dtypes.float64, dtypes.int64] + [dtypes.float64 for i in range(1,29)]\n",
    "    DATASET_GCP_PROJECT_ID, DATASET_ID, TABLE_ID,  = 'bigquery-public-data.ml_datasets.ulb_fraud_detection'.split('.')\n",
    "    bqsession = client.read_session(\n",
    "        \"projects/\" + GCP_PROJECT_ID,\n",
    "        DATASET_GCP_PROJECT_ID, TABLE_ID, DATASET_ID,\n",
    "        COL_NAMES, COL_TYPES,\n",
    "        requested_streams=2,\n",
    "        row_restriction=row_restriction)\n",
    "    dataset = bqsession.parallel_read_rows()\n",
    "    return dataset.prefetch(1).map(features_and_labels).shuffle(batch_size*10).batch(batch_size)\n",
    "\n",
    "client = BigQueryClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee06b3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = read_dataset(client, 'Time <= 144803', 2)\n",
    "for row in temp_df:\n",
    "    print(row)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a26c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = read_dataset(client, 'Time <= 144803', 2048)\n",
    "eval_df = read_dataset(client, 'Time > 144803', 2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58d7b13",
   "metadata": {},
   "source": [
    "Create Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cb134a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      tf.keras.metrics.Precision(name='precision'),\n",
    "      tf.keras.metrics.Recall(name='recall'),\n",
    "      tf.keras.metrics.AUC(name='roc_auc'),\n",
    "]\n",
    "\n",
    "# create inputs, and pass them into appropriate types of feature columns (here, everything is numeric)\n",
    "inputs = {\n",
    "    'V{}'.format(i) : tf.keras.layers.Input(name='V{}'.format(i), shape=(), dtype='float64') for i in range(1, 29)\n",
    "}\n",
    "inputs['Amount'] = tf.keras.layers.Input(name='Amount', shape=(), dtype='float64')\n",
    "input_fc = [tf.feature_column.numeric_column(colname) for colname in inputs.keys()]\n",
    "\n",
    "# transformations. only the Amount is transformed\n",
    "transformed = inputs.copy()\n",
    "transformed['Amount'] = tf.keras.layers.Lambda(\n",
    "    lambda x: tf.math.log(tf.math.maximum(x, 0.01)), name='log_amount')(inputs['Amount'])\n",
    "input_layer = tf.keras.layers.DenseFeatures(input_fc, name='inputs')(transformed)\n",
    "\n",
    "# Deep learning model\n",
    "d1 = tf.keras.layers.Dense(16, activation='relu', name='d1')(input_layer)\n",
    "d2 = tf.keras.layers.Dropout(0.25, name='d2')(d1)\n",
    "d3 = tf.keras.layers.Dense(16, activation='relu', name='d3')(d2)\n",
    "output = tf.keras.layers.Dense(1, activation='sigmoid', name='d4', bias_initializer=tf.keras.initializers.Constant())(d3)\n",
    "\n",
    "model = tf.keras.Model(inputs, output)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=metrics)\n",
    "tf.keras.utils.plot_model(model, rankdir='LR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e686442c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = {0: 0.5, 1: 289.4}\n",
    "history = model.fit(train_df, validation_data=eval_df, epochs=20, class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2b1012",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['val_roc_auc']);\n",
    "plt.xlabel('Epoch');\n",
    "plt.ylabel('AUC');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13a0566",
   "metadata": {},
   "source": [
    "## Load TensorFlow model into BigQuery\n",
    "\n",
    "Now that we have trained a TensorFlow model off BigQuery data ...\n",
    "let's load the model into BigQuery and use it for batch prediction!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f99df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET='ai-analytics-solutions-kfpdemo'  # CHANGE TO SOMETHING THAT YOU OWN\n",
    "model.save('gs://{}/bqexample/export'.format(BUCKET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68f8a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "CREATE OR REPLACE MODEL advdata.keras_fraud_detection \n",
    "OPTIONS(model_type='tensorflow', model_path='gs://ai-analytics-solutions-kfpdemo/bqexample/export/*')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f36681a",
   "metadata": {},
   "source": [
    "Now predict with this model (the reason it's called 'd4' is because the output node of my Keras model was called 'd4').\n",
    "To get probabilities, etc. we'd have to add the corresponding outputs to the Keras model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a3a8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "SELECT d4, Class\n",
    "FROM ML.PREDICT( MODEL advdata.keras_fraud_detection,\n",
    "  (SELECT * FROM `bigquery-public-data.ml_datasets.ulb_fraud_detection` WHERE Time = 85285.0)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd20a02a",
   "metadata": {},
   "source": [
    "Copyright 2020 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
