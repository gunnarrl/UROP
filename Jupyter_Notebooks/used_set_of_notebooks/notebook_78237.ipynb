{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f31a2822",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a747095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings, json, re, math\n",
    "from melanoma_utility_scripts import *\n",
    "from kaggle_datasets import KaggleDatasets\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold, RandomizedSearchCV, GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "SEED = 42\n",
    "seed_everything(SEED)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1e6b2a",
   "metadata": {},
   "source": [
    "# Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42865ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "  \"N_FOLDS\": 5,\n",
    "  \"N_USED_FOLDS\": 5,\n",
    "  \"DATASET_PATH\": 'melanoma-256x256'\n",
    "}\n",
    "\n",
    "with open('config.json', 'w') as json_file:\n",
    "    json.dump(json.loads(json.dumps(config)), json_file)\n",
    "    \n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da4074d",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c348cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "database_base_path = '/kaggle/input/siim-isic-melanoma-classification/'\n",
    "train = pd.read_csv(f\"/kaggle/input/{config['DATASET_PATH']}/train.csv\")\n",
    "test = pd.read_csv(database_base_path + 'test.csv')\n",
    "\n",
    "print('Train samples: %d' % len(train))\n",
    "display(train.head())\n",
    "print(f'Test samples: {len(test)}')\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9490652d",
   "metadata": {},
   "source": [
    "# Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfd4a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# age_approx (mean)\n",
    "train['age_approx'].fillna(train['age_approx'].mean(), inplace=True)\n",
    "test['age_approx'].fillna(train['age_approx'].mean(), inplace=True)\n",
    "# anatom_site_general_challenge (NaN)\n",
    "train['anatom_site_general_challenge'].fillna('NaN', inplace=True)\n",
    "test['anatom_site_general_challenge'].fillna('NaN', inplace=True)\n",
    "# sex (mode)\n",
    "train['sex'].fillna(train['sex'].mode()[0], inplace=True)\n",
    "test['sex'].fillna(train['sex'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1e7595",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a566a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Label ecoding\n",
    "enc = LabelEncoder()\n",
    "train['sex_enc'] = enc.fit_transform(train['sex'].astype('str'))\n",
    "test['sex_enc'] = enc.transform(test['sex'].astype('str'))\n",
    "\n",
    "### One-hot ecoding\n",
    "# train = pd.concat([train, pd.get_dummies(train['sex'], prefix='sex_enc', drop_first=True)], axis=1)\n",
    "# test = pd.concat([test, pd.get_dummies(test['sex'], prefix='sex_enc', drop_first=True)], axis=1)\n",
    "\n",
    "### Mean ecoding\n",
    "# Sex\n",
    "train['sex_mean'] = train['sex'].map(train.groupby(['sex'])['target'].mean())\n",
    "test['sex_mean'] = test['sex'].map(train.groupby(['sex'])['target'].mean())\n",
    "\n",
    "\n",
    "# # External features\n",
    "# train_img_ft = pd.read_csv('../input/landscape/TrainSuperTab.csv')\n",
    "# test_img_ft = pd.read_csv('../input/landscape/TestSuperTab.csv')\n",
    "# ext_fts = ['V1', 'V2', 'V3', 'V4','V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', \n",
    "#            'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25',\n",
    "#            'V26', 'V27', 'V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'V34', 'V35', 'V36', 'V37']\n",
    "# for ft in ext_fts:\n",
    "#     train[ft] = train_img_ft[ft]\n",
    "#     test[ft] = test_img_ft[ft]\n",
    "\n",
    "print('Train set')\n",
    "display(train.head())\n",
    "print('Test set')\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1622dd7a",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fbbbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['age_approx', 'sex_mean']\n",
    "\n",
    "ohe_features  = [col for col in train.columns if 'enc' in col]\n",
    "\n",
    "features += ohe_features\n",
    "\n",
    "# External features\n",
    "# features += ext_fts\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9f628e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    'max_depth': list(range(2, 12, 2)),\n",
    "    'learning_rate': list(np.logspace(np.log10(0.005), np.log10(0.5), base=10, num=1000)),\n",
    "    'reg_alpha': list(np.linspace(0, 1)),\n",
    "    'reg_lambda': list(np.linspace(0, 1)),\n",
    "    'colsample_bytree': list(np.linspace(0.3, 1, 10)),\n",
    "    'subsample': list(np.linspace(0.5, 1, 100)),\n",
    "    'scale_pos_weight': list(np.linspace(1, (len(train[train['target'] == 0]) / len(train[train['target'] == 1])), 10)),\n",
    "}\n",
    "\n",
    "\n",
    "skf = KFold(n_splits=config['N_USED_FOLDS'], shuffle=True, random_state=SEED)\n",
    "\n",
    "def get_idxs():\n",
    "    for fold,(idxT, idxV) in enumerate(skf.split(np.arange(15))):\n",
    "        x_train = train[train['tfrecord'].isin(idxT)]\n",
    "        x_valid = train[~train['tfrecord'].isin(idxT)]\n",
    "        yield x_train.index, x_valid.index\n",
    "\n",
    "\n",
    "# Model\n",
    "model = XGBClassifier(n_estimators=300, random_state=SEED)\n",
    "\n",
    "grid_search = RandomizedSearchCV(param_distributions=param_grid, estimator=model, scoring='roc_auc', \n",
    "                                 cv=iter(get_idxs()), n_jobs=-1, n_iter=100, verbose=1)\n",
    "result = grid_search.fit(train[features], train['target'])\n",
    "\n",
    "print(\"Best: %f using %s\" % (result.best_score_, result.best_params_))\n",
    "means = result.cv_results_['mean_test_score']\n",
    "stds = result.cv_results_['std_test_score']\n",
    "params = result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "params = result.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df7aebb",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f118cbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = KFold(n_splits=config['N_USED_FOLDS'], shuffle=True, random_state=SEED)\n",
    "test['target'] = 0\n",
    "model_list = []\n",
    "\n",
    "for fold,(idxT, idxV) in enumerate(skf.split(np.arange(15))):\n",
    "    print(f'\\nFOLD: {fold+1}')\n",
    "    print(f'TRAIN: {idxT} VALID: {idxV}')\n",
    "    \n",
    "    train[f'fold_{fold+1}'] = train.apply(lambda x: 'train' if x['tfrecord'] in idxT else 'validation', axis=1)\n",
    "    x_train = train[train['tfrecord'].isin(idxT)]\n",
    "    y_train = x_train['target']\n",
    "    x_valid = train[~train['tfrecord'].isin(idxT)]\n",
    "    y_valid = x_valid['target']\n",
    "\n",
    "    model = XGBClassifier(**params, random_state=SEED)\n",
    "    \n",
    "    model.fit(x_train[features], y_train, eval_set=[(x_valid[features], y_valid)], eval_metric='auc', verbose=0)\n",
    "    model_list.append(model)\n",
    "\n",
    "    # Evaludation\n",
    "    preds = model.predict_proba(train[features])[:, 1]\n",
    "    train[f'pred_fold_{fold+1}'] = preds\n",
    "    \n",
    "    # Inference\n",
    "    preds = model.predict_proba(test[features])[:, 1]\n",
    "    test[f'pred_fold_{fold+1}'] = preds\n",
    "    test['target'] += preds / config['N_USED_FOLDS']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed78faa",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b52520",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    if x['fold_1'] == 'validation':\n",
    "        return x['pred_fold_1']\n",
    "    elif x['fold_2'] == 'validation':\n",
    "        return x['pred_fold_2']\n",
    "    elif x['fold_3'] == 'validation':\n",
    "        return x['pred_fold_3']\n",
    "    elif x['fold_4'] == 'validation':\n",
    "        return x['pred_fold_4']\n",
    "    elif x['fold_5'] == 'validation':\n",
    "        return x['pred_fold_5']\n",
    "    \n",
    "train['pred'] = train.apply(lambda x: func(x), axis=1)\n",
    "\n",
    "auc_oof = roc_auc_score(train['target'], train['pred'])\n",
    "print(f'Overall OOF AUC = {auc_oof:.3f}')\n",
    "\n",
    "df_oof = train[['image_name', 'target', 'pred']]\n",
    "df_oof.to_csv('oof.csv', index=False)\n",
    "display(df_oof.head())\n",
    "display(df_oof.describe().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f2e6b3",
   "metadata": {},
   "source": [
    "# Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124feb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_fold, model in enumerate(model_list):\n",
    "    print(f'Fold: {n_fold + 1}')\n",
    "    feature_importance = model.get_booster().get_score(importance_type='weight')\n",
    "\n",
    "    keys = list(feature_importance.keys())\n",
    "    values = list(feature_importance.values())\n",
    "\n",
    "    importance = pd.DataFrame(data=values, index=keys,\n",
    "                              columns=['score']).sort_values(by='score',\n",
    "                                                             ascending=False)\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    sns.barplot(x=importance.score.iloc[:20],\n",
    "                y=importance.index[:20],\n",
    "                orient='h',\n",
    "                palette='Reds_r')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ecfc86",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670e81fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(evaluate_model(train, config['N_USED_FOLDS']).style.applymap(color_map))\n",
    "display(evaluate_model_Subset(train, config['N_USED_FOLDS']).style.applymap(color_map))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2106d55e",
   "metadata": {},
   "source": [
    "# Adversarial Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a4cc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Adversarial set\n",
    "adv_train = train.copy()\n",
    "adv_test = test.copy()\n",
    "adv_train['dataset'] = 1\n",
    "adv_test['dataset'] = 0\n",
    "\n",
    "x_adv = pd.concat([adv_train, adv_test], axis=0)\n",
    "y_adv = x_adv['dataset']\n",
    "\n",
    "### Adversarial model\n",
    "model_adv = XGBClassifier(**params, random_state=SEED)\n",
    "\n",
    "model_adv.fit(x_adv[features], y_adv, eval_metric='auc', verbose=0)\n",
    "\n",
    "\n",
    "### Preds\n",
    "preds = model_adv.predict_proba(x_adv[features])[:, 1]\n",
    "\n",
    "\n",
    "### Plot feature importance and ROC AUC curve\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = model_adv.get_booster().get_score(importance_type='weight')\n",
    "\n",
    "keys = list(feature_importance.keys())\n",
    "values = list(feature_importance.values())\n",
    "\n",
    "importance = pd.DataFrame(data=values, index=keys,\n",
    "                          columns=['score']).sort_values(by='score',\n",
    "                                                         ascending=False)\n",
    "\n",
    "ax1.set_title('Feature Importances')\n",
    "sns.barplot(x=importance.score.iloc[:20],\n",
    "            y=importance.index[:20],\n",
    "            orient='h',\n",
    "            palette='Reds_r',\n",
    "            ax=ax1)\n",
    "\n",
    "# Plot ROC AUC curve\n",
    "fpr_train, tpr_train, _ = roc_curve(y_adv, preds)\n",
    "roc_auc_train = auc(fpr_train, tpr_train)\n",
    "\n",
    "ax2.set_title('ROC AUC curve')\n",
    "ax2.plot(fpr_train, tpr_train, color='blue', label='Adversarial AUC = %0.2f' % roc_auc_train)\n",
    "ax2.legend(loc = 'lower right')\n",
    "ax2.plot([0, 1], [0, 1],'r--')\n",
    "ax2.set_xlim([0, 1])\n",
    "ax2.set_ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d799e2b",
   "metadata": {},
   "source": [
    "# Visualize predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f265b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['pred'] = 0\n",
    "for n_fold in range(config['N_USED_FOLDS']):\n",
    "    train['pred'] += train[f'pred_fold_{n_fold+1}'] / config['N_FOLDS']\n",
    "\n",
    "print('Label/prediction distribution')\n",
    "print(f\"Train positive labels: {len(train[train['target'] > .5])}\")\n",
    "print(f\"Train positive predictions: {len(train[train['pred'] > .5])}\")\n",
    "print(f\"Train positive correct predictions: {len(train[(train['target'] > .5) & (train['pred'] > .5)])}\")\n",
    "    \n",
    "print('Top 10 samples')\n",
    "display(train[['image_name', 'sex', 'age_approx','anatom_site_general_challenge', 'diagnosis',\n",
    "                'target', 'pred'] + [c for c in train.columns if (c.startswith('pred_fold'))]].head(10))\n",
    "\n",
    "print('Top 10 positive samples')\n",
    "display(train[['image_name', 'sex', 'age_approx','anatom_site_general_challenge', 'diagnosis',\n",
    "                'target', 'pred'] + [c for c in train.columns if (c.startswith('pred_fold'))]].query('target == 1').head(10))\n",
    "\n",
    "print('Top 10 predicted positive samples')\n",
    "display(train[['image_name', 'sex', 'age_approx','anatom_site_general_challenge', 'diagnosis',\n",
    "                'target', 'pred'] + [c for c in train.columns if (c.startswith('pred_fold'))]].query('pred > .5').head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b2ae9a",
   "metadata": {},
   "source": [
    "# Visualize test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0999f847",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Test predictions {len(test[test['target'] > .5])}|{len(test[test['target'] <= .5])}\")\n",
    "\n",
    "print('Top 10 samples')\n",
    "display(test[['image_name', 'sex', 'age_approx','anatom_site_general_challenge', 'target'] + \n",
    "             [c for c in test.columns if (c.startswith('pred_fold'))]].head(10))\n",
    "\n",
    "print('Top 10 positive samples')\n",
    "display(test[['image_name', 'sex', 'age_approx','anatom_site_general_challenge', 'target'] + \n",
    "             [c for c in test.columns if (c.startswith('pred_fold'))]].query('target > .5').head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcac9d0",
   "metadata": {},
   "source": [
    "# Test set predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1613b4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(database_base_path + 'sample_submission.csv')\n",
    "submission['target'] = test['target']\n",
    "\n",
    "fig = plt.subplots(figsize=(20, 6))\n",
    "plt.hist(submission['target'], bins=100)\n",
    "plt.title('Preds', size=18)\n",
    "plt.show()\n",
    "\n",
    "display(submission.head(10))\n",
    "display(submission.describe())\n",
    "\n",
    "submission[['image_name', 'target']].to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
