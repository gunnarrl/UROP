{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a857e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "import collections\n",
    "import datetime as dt\n",
    "import os\n",
    "import itertools\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Dropout, Dense, Flatten, LSTM, MaxPooling1D, Bidirectional\n",
    "from keras.layers import Input, concatenate, Activation, GlobalMaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorflow.metrics import average_precision_at_k\n",
    "import keras_metrics as km\n",
    "\n",
    "pd.options.display.max_colwidth = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8d81fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_xy(df_train, df_test, vectorizer=None):\n",
    "    ''' \n",
    "    This function makes training and testing data from Term Frequency-Inverse Document Frequency (TFIDF)\n",
    "    vectors based on how often words appears in any given document and accross all documents.\n",
    "    '''\n",
    "    if vectorizer is None:\n",
    "        # make vectorizer to transform text documents to TFIDF vectors\n",
    "        vectorizer = TfidfVectorizer(ngram_range=(1, 2), token_pattern=r'\\b\\w+\\b')\n",
    "    \n",
    "    # fit vectorizer to training Tweets and transform training and testing Tweets to vectors\n",
    "    x_train = vectorizer.fit_transform(df_train.tweet.values.astype(str))\n",
    "    y_train = (df_train.sentiment == 'negative').values.astype(np.int)\n",
    "    x_test = vectorizer.transform(df_test.tweet.values.astype(str))\n",
    "    y_test = (df_test.sentiment == 'negative').values.astype(np.int)\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "def return_time(seconds):\n",
    "    '''\n",
    "    This function returns 'seconds' in \"h hours, m minutes, s seconds\" format.\n",
    "    '''\n",
    "    # create timedelta object (in HH:MM:SS format) from seconds and convert to string\n",
    "    d = str(dt.timedelta(seconds=round(seconds)))\n",
    "    \n",
    "    # slice timedelta string to select corresponding hours, minutes, and seconds\n",
    "    hours = d[:len(d)-6]\n",
    "    minutes = d[-5:-3]\n",
    "    seconds_left = d[-2:]\n",
    "    \n",
    "    # set and join time variables and corresponding time unit strings\n",
    "    periods = [('hours', hours), ('minutes', minutes), ('seconds', seconds_left)]\n",
    "    time_string = ' '.join('{} {}'.format(value, name)\n",
    "                        for name, value in periods\n",
    "                        if int(value) != 0)\n",
    "    \n",
    "    return time_string\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function plots the confusion matrix (cm) and normalized confusion matrix (in parentheses)\n",
    "    as calculated from sklearn.metrics.confusion_matrix().\n",
    "    \"\"\"\n",
    "    # normalize confusion matix\n",
    "    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    # create figure\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    # plot confusion matrix values\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "    # plot normalized confusion matrix values\n",
    "    for i, j in itertools.product(range(cm_norm.shape[0]), range(cm_norm.shape[1])):\n",
    "        plt.text(j, i+.07, '(' + format(cm_norm[i, j], '.2f') + ')',\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "    plt.grid(False)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "    \n",
    "def get_best_model(min_dfs, model_cv):\n",
    "    '''\n",
    "    This function finds the best min_df and max_df parameters used in TfidfVectorizer for GridSearchCV models,\n",
    "    fits model with best parameters on training data, and prints the sklearn.metrics.classification_report and \n",
    "    plots the confusion matrix of model results on test data.\n",
    "    '''\n",
    "    print('Finding best min_df...')\n",
    "    prev_score = 0\n",
    "    \n",
    "    def get_best_max_df(min_df, model_cv):\n",
    "        '''\n",
    "        This helper function finds the best max_df parameter and then fits model with best parameters on \n",
    "        training data, and prints the sklearn.metrics.classification_report and plots the confusion matrix \n",
    "        of model results on test data.\n",
    "        '''\n",
    "        print('Finding best max_df...')\n",
    "        prev_score = 0\n",
    "        \n",
    "        for max_df in np.arange(.1, 1.1, .1)[::-1]: # range of values to look for best max_df: [1, .9, .8, ... .1]\n",
    "            start = time.time()\n",
    "            \n",
    "            # make training and testing data for each max_df in range of values\n",
    "            x_train, y_train, x_test, y_test = make_xy(df_tweets_train, \n",
    "                                                       df_tweets_test,\n",
    "                                                       vectorizer=TfidfVectorizer(ngram_range=(1,2), \n",
    "                                                                                  token_pattern=r'\\b\\w+\\b',\n",
    "                                                                                  min_df=min_df,\n",
    "                                                                                  max_df=max_df))\n",
    "            \n",
    "            # fit model and compare to previous model to see if it's scoring metric is higher or lower\n",
    "            model_cv.fit(x_train, y_train)\n",
    "            curr_score = np.mean(model_cv.cv_results_['mean_test_score'])\n",
    "            \n",
    "            # print results and continue if current scoring metric is higher than previous\n",
    "            if round(curr_score, 3) > round(prev_score, 3):\n",
    "                print('max_df: {}, Mean CV {}: {:.3f}'.format(max_df, model_cv.scoring, curr_score))\n",
    "                \n",
    "            # if scoring metric lower than previous, stop, refit previous model and print results\n",
    "            else:\n",
    "                print('Best max_df: {}, Best mean CV {} {:.3f}'.format(max_df + 0.1, model_cv.scoring, prev_score))\n",
    "                print()\n",
    "                print('Fitting best model...')\n",
    "                print()\n",
    "                start = time.time()\n",
    "                x_train, y_train, x_test, y_test = make_xy(df_tweets_train, \n",
    "                                                           df_tweets_test,\n",
    "                                                           vectorizer=TfidfVectorizer(ngram_range=(1,2), \n",
    "                                                                                      token_pattern=r'\\b\\w+\\b',\n",
    "                                                                                      min_df=min_df,\n",
    "                                                                                      max_df=max_df + 0.1))\n",
    "                # fit best model, predict on test data, and print results\n",
    "                best_cv_model = model_cv.fit(x_train, y_train)\n",
    "                Y_pred = best_cv_model.predict(x_test)\n",
    "                y_pred = np.rint(Y_pred).flatten()\n",
    "                \n",
    "                print()\n",
    "                print(str(model_cv.estimator).split('(')[0] + ' Classification Report (Test Data)')\n",
    "                print('--------------------------------------------------------')\n",
    "                target_names = ['Positive', 'Negative']\n",
    "                print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "                cnf_matrix = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "                plot_confusion_matrix(cnf_matrix, classes=target_names,\n",
    "                                      title=str(model_cv.estimator).split('(')[0] \n",
    "                                            + ' Confusion Matrix \\n (Test Data)')\n",
    "                return\n",
    "            \n",
    "            prev_score = curr_score\n",
    "        \n",
    "    # find best min_df parameter in the same way as get_best_max_df above \n",
    "    for min_df in min_dfs:\n",
    "        start = time.time()\n",
    "        x_train, y_train, x_test, y_test = make_xy(df_tweets_train, \n",
    "                                                   df_tweets_test,\n",
    "                                                   vectorizer=TfidfVectorizer(ngram_range=(1,2), \n",
    "                                                                              token_pattern=r'\\b\\w+\\b',\n",
    "                                                                              min_df=min_df))\n",
    "        model_cv.fit(x_train, y_train)\n",
    "        curr_score = np.mean(model_cv.cv_results_['mean_test_score'])\n",
    "            \n",
    "        if round(curr_score, 3) > round(prev_score, 3):\n",
    "            print('min_df: {}, Mean CV {}: {:.3f}'.format(min_df, \n",
    "                                                          model_cv.scoring, \n",
    "                                                          curr_score))\n",
    "        else:\n",
    "            print('Best min_df: {}, Best mean CV {}: {:.3f}'.format(min_df - 1, \n",
    "                                                                    model_cv.scoring, \n",
    "                                                                    prev_score))\n",
    "            print()\n",
    "            return get_best_max_df(min_df-1, model_cv)\n",
    "        prev_score = curr_score\n",
    "        \n",
    "        \n",
    "def count_tokens(tweet):\n",
    "    '''\n",
    "    This function counts the number of tokens (words for which an Word2Vec vector exists) in a Tweet.\n",
    "    '''\n",
    "    count = 0\n",
    "    for word in tweet:\n",
    "        if word in x_vectors:\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f40a780",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled_tweets = pd.read_csv('../data/processed/labeled_tweets.csv')\n",
    "df_tweets_train, df_tweets_test = train_test_split(df_labeled_tweets, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca87ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled_tweets['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73078c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8a6870",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_stopwords = set(stopwords.words('spanish'))\n",
    "print('Length of nltk stopwords: {}'.format(len(nltk_stopwords)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3460b3f5",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes\n",
    "\n",
    "First we'll see how Multinomial Naive Bayes performs with and without removing stopwords, then we'll tune and cross validate the better performing model (based on f1-score) using GridsearchCV and then we'll evaluate it on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9291651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make testing and traning data with nltk stopwords removed\n",
    "x_train, y_train, x_test, y_test = make_xy(df_tweets_train, \n",
    "                                           df_tweets_test, \n",
    "                                           vectorizer=TfidfVectorizer(ngram_range=(1, 2), \n",
    "                                                                      token_pattern=r'\\b\\w+\\b',\n",
    "                                                                      stop_words=nltk_stopwords))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# create parameter grid of alphas to search through\n",
    "alphas = [.00001, .0001, .001, .01, .1, .5, .75, 1, 1.25, 5, 10, 50]\n",
    "mnb_param_grid = {'alpha': alphas}\n",
    "\n",
    "# build multinomial Naive Bayes model and cross validate using GridSearchCV\n",
    "mnb = MultinomialNB(fit_prior=False)\n",
    "mnb_cv = GridSearchCV(mnb, mnb_param_grid, scoring='f1', cv=10, n_jobs=-1)\n",
    "\n",
    "start = time.time()\n",
    "print()\n",
    "print(\"Cross validating model (with stopwords removed)...\")\n",
    "print()\n",
    "mnb_cv.fit(x_train, y_train)\n",
    "\n",
    "print(\"10 fold CV results\")\n",
    "print(\"------------------\")\n",
    "print(\"Multinomial Naive Bayes took {} to fit.\".format(return_time(time.time() - start)))\n",
    "print(\"Mean CV f1-score: {:.3f}\".format(np.mean(mnb_cv.cv_results_['mean_test_score'])))\n",
    "print(\"Standard deviation: {:.3f}\".format(np.mean(mnb_cv.cv_results_['std_test_score'])))\n",
    "\n",
    "\n",
    "# repeat without removing stopwords\n",
    "x_train, y_train, x_test, y_test = make_xy(df_tweets_train, df_tweets_test)\n",
    "\n",
    "start = time.time()\n",
    "print()\n",
    "print(\"Cross validating model (without removing stopwords)...\")\n",
    "print()\n",
    "mnb_cv.fit(x_train, y_train)\n",
    "\n",
    "print(\"10 fold CV results\")\n",
    "print(\"------------------\")\n",
    "print(\"Multinomial Naive Bayes took {} to fit.\".format(return_time(time.time() - start)))\n",
    "print(\"Mean CV f1-score: {:.3f}\".format(np.mean(mnb_cv.cv_results_['mean_test_score'])))\n",
    "print(\"Standard deviation: {:.3f}\".format(np.mean(mnb_cv.cv_results_['std_test_score'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a936dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find and fit best mulitnomial Naive Bayes model (without removing stopwords) and evaluate on test data\n",
    "min_dfs = range(1,10)\n",
    "get_best_model(min_dfs, mnb_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23873073",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "\n",
    "We'll repeat the same process above and see how Logistic Regression performs with and without removing stopwords, then we'll tune and cross validate the better performing model (based on f1-score) using GridsearchCV and then we'll evaluate it on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f34a89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make testing and traning data with nltk stopwords removed\n",
    "x_train, y_train, x_test, y_test = make_xy(df_tweets_train, \n",
    "                                           df_tweets_test, \n",
    "                                           vectorizer=TfidfVectorizer(ngram_range=(1, 2), \n",
    "                                                                      token_pattern=r'\\b\\w+\\b',\n",
    "                                                                      stop_words=nltk_stopwords))\n",
    "\n",
    "# create parameter grid of regularization constants to search through\n",
    "c_space = np.logspace(-4,4,10)\n",
    "lr_param_grid = {'C': c_space}\n",
    "\n",
    "# build logistic regression model and cross validate using GridSearchCV\n",
    "logreg = LogisticRegression(solver='lbfgs', max_iter=5000, random_state=7)\n",
    "logreg_cv = GridSearchCV(logreg, lr_param_grid, scoring='f1', cv=10, n_jobs=-1)\n",
    "\n",
    "start = time.time()\n",
    "print()\n",
    "print(\"Cross validating model (with stopwords removed)...\")\n",
    "print()\n",
    "logreg_cv.fit(x_train, y_train)\n",
    "\n",
    "print(\"10 fold CV results\")\n",
    "print(\"------------------\")\n",
    "print(\"Logistic Regression took {} to fit.\".format(return_time(time.time() - start)))\n",
    "print(\"Mean CV f1-score: {:.3f}\".format(np.mean(logreg_cv.cv_results_['mean_test_score'])))\n",
    "print(\"Standard deviation: {:.3f}\".format(np.mean(logreg_cv.cv_results_['std_test_score'])))\n",
    "\n",
    "# repeat without removing stopwords\n",
    "x_train, y_train, x_test, y_test = make_xy(df_tweets_train, df_tweets_test)\n",
    "\n",
    "start = time.time()\n",
    "print()\n",
    "print(\"Cross validating model (without removing stopwords)...\")\n",
    "print()\n",
    "logreg_cv.fit(x_train, y_train)\n",
    "\n",
    "print(\"10 fold CV results\")\n",
    "print(\"---------------------------------------------------------------------\")\n",
    "print(\"Logistic Regression took {} to fit.\".format(return_time(time.time() - start)))\n",
    "print(\"Mean CV f1-score: {:.3f}\".format(np.mean(logreg_cv.cv_results_['mean_test_score'])))\n",
    "print(\"Standard deviation: {:.3f}\".format(np.mean(logreg_cv.cv_results_['std_test_score'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36102dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find and fit best Logistic Regression model (without removing stopwords) and evaluate on test data\n",
    "get_best_model(min_dfs, logreg_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3799bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear memory for Word2Vec model\n",
    "del mnb, mnb_cv, logreg, logreg_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5984a5e1",
   "metadata": {},
   "source": [
    "### Word2Vec and CNN+LSTM Network\n",
    "\n",
    "Now we'll create the Word2Vec vectors from the Spanish vocabulary in our 'word2vec_tweets.txt' data then we'll create the Convoluted Neural Network (CNN) with a Long Short Term Memory (LSTM) network and use the Word2Vec vectors as features to train our CNN+LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8d9add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of Tweets from 'word2vec_tweets.txt' file to create word2vec vectors\n",
    "tweets_list = []\n",
    "with open('../data/processed/word2vec_tweets.txt', 'r', buffering=1000) as f:\n",
    "    for line in f:\n",
    "        tweets_list.append(line.strip().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5100001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set dimension of vectors and 'window' (number of words to consider to the left and right of center word)\n",
    "vector_size = 300\n",
    "window = 2\n",
    "\n",
    "word2vec_model = 'word2vec.model'\n",
    "\n",
    "print('Generating Word2Vec Vectors ..')\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# create word2vec model / vectors\n",
    "model = Word2Vec(sentences=tweets_list, size=vector_size, window=window, negative=20, iter=50, workers=4)\n",
    "\n",
    "print('Word2Vec Created in {}.'.format(return_time(time.time() - start)))\n",
    "\n",
    "# save model\n",
    "save_path = os.path.join('../models/', word2vec_model)\n",
    "model.save(save_path)\n",
    "print('Word2Vec Model saved at {}'.format(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ddba37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model if not already loaded and extract x_vectors to train CNN+LSTM model on\n",
    "model = Word2Vec.load('../models/word2vec.model')\n",
    "x_vectors = model.wv\n",
    "\n",
    "# clear memory for CNN+LSTM Network\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea250289",
   "metadata": {},
   "source": [
    "Now let's count the number of tokens (words that have a Word2Vec vector associated with it) in all the Tweets and make a histogram of them. This will help use determine a good number of tokens to consider in every Tweet when creating our features for our CNN+LSTM network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c813dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of tokens in tweets\n",
    "token_counts = [count_tokens(tweet) for tweet in tweets_list]\n",
    "\n",
    "# plot histogram of number of tokens in Tweets\n",
    "bins = np.arange(0,max(token_counts)) - 0.5\n",
    "plt.figure(figsize=(16, 8))\n",
    "sns.distplot(token_counts, kde=False, bins=bins, hist_kws=dict(edgecolor=\"k\", linewidth=2))\n",
    "plt.xlim(left=-0.5,right=max(token_counts))\n",
    "plt.xticks(np.array(range(0,max(token_counts))))\n",
    "plt.xlabel('Number of Tokens')\n",
    "plt.ylabel('Number of Tweets')\n",
    "plt.title('Histogram of Number of Tokens in Tweets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50213ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_tweets_lt31_tokens = len([num_tokens for num_tokens in token_counts if num_tokens < 31])/len(token_counts)\n",
    "print('Fraction of Tweets that contain 30 or less tokens: {:.4f}'.format(pct_tweets_lt31_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8eeb9f",
   "metadata": {},
   "source": [
    "We'll choose 30 to be our max number of token features to create for each Tweet as it covers over 99.9% of tokens in the Tweets and for memory purposes.\n",
    "\n",
    "Now lets create the training and testing data. y_train and y_test will be the same as used in the previous models, however x_train and x_test are now rank 3 tensors, $T_{x,y,z}$, where x is the number of documents/Tweets, y is the number of tokens/Word2Vec vectors, and z is the dimension of each Word2Vec vector/token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1636398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create rank 3 tensor from x_train and x_test data from labeled tweets and Word2Vec vectors for CNN+LSTM Network\n",
    "# y_test and y_train is the same as used in the previous models\n",
    "\n",
    "# set dimensions of tensor for x_train and x_test\n",
    "num_of_train_docs = len(df_tweets_train)\n",
    "num_of_test_docs = len(df_tweets_test)\n",
    "vector_size = 300\n",
    "max_no_tokens = 30\n",
    "\n",
    "# create rank 3 zero tensor for x_train and x_test\n",
    "x_train = np.zeros((num_of_train_docs, max_no_tokens, vector_size), dtype=K.floatx())\n",
    "x_test = np.zeros((num_of_test_docs, max_no_tokens, vector_size), dtype=K.floatx())\n",
    "y_train = (df_tweets_train.sentiment == 'negative').values.astype(np.int)\n",
    "y_test = (df_tweets_test.sentiment == 'negative').values.astype(np.int)\n",
    "# create tensors for x_train and x_test\n",
    "\n",
    "# loop over training Tweets (indices) and x_vectors and place Wvector in tensor where 'token' word is in Tweet\n",
    "train_indices = df_tweets_train.index\n",
    "for i, index in enumerate(train_indices):\n",
    "    for t, token in enumerate(tweets_list[index]):\n",
    "        if t >= max_no_tokens:\n",
    "            break\n",
    "      \n",
    "        if token not in x_vectors: \n",
    "            continue\n",
    "    \n",
    "        x_train[i, t, :] = x_vectors[token]\n",
    "\n",
    "# repeat above with x_test\n",
    "test_indices = df_tweets_test.index\n",
    "for i, index in enumerate(test_indices):\n",
    "    for t, token in enumerate(tweets_list[index]):\n",
    "        if t >= max_no_tokens:\n",
    "            break\n",
    "      \n",
    "        if token not in x_vectors:\n",
    "            continue\n",
    "    \n",
    "        x_test[i, t, :] = x_vectors[token]\n",
    "\n",
    "# clear memory\n",
    "del tweets_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18c8864",
   "metadata": {},
   "source": [
    "Now we'll build our CNN+LSTM network, then we'll train and evaluate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c2663c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "no_epochs = 100\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(100, kernel_size=3, activation='relu', padding='same',\n",
    "                 input_shape=(max_no_tokens, vector_size), strides=1))\n",
    "model.add(MaxPooling1D(pool_size=3))\n",
    "model.add(Conv1D(100, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(MaxPooling1D(pool_size=3))\n",
    "model.add(Conv1D(100, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(MaxPooling1D(pool_size=3))\n",
    "\n",
    "model.add(Bidirectional(LSTM(512, dropout=0.2, recurrent_dropout=0.3)))\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=[km.f1_score()])\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='logs/', histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "print('Network Architecture')\n",
    "print('--------------------')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a29964",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "print(\"CNN-LSTM results\")\n",
    "print(\"----------------\")\n",
    "\n",
    "# fit model, predict on test data, and print results\n",
    "model.fit(x_train, y_train, batch_size=batch_size, validation_split=0.2, shuffle=True, epochs=no_epochs, \n",
    "          callbacks=[tensorboard, EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=3)])\n",
    "\n",
    "print(\"CNN-LSTM took {} to fit.\".format(return_time(time.time() - start)))\n",
    "print()\n",
    "Y_pred = model.predict(x_test)\n",
    "y_pred = np.rint(Y_pred).flatten()\n",
    "\n",
    "print('Classification Report')\n",
    "target_names = ['Positive', 'Negative']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "plot_confusion_matrix(cnf_matrix, classes=target_names, title='CNN-LSTM Confusion Matrix \\n (Test Data)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d5ac3d",
   "metadata": {},
   "source": [
    "## Summary of Results and Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79af16b",
   "metadata": {},
   "source": [
    "In this project we applied the algorithms Multinomial Naive Bayes, Logistic Regression, and a combination of a Convoluted Neural Network (CNN) with a Long Short Term Memory (LSTM) network to a dataset containing 150K+ Spanish Tweets to classify Tweets as either positive or negative.\n",
    "\n",
    "The following table summarizes the evaluation metrics used:\n",
    "    \n",
    "| Model                   | Mean CV f1-score | Val f1-score | Test f1-score (neg/pos) | Training time |\n",
    "|-------------------------|------------------|--------------|-------------------------|---------------|\n",
    "| Multinomial Naive Bayes | .839 (.002)      |  N/A         | .86 / .50               | 0h 0m 12s     |\n",
    "| Logistic Regression     | .849 (.001)      |  N/A         | .87 / .60               | 1h 0m 35s     |\n",
    "| CNN + LSTM              | N/A              |  .897        | .89 / .79               | 0h 7m 14s     |\n",
    "\n",
    "    \n",
    "Based on the results summarized in the above table, the CNN + LSTM model performed best at classifying both negative and positive Tweets. Although we tuned the models on f1-score for negative Tweets as negative sentiments are often times more useful for improving a product or service, it's important to note the f1-score of positive Tweets as well, as this is an indication of how many correctly classified positive sentiments were made, and therefore the higher this number the less there are of positive Tweets classified as negative. This is where the CNN + LSTM model really shines, as it's f1-score is nearly .20 higher for positive Tweets, meaning that there are a lot less positive Tweets that are incorrectly classified as negative that one would have to sift through manually when determining areas for improvements in a product or service. For further details see the final report in /reports."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
