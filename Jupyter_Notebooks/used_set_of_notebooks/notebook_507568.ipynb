{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68452b9b",
   "metadata": {},
   "source": [
    "# CNN Classifier Training Example\n",
    "\n",
    "This notebook demonstrates a basic 4-layer CNN trained to classify spectra from galaxies and galaxies + SNe Ia within 2 weeks (plus/minus) of max light.\n",
    "\n",
    "Required software:\n",
    "* TensorFlow2\n",
    "* [desihub software](https://desi.lbl.gov/trac/wiki/Pipeline/GettingStarted/Laptop) (with usual dependencies).\n",
    "\n",
    "Adding more spectral categories is straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463e5a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from desispec.io import read_spectra\n",
    "from desitrip.preproc import rebin_flux, rescale_flux\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import platform\n",
    "\n",
    "mpl.rc('font', size=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0643e7",
   "metadata": {},
   "source": [
    "## Input Spectra\n",
    "\n",
    "Input DESI spectra, rebin and rescale them, and then divide them into training and test sets for the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd46138",
   "metadata": {},
   "outputs": [],
   "source": [
    "def condition_spectra(input_files):\n",
    "    \"\"\"Read DESI spectra, rebin to a subsampled logarithmic wavelength grid, and rescale.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_files : list or ndarray\n",
    "        List of FITS files on disk with DESI spectra.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    fluxes : ndarray\n",
    "        Array of fluxes rebinned to a logarithmic wavelength grid.\n",
    "    \"\"\"\n",
    "    fluxes = None\n",
    "    \n",
    "    for f in input_files:\n",
    "        spectra = read_spectra(f)\n",
    "        wave = spectra.wave['brz']\n",
    "        flux = spectra.flux['brz']\n",
    "        ivar = spectra.ivar['brz']\n",
    "\n",
    "        # Pre-condition: remove spectra with NaNs and zero flux values.\n",
    "        mask = np.isnan(flux).any(axis=1) | (np.count_nonzero(flux, axis=1) == 0)\n",
    "        mask_idx = np.argwhere(mask)\n",
    "        flux = np.delete(flux, mask_idx, axis=0)\n",
    "        ivar = np.delete(ivar, mask_idx, axis=0)\n",
    "\n",
    "        # Rebin and rescale fluxes so that each is normalized between 0 and 1.\n",
    "        rewave, reflux, reivar = rebin_flux(wave, flux, ivar, minwave=3600., maxwave=9800., nbins=150, log=True, clip=True)\n",
    "        rsflux = rescale_flux(reflux)\n",
    "\n",
    "        if fluxes is None:\n",
    "            fluxes = rsflux\n",
    "        else:\n",
    "            fluxes = np.concatenate((fluxes, rsflux))\n",
    "    \n",
    "    return fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b603351",
   "metadata": {},
   "outputs": [],
   "source": [
    "host_truth = sorted(glob('../../../../bgs/150s/hosts/*truth.fits'))\n",
    "host_coadd = sorted(glob('../../../../bgs/150s/hosts/*coadd.fits'))\n",
    "host_flux  = condition_spectra(host_coadd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc4fabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "snia_truth = sorted(glob('../../../../bgs/150s/sn_ia/hsiao/*truth.fits'))\n",
    "snia_files = sorted(glob('../../../../bgs/150s/sn_ia/hsiao/*coadd.fits'))\n",
    "snia_flux  = condition_spectra(snia_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c417a48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nhost, nbins = host_flux.shape\n",
    "nsnia, nbins = snia_flux.shape\n",
    "\n",
    "nhost, nsnia, nbins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e47db65",
   "metadata": {},
   "source": [
    "### Plot Spectra to Check Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c590c2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2, figsize=(14,5), sharex=True, sharey=True)\n",
    "\n",
    "for i in range(0,500):\n",
    "    \n",
    "    ax = axes[0]\n",
    "    ax.plot(host_flux[i], alpha=0.2)\n",
    "\n",
    "    ax = axes[1]\n",
    "    ax.plot(snia_flux[i], alpha=0.2)\n",
    "    \n",
    "axes[0].set_title('host spectra')\n",
    "axes[1].set_title('host + SN spectra')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d604f5",
   "metadata": {},
   "source": [
    "### Set up Training Sets and Labels\n",
    "\n",
    "0. \"host\" spectra based only on BGS templates\n",
    "1. \"snia\" spectra based on BGS + SN Ia templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f831cc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.concatenate([host_flux, snia_flux]).reshape(-1, nbins, 1)\n",
    "y = np.concatenate([np.zeros(nhost), np.ones(nsnia)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fc05af",
   "metadata": {},
   "source": [
    "## CNN Network Setup\n",
    "\n",
    "Train network with TensorFlow+Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ececeec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import utils, regularizers, callbacks, backend\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, ZeroPadding1D, BatchNormalization, Flatten, Reshape, Conv1D, MaxPooling1D, Dropout, Add, LSTM, Embedding\n",
    "from tensorflow.keras.initializers import glorot_normal, glorot_uniform\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0cff4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def network(input_shape, learning_rate=0.0005, reg=0.0032, dropout=0.7436, seed=None):\n",
    "    \"\"\"Define the CNN structure.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_shape : int\n",
    "        Shape of the input spectra.\n",
    "    learning_rate : float\n",
    "        Learning rate.\n",
    "    reg : float\n",
    "        Regularization factor.\n",
    "    dropout : float\n",
    "        Dropout rate.\n",
    "    seed : int\n",
    "        Seed of initializer.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    model : tensorflow.keras.Model\n",
    "        A model instance of the network.\n",
    "    \"\"\"\n",
    "    X_input = Input(input_shape, name='Input_Spec')\n",
    "    \n",
    "    X_input = Input(input_shape, name='Input_Spec')\n",
    "\n",
    "    # First convolutional layer.\n",
    "    with backend.name_scope('Conv_1'):\n",
    "        X = Conv1D(filters=8, kernel_size=5, strides=1, padding='same',\n",
    "                   kernel_regularizer=regularizers.l2(reg),\n",
    "                   bias_initializer='zeros',\n",
    "                   kernel_initializer=glorot_normal(seed))(X_input)\n",
    "        X = BatchNormalization(axis=2)(X)\n",
    "        X = Activation('relu')(X)\n",
    "        X = MaxPooling1D(pool_size= 2)(X)\n",
    "\n",
    "    # Second convolutional layer.\n",
    "    with backend.name_scope('Conv_2'):\n",
    "        X = Conv1D(filters=16, kernel_size=5, strides=1, padding='same',\n",
    "                   kernel_regularizer=regularizers.l2(reg),\n",
    "                   bias_initializer='zeros',\n",
    "                   kernel_initializer=glorot_normal(seed))(X)\n",
    "        X = BatchNormalization(axis=2)(X)\n",
    "        X = Activation('relu')(X)\n",
    "        X = MaxPooling1D(2)(X)\n",
    "        \n",
    "    # Third convolutional layer.\n",
    "    with backend.name_scope('Conv_3'):\n",
    "        X = Conv1D(filters=32, kernel_size=5, strides=1, padding='same',\n",
    "                   kernel_regularizer=regularizers.l2(reg),\n",
    "                   bias_initializer='zeros',\n",
    "                   kernel_initializer=glorot_normal(seed))(X)\n",
    "        X = BatchNormalization(axis=2)(X)\n",
    "        X = Activation('relu')(X)\n",
    "        X = MaxPooling1D(2)(X)\n",
    "        \n",
    "    # Fourth convolutional layer.\n",
    "    with backend.name_scope('Conv_4'):\n",
    "        X = Conv1D(filters=64, kernel_size=5, strides=1, padding='same',\n",
    "                   kernel_regularizer=regularizers.l2(reg),\n",
    "                   bias_initializer='zeros',\n",
    "                   kernel_initializer=glorot_normal(seed))(X)\n",
    "        X = BatchNormalization(axis=2)(X)\n",
    "        X = Activation('relu')(X)\n",
    "        X = MaxPooling1D(2)(X)\n",
    "\n",
    "    # Flatten to fully connected dense layer.\n",
    "    with backend.name_scope('Dense_Layer'):\n",
    "        X = Flatten()(X)\n",
    "        X = Dense(256, kernel_regularizer=regularizers.l2(reg),\n",
    "                  activation='relu')(X)\n",
    "        X = Dropout(rate=dropout, seed=seed)(X)\n",
    "    \n",
    "    # Output layer with sigmoid activation.\n",
    "    with backend.name_scope('Output_Layer'):\n",
    "        X = Dense(1, kernel_regularizer=regularizers.l2(reg),\n",
    "              activation='sigmoid',name='Output_Classes')(X)\n",
    "\n",
    "    model = Model(inputs=X_input, outputs=X, name='SNnet')\n",
    "    \n",
    "    # Set up optimizer, loss function, and optimization metrics.\n",
    "    model.compile(optimizer=Adam(lr=learning_rate), loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acbdafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = network((nbins, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ea5a73",
   "metadata": {},
   "source": [
    "## Train and Test\n",
    "\n",
    "Split the data into training and testing (validation) samples and fit the network weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81937c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
    "hist = model.fit(x_train, y_train, batch_size=65, epochs=30, validation_data=(x_test, y_test), shuffle=True)\n",
    "\n",
    "# permute = np.random.permutation(len(y))\n",
    "# l = len(x)\n",
    "# hist = model.fit(x[permute][:l], y[permute][:l], batch_size=64, epochs=30, validation_split=0.25, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23e17e8",
   "metadata": {},
   "source": [
    "## Performance\n",
    "\n",
    "### Loss and Accuracy\n",
    "\n",
    "Plot loss and accuracy as a function of epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6efb280",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2, figsize=(12,5), sharex=True)\n",
    "\n",
    "nepoch = len(hist.history['loss'])\n",
    "epochs = np.arange(1, nepoch+1)\n",
    "\n",
    "ax = axes[0]\n",
    "ax.plot(epochs, hist.history['accuracy'], label='acc')\n",
    "ax.plot(epochs, hist.history['val_accuracy'], label='val_acc')\n",
    "ax.set(xlabel='training epoch',\n",
    "       ylabel='accuracy',\n",
    "       xlim=(0, nepoch),\n",
    "       ylim=(0.5,1.0))\n",
    "ax.legend(fontsize=12, loc='best')\n",
    "ax.grid(ls=':')\n",
    "\n",
    "ax = axes[1]\n",
    "ax.plot(epochs, hist.history['loss'], label='loss')\n",
    "ax.plot(epochs, hist.history['val_loss'], label='val_loss')\n",
    "ax.set(xlabel='training epoch',\n",
    "       ylabel='loss',\n",
    "       xlim=(0, nepoch),\n",
    "       ylim=(0.,2.0))\n",
    "ax.legend(fontsize=12, loc='best')\n",
    "ax.grid(ls=':')\n",
    "\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe82eadf",
   "metadata": {},
   "source": [
    "### ROC Curve and Precision-Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745920f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = np.random.choice(a=len(y), size=int(0.2 * len(y)))\n",
    "# x_test = x[idx]\n",
    "# y_test = y[idx]\n",
    "y_pred = model.predict(x_test).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13478ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "pre, rec, _ = precision_recall_curve(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc0b5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2, figsize=(10,5), sharex=True, sharey=True)\n",
    "\n",
    "ax = axes[0]\n",
    "ax.plot(fpr, tpr, lw=2)\n",
    "ax.plot((0,1), (0,1), 'k--', alpha=0.3)\n",
    "ax.grid(ls=':')\n",
    "ax.set(xlim=(-0.01,1.01), xlabel='FPR = FP / (FP + TN)',\n",
    "       ylim=(-0.01,1.01), ylabel='recall (TPR) = TP / (TP + FN)',\n",
    "       title='ROC: AUC = {:.3f}'.format(auc(fpr, tpr)),\n",
    "       aspect='equal')\n",
    "\n",
    "ax = axes[1]\n",
    "ax.plot(rec, pre, lw=2)\n",
    "f_scores = np.linspace(0.1, 0.9, num=5)\n",
    "lines = []\n",
    "labels = []\n",
    "for f_score in f_scores:\n",
    "    x_ = np.linspace(0.01, 1)\n",
    "    y_ = f_score * x_ / (2 * x_ - f_score)\n",
    "    l, = plt.plot(x_[y_ >= 0], y_[y_ >= 0], color='k', ls='--', alpha=0.3)\n",
    "    ax.annotate(' $F_{{1}}={0:0.1f}$'.format(f_score), xy=(1.01, y_[45]-0.02),\n",
    "                fontsize=12, alpha=0.8)\n",
    "ax.grid(ls=':')\n",
    "ax.set(xlabel='recall (TPR) = TP / (TP + FN)',\n",
    "       ylabel='precision = TP / (TP + FP)',\n",
    "       title='Average precision = {:.3f}'.format(average_precision_score(y_test, y_pred)),\n",
    "       aspect='equal')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0faf04a6",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d7fa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2, figsize=(12,5), sharex=True)\n",
    "\n",
    "ax = axes[0]\n",
    "ybins = np.linspace(0,1,41)\n",
    "ax.hist(y_test, bins=ybins, alpha=0.5, label='true label')\n",
    "ax.hist(y_pred[y_test==0], bins=ybins, alpha=0.5, label='prediction (host)')\n",
    "ax.hist(y_pred[y_test==1], bins=ybins, alpha=0.5, label='prediction (SN Ia)')\n",
    "ax.grid(ls=':')\n",
    "ax.set(xlabel='label probability',\n",
    "       xlim=(-0.01, 1.01),\n",
    "       ylabel='count')\n",
    "ax.legend(fontsize=12, loc='best')\n",
    "\n",
    "ax = axes[1]\n",
    "ybins = np.linspace(0,1,41)\n",
    "ax.hist(y_test, bins=ybins, alpha=0.5, label='true label')\n",
    "ax.hist(y_pred[y_test==0], bins=ybins, alpha=0.5, label='prediction (host)')\n",
    "ax.hist(y_pred[y_test==1], bins=ybins, alpha=0.5, label='prediction (SN Ia)', log=True)\n",
    "ax.grid(ls=':')\n",
    "ax.set(xlabel='label probability',\n",
    "       xlim=(-0.01, 1.01),\n",
    "       ylabel='count')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c703de89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred > 0.99)\n",
    "cmnorm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d06301e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(6,5))\n",
    "\n",
    "im = ax.imshow(cmnorm, cmap='Blues', vmin=0, vmax=1)\n",
    "cb = ax.figure.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "cb.set_label('correct label probability')\n",
    "\n",
    "ax.set(aspect='equal',\n",
    "       xlabel='predicted label',\n",
    "       xticks=np.arange(cm.shape[1]),\n",
    "       xticklabels=['host', 'SN Ia'],\n",
    "       ylabel='true label',\n",
    "       yticks=np.arange(cm.shape[1]),\n",
    "       yticklabels=['host', 'SN Ia'])\n",
    "\n",
    "thresh = 0.5*cm.max()\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        ax.text(j, i, '{:.3f}\\n({:d})'.format(cmnorm[i,j], cm[i,j]),\n",
    "                ha='center', va='center',\n",
    "                color='black' if cm[i,j] < thresh else 'white')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a15d90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('twolabel_cnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07921594",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('twolabel_cnn.h5')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
