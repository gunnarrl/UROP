{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ff9d170",
   "metadata": {},
   "source": [
    "# Visualizing the Predictions of Binary Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7af947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and setup\n",
    "import numpy as np\n",
    "from scipy.special import expit as logistic_sigmoid\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn.metrics\n",
    "import sklearn.linear_model\n",
    "import sklearn.tree\n",
    "import sklearn.neighbors\n",
    "\n",
    "%matplotlib inline\n",
    "np.set_printoptions(suppress=True, precision=2)\n",
    "plt.style.use('seaborn') # pretty matplotlib plots\n",
    "\n",
    "sns.set(font_scale=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17969935",
   "metadata": {},
   "source": [
    "## Define simple dataset of points in 2D space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2368de56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_2d_dataset(N=100, noise_stddev=0.1, random_state=0):\n",
    "    random_state = np.random.RandomState(int(random_state))\n",
    "\n",
    "    mA_2 = np.asarray([1, 0])\n",
    "    covA_22 = np.square(noise_stddev) * np.eye(2)\n",
    "    \n",
    "    mB_2 = np.asarray([0, 0])\n",
    "    covB_22 = np.square(noise_stddev) * np.eye(2)\n",
    "\n",
    "    mC_2 = np.asarray([0, 1])\n",
    "    covC_22 = np.square(noise_stddev) * np.eye(2)\n",
    "\n",
    "    # Draw data from 3 \"Gaussian\" blobs\n",
    "    xA_N2 = random_state.multivariate_normal(mA_2, covA_22, size=N)\n",
    "    xB_N2 = random_state.multivariate_normal(mB_2, covB_22, size=N)\n",
    "    xC_N2 = random_state.multivariate_normal(mC_2, covC_22, size=N)\n",
    "\n",
    "    x_N2 = np.vstack([xA_N2, xB_N2, xC_N2])\n",
    "    y_N = np.hstack([np.ones(xA_N2.shape[0]), np.zeros(xB_N2.shape[0]), np.ones(xC_N2.shape[0])])\n",
    "    \n",
    "    return x_N2, y_N"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44e0a6d",
   "metadata": {},
   "source": [
    "## Create the dataset with 100 points per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fddf5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_N2, y_N = create_2d_dataset(N=100, noise_stddev=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09fef2b",
   "metadata": {},
   "source": [
    "## Define function to plot data as scatterpoints in 2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24238fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pretty_data_colored_by_labels(x_N2, y_N):\n",
    "    plt.plot(x_N2[y_N==0,0], x_N2[y_N==0,1], color='r', marker='x', linestyle='', markersize=5, mew=2);\n",
    "    plt.plot(x_N2[y_N==1,0], x_N2[y_N==1,1], color='b', marker='+', linestyle='', markersize=8, mew=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2467f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pretty_data_colored_by_labels(x_N2, y_N);\n",
    "plt.xlabel('x1');\n",
    "plt.ylabel('x2');\n",
    "plt.gca().set_aspect(1.0);\n",
    "plt.xticks([0, 1, 2]);\n",
    "plt.yticks([0, 1, 2]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1021d091",
   "metadata": {},
   "source": [
    "## Define function to make pretty plots of predicted probability color fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20ff2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pretty_probabilities_for_clf(\n",
    "        clf,\n",
    "        do_show_colorbar=False,\n",
    "        x1_ticks=np.asarray([0, 2, 4]),\n",
    "        x2_ticks=np.asarray([0, 2, 4]),\n",
    "        c_levels=np.linspace(0, 1, 100),\n",
    "        c_ticks=np.asarray([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]),\n",
    "        x1_grid=np.linspace(-1, 2.3, 100),\n",
    "        x2_grid=np.linspace(-1, 2.3, 100)):\n",
    "    cur_ax = plt.gca()\n",
    "    \n",
    "    G = x1_grid.size\n",
    "    H = x2_grid.size\n",
    "    \n",
    "    # Get regular grid of G x H points, where each point is an (x1, x2) location\n",
    "    x1_GH, x2_GH = np.meshgrid(x1_grid, x2_grid)\n",
    "    \n",
    "    # Combine the x1 and x2 values into one array\n",
    "    # Flattened into M = G x H rows\n",
    "    # Each row of x_M2 is a 2D vector [x_m1, x_m2]\n",
    "    x_M2 = np.hstack([x1_GH.flatten()[:,np.newaxis], x2_GH.flatten()[:,np.newaxis]])\n",
    "    \n",
    "    # Predict proba for each point in the flattened grid\n",
    "    yproba1_M = clf.predict_proba(x_M2)[:,1]\n",
    "    \n",
    "    # Reshape the M probas into the GxH 2D field\n",
    "    yproba1_GH = np.reshape(yproba1_M, x1_GH.shape)\n",
    "    \n",
    "    cmap = plt.cm.RdYlBu\n",
    "    my_contourf_h = plt.contourf(x1_GH, x2_GH, yproba1_GH, levels=c_levels, vmin=0, vmax=1.0, cmap=cmap)\n",
    "    \n",
    "    plt.xticks(x1_ticks, x1_ticks);\n",
    "    plt.yticks(x2_ticks, x2_ticks);\n",
    "    \n",
    "    if do_show_colorbar:\n",
    "        left, bottom, width, height = plt.gca().get_position().bounds\n",
    "        cax = plt.gcf().add_axes([left+1.1*width, bottom, 0.03, height])\n",
    "        plt.colorbar(my_contourf_h, orientation='vertical', cax=cax, ticks=c_ticks);\n",
    "        plt.sca(cur_ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a5a26e",
   "metadata": {},
   "source": [
    "# Define function to visualize hard decisions made as threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa608fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pretty_decision_boundaries_for_clf(\n",
    "        clf,\n",
    "        threshold=0.5,\n",
    "        do_show_colorbar=False,\n",
    "        x1_ticks=np.asarray([0, 2, 4]),\n",
    "        x2_ticks=np.asarray([0, 2, 4]),\n",
    "        c_levels=np.linspace(0, 1, 100),\n",
    "        c_ticks=np.asarray([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]),\n",
    "        x1_grid=np.linspace(-1, 2.3, 100),\n",
    "        x2_grid=np.linspace(-1, 2.3, 100)):\n",
    "    cur_ax = plt.gca()\n",
    "    \n",
    "    G = x1_grid.size\n",
    "    H = x2_grid.size\n",
    "    \n",
    "    # Get regular grid of G x H points, where each point is an (x1, x2) location\n",
    "    x1_GH, x2_GH = np.meshgrid(x1_grid, x2_grid)\n",
    "    \n",
    "    # Combine the x1 and x2 values into one array\n",
    "    # Flattened into M = G x H rows\n",
    "    # Each row of x_M2 is a 2D vector [x_m1, x_m2]\n",
    "    x_M2 = np.hstack([x1_GH.flatten()[:,np.newaxis], x2_GH.flatten()[:,np.newaxis]])\n",
    "    \n",
    "    # Predict proba for each point in the flattened grid\n",
    "    yproba1_M = clf.predict_proba(x_M2)[:,1]\n",
    "    yhat_M = yproba1_M >= threshold\n",
    "    \n",
    "    # Reshape the M probas into the GxH 2D field\n",
    "    yhat_GH = np.reshape(yhat_M, x1_GH.shape)\n",
    "    \n",
    "    cmap = plt.cm.RdYlBu\n",
    "    my_contourf_h = plt.contourf(x1_GH, x2_GH, yhat_GH, levels=c_levels, vmin=0, vmax=1.0, cmap=cmap)\n",
    "    \n",
    "    plt.xticks(x1_ticks, x1_ticks);\n",
    "    plt.yticks(x2_ticks, x2_ticks);\n",
    "    \n",
    "    if do_show_colorbar:\n",
    "        left, bottom, width, height = plt.gca().get_position().bounds\n",
    "        cax = plt.gcf().add_axes([left+1.1*width, bottom, 0.03, height])\n",
    "        plt.colorbar(my_contourf_h, orientation='vertical', cax=cax, ticks=c_ticks);\n",
    "        plt.sca(cur_ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67c8e19",
   "metadata": {},
   "source": [
    "## Decision Tree: predicted proba (colors) over 2D plane of (x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782b7a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples_leaf_grid = [1000, 100, 50, 10, 5]\n",
    "ncols = len(min_samples_leaf_grid)\n",
    "\n",
    "fig_h, axes = plt.subplots(nrows=1, ncols=ncols, figsize=(5 * ncols, 5))\n",
    "\n",
    "is_last = False\n",
    "for ii, min_samples_leaf in enumerate(min_samples_leaf_grid):\n",
    "    if ii == ncols - 1:\n",
    "        is_last = True\n",
    "    plt.sca(axes[ii])\n",
    "    dtree = sklearn.tree.DecisionTreeClassifier(min_samples_leaf=min_samples_leaf)\n",
    "    dtree.fit(x_N2, y_N)\n",
    "    \n",
    "    plot_pretty_probabilities_for_clf(dtree, do_show_colorbar=is_last);\n",
    "    plot_pretty_data_colored_by_labels(x_N2, y_N);\n",
    "    \n",
    "    plt.title(\"min_samples_leaf=%d\" % min_samples_leaf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f5d942",
   "metadata": {},
   "source": [
    "## Decision Tree: hard binary decisions (colors) over 2D plane of (x1, x2)\n",
    "\n",
    "Using Threshold: 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde63394",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples_leaf_grid = [1000, 100, 50, 10, 5]\n",
    "ncols = len(min_samples_leaf_grid)\n",
    "\n",
    "fig_h, axes = plt.subplots(nrows=1, ncols=ncols, figsize=(5 * ncols, 5))\n",
    "\n",
    "is_last = False\n",
    "for ii, min_samples_leaf in enumerate(min_samples_leaf_grid):\n",
    "    if ii == ncols - 1:\n",
    "        is_last = True\n",
    "    plt.sca(axes[ii])\n",
    "    dtree = sklearn.tree.DecisionTreeClassifier(min_samples_leaf=min_samples_leaf)\n",
    "    dtree.fit(x_N2, y_N)\n",
    "    err_rate = np.mean(np.logical_xor(y_N, dtree.predict(x_N2)))\n",
    "    \n",
    "    plot_pretty_decision_boundaries_for_clf(dtree, do_show_colorbar=is_last);\n",
    "    plot_pretty_data_colored_by_labels(x_N2, y_N);\n",
    "    \n",
    "    plt.title(\"min_samples_leaf=%d\\ntrain_error_rate %.3f\" % (min_samples_leaf, err_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd267ca1",
   "metadata": {},
   "source": [
    "# KNN: predicted proba (colors) over 2D plane of x1, x2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6442b399",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors_grid = [y_N.size, 100, 10, 3,  1]\n",
    "ncols = len(n_neighbors_grid)\n",
    "\n",
    "fig_h, axes = plt.subplots(nrows=1, ncols=ncols, figsize=(5 * ncols, 5))\n",
    "\n",
    "is_last = False\n",
    "for ii, n_neighbors in enumerate(n_neighbors_grid):\n",
    "    if ii == ncols - 1:\n",
    "        is_last = True\n",
    "    plt.sca(axes[ii])\n",
    "    clf = sklearn.neighbors.KNeighborsClassifier(n_neighbors=n_neighbors, algorithm='brute')\n",
    "    clf.fit(x_N2, y_N)\n",
    "    \n",
    "    plot_pretty_probabilities_for_clf(clf, do_show_colorbar=is_last);\n",
    "    plot_pretty_data_colored_by_labels(x_N2, y_N);\n",
    "    \n",
    "    plt.title(\"n_neighbors=%d\" % n_neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41242964",
   "metadata": {},
   "source": [
    "## KNN: hard binary decisions (colors) over 2D plane of (x1, x2)\n",
    "\n",
    "Using Threshold: 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dcbe08",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors_grid = [y_N.size, 100, 10, 3,  1]\n",
    "ncols = len(n_neighbors_grid)\n",
    "\n",
    "fig_h, axes = plt.subplots(nrows=1, ncols=ncols, figsize=(5 * ncols, 5))\n",
    "\n",
    "is_last = False\n",
    "for ii, n_neighbors in enumerate(n_neighbors_grid):\n",
    "    if ii == ncols - 1:\n",
    "        is_last = True\n",
    "    plt.sca(axes[ii])\n",
    "    clf = sklearn.neighbors.KNeighborsClassifier(n_neighbors=n_neighbors, algorithm='brute')\n",
    "    clf.fit(x_N2, y_N)\n",
    "    err_rate = np.mean(np.logical_xor(y_N, clf.predict(x_N2)))\n",
    "    \n",
    "    plot_pretty_decision_boundaries_for_clf(clf, do_show_colorbar=is_last);\n",
    "    plot_pretty_data_colored_by_labels(x_N2, y_N);\n",
    "    \n",
    "    plt.title(\"n_neighbors=%d\\ntrain_error_rate %.3f\" % (n_neighbors, err_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427bb3eb",
   "metadata": {},
   "source": [
    "# Show Logistic Regression predicted proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1bdde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_grid = np.asarray([0.0001, 0.01, 1, 100, 10000])\n",
    "ncols = len(C_grid)\n",
    "\n",
    "fig_h, axes = plt.subplots(nrows=1, ncols=ncols, figsize=(5 * ncols, 5))\n",
    "\n",
    "is_last = False\n",
    "for ii, C in enumerate(C_grid):\n",
    "    if ii == ncols - 1:\n",
    "        is_last = True\n",
    "    plt.sca(axes[ii])\n",
    "    clf = sklearn.linear_model.LogisticRegression(C=C)\n",
    "    clf.fit(x_N2, y_N)\n",
    "    if ii == 0:\n",
    "        clf0 = clf\n",
    "    \n",
    "    plot_pretty_probabilities_for_clf(clf, do_show_colorbar=is_last);\n",
    "    plot_pretty_data_colored_by_labels(x_N2, y_N);\n",
    "    \n",
    "    plt.title(\"C=%.2g\" % C)\n",
    "    print(np.hstack([clf.coef_.flatten(), np.atleast_1d(clf.intercept_)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fcc177",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_sigmoid(0.01 * -0.4 * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14434b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf0.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5702f8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf0.predict_proba(np.asarray([[-.4, -.4]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9e931c",
   "metadata": {},
   "source": [
    "## Decision Tree: hard binary decisions (colors) over 2D plane of (x1, x2)\n",
    "\n",
    "Using Threshold: 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d6ee5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_grid = np.asarray([0.0001, 0.01, 1, 100, 10000])\n",
    "ncols = len(C_grid)\n",
    "\n",
    "fig_h, axes = plt.subplots(nrows=1, ncols=ncols, figsize=(5 * ncols, 5))\n",
    "\n",
    "is_last = False\n",
    "for ii, C in enumerate(C_grid):\n",
    "    if ii == ncols - 1:\n",
    "        is_last = True\n",
    "    plt.sca(axes[ii])\n",
    "    clf = sklearn.linear_model.LogisticRegression(C=C)\n",
    "    clf.fit(x_N2, y_N)\n",
    "    train_err_rate = np.mean(np.logical_xor(y_N, clf.predict(x_N2)))\n",
    "    plot_pretty_decision_boundaries_for_clf(clf, 0.5, do_show_colorbar=is_last);\n",
    "    plot_pretty_data_colored_by_labels(x_N2, y_N);\n",
    "    \n",
    "    plt.title(\"C=%.2g\\ntrain_error_rate %.3f\" % (C, train_err_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eef8578",
   "metadata": {},
   "source": [
    "## Show specific plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65d23b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_grid = [[0, 1, 0], [0 , 5, 0], [0, 1, -1]]\n",
    "ncols = len(w_grid)\n",
    "\n",
    "fig_h, axes = plt.subplots(nrows=1, ncols=ncols, figsize=(5 * ncols, 5))\n",
    "\n",
    "clf = sklearn.linear_model.LogisticRegression(C=10.0)\n",
    "clf.fit(x_N2, y_N)\n",
    "\n",
    "is_last = False\n",
    "for ii, w_G in enumerate(w_grid):\n",
    "    if ii == ncols - 1:\n",
    "        is_last = True\n",
    "\n",
    "    clf.coef_[:] = w_G[:-1]\n",
    "    clf.intercept_ = w_G[-1]\n",
    "        \n",
    "    plt.sca(axes[ii])\n",
    "    plot_pretty_probabilities_for_clf(clf, do_show_colorbar=is_last);\n",
    "    plot_pretty_data_colored_by_labels(x_N2, y_N);\n",
    "    \n",
    "    plt.title(\"w_G= %s\" % ' '.join(['%d' % wval for wval in w_G]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d329823",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_grid = [[1, 1, 0], [1, 1, +0.8], [1, 1, -0.8]]\n",
    "ncols = len(w_grid)\n",
    "\n",
    "fig_h, axes = plt.subplots(nrows=1, ncols=ncols, figsize=(5 * ncols, 5))\n",
    "\n",
    "clf = sklearn.linear_model.LogisticRegression(C=10.0)\n",
    "clf.fit(x_N2, y_N)\n",
    "\n",
    "is_last = False\n",
    "for ii, w_G in enumerate(w_grid):\n",
    "    if ii == ncols - 1:\n",
    "        is_last = True\n",
    "\n",
    "    clf.coef_[:] = w_G[:-1]\n",
    "    clf.intercept_ = w_G[-1]\n",
    "        \n",
    "    plt.sca(axes[ii])\n",
    "    plot_pretty_probabilities_for_clf(clf, do_show_colorbar=is_last);\n",
    "    plot_pretty_data_colored_by_labels(x_N2, y_N);\n",
    "    \n",
    "    plt.title(\"w_G= %s\" % ' '.join(['%.1f' % wval for wval in w_G]))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
