{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ef43b1c",
   "metadata": {},
   "source": [
    "# Supervised Learning and K Nearest Neighbors Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7d0b48",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "We will be using customer churn data from the telecom industry for this week's exercises. The data file is called \n",
    "`Orange_Telecom_Churn_Data.csv`. We will load this data together, do some preprocessing, and use K-nearest neighbors to predict customer churn based on account characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f12734f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "data_path = ['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1441dc6d",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "* Begin by importing the data. Examine the columns and data.\n",
    "* Notice that the data contains a state, area code, and phone number. Do you think these are good features to use when building a machine learning model? Why or why not? \n",
    "\n",
    "We will not be using them, so they can be dropped from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7859bc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Import the data using the file path\n",
    "# filepath = os.sep.join(data_path + ['Orange_Telecom_Churn_Data.csv'])\n",
    "data = pd.read_csv('./data/Orange_Telecom_Churn_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cb6b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3505a7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove extraneous columns\n",
    "data.drop(['state', 'area_code', 'phone_number'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7828ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d754c2bc",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "* Notice that some of the columns are categorical data and some are floats. These features will need to be numerically encoded using one of the methods from the lecture.\n",
    "* Finally, remember from the lecture that K-nearest neighbors requires scaled data. Scale the data using one of the scaling methods discussed in the lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d931d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "\n",
    "for col in ['intl_plan', 'voice_mail_plan', 'churned']:\n",
    "    data[col] = lb.fit_transform(data[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92e77a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mute the sklearn warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', module='sklearn')\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "msc = MinMaxScaler()\n",
    "\n",
    "data = pd.DataFrame(msc.fit_transform(data),  # this is an np.array, not a dataframe.\n",
    "                    columns=data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35141a83",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "* Separate the feature columns (everything except `churned`) from the label (`churned`). This will create two tables.\n",
    "* Fit a K-nearest neighbors model with a value of `k=3` to this data and predict the outcome on the same data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbe810d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all the columns that don't contain the label\n",
    "x_cols = [x for x in data.columns if x != 'churned']\n",
    "\n",
    "# Split the data into two dataframes\n",
    "X_data = data[x_cols]\n",
    "y_data = data['churned']\n",
    "\n",
    "# # alternatively:\n",
    "# X_data = data.copy()\n",
    "# y_data = X_data.pop('churned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbdfd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "knn = knn.fit(X_data, y_data)\n",
    "\n",
    "y_pred = knn.predict(X_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4462788",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Ways to measure error haven't been discussed in class yet, but accuracy is an easy one to understand--it is simply the percent of labels that were correctly predicted (either true or false). \n",
    "\n",
    "* Write a function to calculate accuracy using the actual and predicted labels.\n",
    "* Using the function, calculate the accuracy of this K-nearest neighbors model on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3209f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the % of values that were correctly predicted\n",
    "\n",
    "def accuracy(real, predict):\n",
    "    return sum(y_data == y_pred) / float(real.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d028dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy(y_data, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c75fb6e",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "* Fit the K-nearest neighbors model again with `n_neighbors=3` but this time use distance for the weights. Calculate the accuracy using the function you created above. \n",
    "* Fit another K-nearest neighbors model. This time use uniform weights but set the power parameter for the Minkowski distance metric to be 1 (`p=1`) i.e. Manhattan Distance.\n",
    "\n",
    "When weighted distances are used for part 1 of this question, a value of 1.0 should be returned for the accuracy. Why do you think this is? *Hint:* we are predicting on the data and with KNN the model *is* the data. We will learn how to avoid this pitfall in the next lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d16f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Student writes code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538dd69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3, weights='distance')\n",
    "\n",
    "knn = knn.fit(X_data, y_data)\n",
    "\n",
    "y_pred = knn.predict(X_data)\n",
    "\n",
    "print(accuracy(y_data, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ebe275",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "* Fit a K-nearest neighbors model using values of `k` (`n_neighbors`) ranging from 1 to 20. Use uniform weights (the default). The coefficient for the Minkowski distance (`p`) can be set to either 1 or 2--just be consistent. Store the accuracy and the value of `k` used from each of these fits in a list or dictionary.\n",
    "* Plot (or view the table of) the `accuracy` vs `k`. What do you notice happens when `k=1`? Why do you think this is? *Hint:* it's for the same reason discussed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa268ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Student writes code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7754d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "list =[]\n",
    "for k in range(1,20):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k,p=2)\n",
    "    knn = knn.fit(X_data, y_data)\n",
    "    y_pred = knn.predict(X_data)\n",
    "    list.append(accuracy(y_data, y_pred))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfa57cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a8a1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d6f095",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('k')\n",
    "plt.ylabel('accuracy')\n",
    "plt.plot(list)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
