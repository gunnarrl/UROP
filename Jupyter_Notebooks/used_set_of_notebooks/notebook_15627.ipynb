{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30055cca",
   "metadata": {},
   "source": [
    "# Unsupervised Classification With Autoencoder\n",
    "## Arda Mavi\n",
    "[Arda Mavi - GitHub](https://github.com/ardamavi)\n",
    "\n",
    "### Summary:\n",
    "In this project, we use autoencoders for classification as unsupervised machine learning algorithms with Deep Learning.<br/>\n",
    "#### Give the 'images' and 'number of the class', then let the program do the rest!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe2d401",
   "metadata": {},
   "source": [
    "# First we look up what is autoencoder:\n",
    "[Building Autoencoders in Keras](https://blog.keras.io/building-autoencoders-in-keras.html)\n",
    "## Example of image denoising:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bd2fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arda Mavi\n",
    "# Unsupervised Classification With Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836f303c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2798c3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Dataset:\n",
    "def get_dataset():\n",
    "    (X, Y), (X_test, Y_test) = mnist.load_data()\n",
    "    \n",
    "    X = X.astype('float32') / 255.\n",
    "    X_test = X_test.astype('float32') / 255.\n",
    "    X = np.reshape(X, (len(X), 28, 28, 1))\n",
    "    X_test = np.reshape(X_test, (len(X_test), 28, 28, 1))\n",
    "    \n",
    "    # Add noise:\n",
    "    noise_factor = 0.4\n",
    "    X_train_noisy = X + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X.shape) \n",
    "    X_test_noisy = X_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_test.shape) \n",
    "\n",
    "    X_train_noisy = np.clip(X_train_noisy, 0., 1.)\n",
    "    X_test_noisy = np.clip(X_test_noisy, 0., 1.)\n",
    "    \n",
    "    return X, X_test, Y, Y_test, X_train_noisy, X_test_noisy\n",
    "\n",
    "X, X_test, Y, Y_test, X_train_noisy, X_test_noisy = get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb36a753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# About Dataset:\n",
    "print('Training shape:', X.shape)\n",
    "print(X.shape[0], 'sample,',X.shape[1] ,'x',X.shape[2] ,'size grayscale image.\\n')\n",
    "print('Test shape:', X_test.shape)\n",
    "print(X_test.shape[0], 'sample,',X_test.shape[1] ,'x',X_test.shape[2] ,'size grayscale image.\\n')\n",
    "\n",
    "print('Examples:')\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(1, n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i)\n",
    "    plt.imshow(X[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + n)\n",
    "    plt.imshow(X_train_noisy[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ea7cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Learning Model:\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "input_img = Input(shape=(28, 28, 1))\n",
    "\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "# Output Shape: 4x4x8\n",
    "\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "# Output Shape: 28x28x1\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec02aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoints:\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "checkpoints = []\n",
    "#checkpoints.append(TensorBoard(log_dir='/Checkpoints/logs'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3cda26",
   "metadata": {},
   "source": [
    "#### For training model with Data Augmentation run this cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e69249e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates live data:\n",
    "# For better yield. The duration of the training is extended.\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "generated_data = ImageDataGenerator(featurewise_center=False, samplewise_center=False, featurewise_std_normalization=False, samplewise_std_normalization=False, zca_whitening=False, rotation_range=0,  width_shift_range=0.1, height_shift_range=0.1, horizontal_flip = True, vertical_flip = False)\n",
    "generated_data.fit(X_train_noisy)\n",
    "\n",
    "autoencoder.fit_generator(generated_data.flow(X_train_noisy, X, batch_size=batch_size), steps_per_epoch=X.shape[0], epochs=epochs, validation_data=(X_test_noisy, X_test), callbacks=checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d687410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Model:\n",
    "epochs = 3\n",
    "batch_size = 100\n",
    "autoencoder.fit(X_train_noisy, X, batch_size=batch_size, epochs=epochs, validation_data=(X_test_noisy, X_test), shuffle=True, callbacks=checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b571feec",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder.predict(X_test_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68eb68b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(1, n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i)\n",
    "    plt.imshow(X_test_noisy[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6a76e7",
   "metadata": {},
   "source": [
    "# Now we use autoencoder for unsupervised classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c2cd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the number of classes:\n",
    "num_class = 10\n",
    "\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Conv2DTranspose, Dense, Activation, Lambda, Reshape, Flatten\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "# Custom classifier function:\n",
    "def classifier_func(x):\n",
    "    return x+x*K.one_hot(K.argmax(x, axis=1), num_classes=num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2b6a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Learning Model:\n",
    "\n",
    "inputs = Input(shape=(28, 28, 1))\n",
    "#Encoder:\n",
    "conv_1 = Conv2D(32, (3,3), strides=(1,1))(inputs)\n",
    "act_1 = Activation('relu')(conv_1)\n",
    "maxpool_1 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(act_1)\n",
    "\n",
    "conv_2 = Conv2D(64, (3,3), strides=(1,1), padding='same')(maxpool_1)\n",
    "act_2 = Activation('relu')(conv_2)\n",
    "maxpool_2 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(act_2)\n",
    "# Output Shape: 6x6x64\n",
    "    \n",
    "flat_1 = Flatten()(maxpool_2)\n",
    "\n",
    "fc_1 = Dense(256)(flat_1)\n",
    "act_3 = Activation('relu')(fc_1)\n",
    "\n",
    "fc_2 = Dense(128)(act_3)\n",
    "act_4 = Activation('relu')(fc_2)\n",
    "\n",
    "fc_3 = Dense(num_class)(act_4)\n",
    "\n",
    "act_class = Lambda(classifier_func, output_shape=(num_class,))(fc_3)\n",
    "# Output Shape: 10\n",
    "\n",
    "#Decoder:\n",
    "fc_4 = Dense(256)(act_class)\n",
    "act_5 = Activation('relu')(fc_4)\n",
    "\n",
    "fc_5 = Dense(2304)(act_5)\n",
    "act_6 = Activation('relu')(fc_5)\n",
    "reshape_1 = Reshape((6,6,64))(act_6)\n",
    "\n",
    "upsample_1 = UpSampling2D((2, 2))(reshape_1)\n",
    "deconv_1 = Conv2DTranspose(64, (3, 3), strides=(1, 1))(upsample_1)\n",
    "act_7 = Activation('relu')(deconv_1)\n",
    "\n",
    "upsample_2 = UpSampling2D((2, 2))(act_7)\n",
    "deconv_2 = Conv2DTranspose(32, (3, 3), strides=(1, 1))(upsample_2)\n",
    "act_8 = Activation('relu')(deconv_2)\n",
    "\n",
    "conv_3 = Conv2D(1, (3, 3), strides=(1, 1))(act_8)\n",
    "act_9 = Activation('sigmoid')(conv_3)\n",
    "# Output Shape: 28x28x1\n",
    "\n",
    "autoencoder = Model(inputs, act_9)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131d3e12",
   "metadata": {},
   "source": [
    "#### For training model with Data Augmentation run this cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e64a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates live data:\n",
    "# For better yield. The duration of the training is extended.\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "generated_data = ImageDataGenerator(featurewise_center=False, samplewise_center=False, featurewise_std_normalization=False, samplewise_std_normalization=False, zca_whitening=False, rotation_range=0,  width_shift_range=0.1, height_shift_range=0.1, horizontal_flip = True, vertical_flip = False)\n",
    "generated_data.fit(X)\n",
    "\n",
    "autoencoder.fit_generator(generated_data.flow(X, X, batch_size=batch_size), steps_per_epoch=X.shape[0], epochs=epochs, validation_data=(X_test, X_test), callbacks=checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32516fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Model:\n",
    "epochs = 4\n",
    "batch_size = 100\n",
    "autoencoder.fit(X, X, batch_size=batch_size, epochs=epochs, validation_data=(X_test, X_test), shuffle=True, callbacks=checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6a5138",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1469ec9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(1, n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i)\n",
    "    plt.imshow(X_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c699e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split autoencoder:\n",
    "encoder = Model(inputs, act_class)\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d33f383",
   "metadata": {},
   "source": [
    "#### Use the code to finding which cluster:\n",
    "`np.argmax(<encoder_output>, axis=0)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbafb54",
   "metadata": {},
   "source": [
    "### Now we look up result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3429750a",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = encoder.predict(X)\n",
    "\n",
    "class_dict = np.zeros((num_class, num_class))\n",
    "for i, sample in enumerate(Y):\n",
    "    class_dict[np.argmax(encode[i], axis=0)][sample] += 1\n",
    "    \n",
    "print(class_dict)\n",
    "    \n",
    "neuron_class = np.zeros((num_class))\n",
    "for i in range(num_class):\n",
    "    neuron_class[i] = np.argmax(class_dict[i], axis=0)\n",
    "\n",
    "print(neuron_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3884a9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = encoder.predict(X_test)\n",
    "\n",
    "predicted = np.argmax(encode, axis=1)\n",
    "for i, sample in enumerate(predicted):\n",
    "    predicted[i] = neuron_class[predicted[i]]\n",
    "\n",
    "comparison = Y_test == predicted\n",
    "loss = 1 - np.sum(comparison.astype(int))/Y_test.shape[0]\n",
    "\n",
    "print('Loss:', loss)\n",
    "print('Examples:')\n",
    "for i in range(10):\n",
    "    plt.imshow(X_test[i].reshape(28,28), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    neuron = np.argmax(encode[i], axis=0)\n",
    "    print('Class:', Y_test[i], '- Model\\'s Output Class:', neuron_class[neuron])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb2f5ed",
   "metadata": {},
   "source": [
    "### Thats it! Thank you!\n",
    "#### Still in development"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
