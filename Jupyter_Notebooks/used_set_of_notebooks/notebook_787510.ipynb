{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30af839c",
   "metadata": {},
   "source": [
    "# Leaf Classfication \n",
    "A For CZ4041 Machine Learning Assignment from PT3 in AY2018/2019 Semester 2.\n",
    "The group members are:\n",
    "- LIU Yiqing\n",
    "- LUO Bingyi\n",
    "- TENG He Xu\n",
    "- WANG Jia\n",
    "- YI Zhiyue\n",
    "- ZHAO Ziru"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76be575a",
   "metadata": {},
   "source": [
    "## Import necessary libraries and Define Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcd2cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Convolution2D, MaxPooling2D, Flatten, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "IMAGE_PATH = 'data/images/'\n",
    "LABEL_PATH = 'data/'\n",
    "TRAIN_FILE_NAME = 'train.csv'\n",
    "TEST_FILE_NAME = 'test.csv'\n",
    "COMMON_HEIGHT_WIDTH = 50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5eb5f1",
   "metadata": {},
   "source": [
    "## Load Images and Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dbda94",
   "metadata": {},
   "source": [
    "Load images from the given path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a59cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(path):\n",
    "    images = os.listdir(path)\n",
    "    loaded_images = []\n",
    "    \n",
    "    for i in range(num):\n",
    "        loaded_images.append(path + images[i])\n",
    "    return loaded_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc822eff",
   "metadata": {},
   "source": [
    "Resize the images to a uniformed size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6603d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_resize(file_name, hw):\n",
    "    image = cv2.imread(file_name, 0)\n",
    "    new_img = cv2.resize(image, (int(hw), int(hw)))\n",
    "    return np.reshape(new_img, (int(hw), int(hw), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a580ad",
   "metadata": {},
   "source": [
    "Load labels from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece6cab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(file_path):\n",
    "    labels = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        csv_reader = csv.reader(file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        # Skip the first line\n",
    "        next(csv_reader)\n",
    "        # Remove empty lines\n",
    "        lines = list(line for line in csv_reader if line)\n",
    "        for line in lines:\n",
    "            label = {}\n",
    "            label['id'] = int(line[0])\n",
    "            label['species'] = line[1]\n",
    "            labels.append(label)\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1698cef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_images_and_labels(images, labels):\n",
    "    id = []\n",
    "    x = []\n",
    "    y = []\n",
    "    for image in images:\n",
    "        for label in labels:\n",
    "            if image['id'] == label['id']:\n",
    "                x.append(image['image'])\n",
    "                y.append(label['species'])\n",
    "                id.append( image['id'])\n",
    "    \n",
    "    return {\n",
    "        'id': np.array(id),\n",
    "        'x': np.array(x),\n",
    "        'y': np.array(y)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffd032c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def constructDicitionary(labels):\n",
    "    uniqueLabels = list(set(list(map(lambda x: x[\"species\"], labels))))\n",
    "    dictionary = []\n",
    "    for i in range(len(uniqueLabels)):\n",
    "        dictionary.append({\n",
    "            \"number\": i,\n",
    "            \"text\": uniqueLabels[i]\n",
    "        })\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce47f239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(dictionary, text):\n",
    "    for i in range(len(dictionary)):\n",
    "        if dictionary[i][\"text\"] == text:\n",
    "            return dictionary[i][\"number\"]\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b51530",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(dictionary, number):\n",
    "    for i in range(len(dictionary)):\n",
    "        if dictionary[i][\"number\"] == number:\n",
    "            return dictionary[i][\"text\"]\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87150e0a",
   "metadata": {},
   "source": [
    "### Execution Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c803396",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = load_images(IMAGE_PATH)\n",
    "train_labels = load_labels(LABEL_PATH + TRAIN_FILE_NAME)\n",
    "resized_images = []\n",
    "\n",
    "dictionary = constructDicitionary(train_labels)\n",
    "\n",
    "for i in range(len(images)):\n",
    "    resized_image = image_resize(images[i], COMMON_HEIGHT_WIDTH)\n",
    "    record = {}\n",
    "    record['id'] = int(images[i].split('.')[0].split('/')[2])\n",
    "    record['image'] = resized_image\n",
    "    resized_images.append(record)\n",
    "    \n",
    "## for img in resized_images:\n",
    "##     plt.imshow(img)\n",
    "##     plt.show()\n",
    "\n",
    "for j in range(len(train_labels)):\n",
    "    train_labels[j][\"species\"] = encode(dictionary, train_labels[j][\"species\"])\n",
    "\n",
    "train_data = combine_images_and_labels(resized_images, train_labels)\n",
    "train_x = train_data['x']\n",
    "train_y = train_data['y']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76e24db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(train_y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0a5e9c",
   "metadata": {},
   "source": [
    "### Construct model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b4b5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3, input_shape=(50, 50, 1)))       \n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(99, activation=tf.nn.softmax))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd38e020",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749ac410",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "print(np.shape(train_x))\n",
    "print(np.shape(train_y))\n",
    "model.fit(train_x, train_y, epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c621b67",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebe6696",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = load_labels(LABEL_PATH + TEST_FILE_NAME)\n",
    "\n",
    "for k in range(len(test_labels)):\n",
    "    test_labels[k][\"species\"] = encode(dictionary, test_labels[k][\"species\"])\n",
    "\n",
    "test_data = combine_images_and_labels(resized_images, test_labels)\n",
    "\n",
    "test_x = test_data['x']\n",
    "test_y = test_data['y']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830e94df",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.predict(test_x)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "with open('submission.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['id']\n",
    "    \n",
    "    label_fieldslist = list(set(list(map(lambda x: x[\"species\"], train_labels))))\n",
    "    for i in range(len(label_fieldslist)):\n",
    "        fieldnames.append(decode(dictionary, label_fieldslist[i]))\n",
    "        \n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    \n",
    "    for n in range(len(output)):\n",
    "        #print(np.argmax(output[n]))\n",
    "        row = {}\n",
    "        for field in fieldnames:\n",
    "            species = decode(dictionary, np.argmax(output[n]))\n",
    "            row[\"id\"] = test_data['id'][n]\n",
    "            row[species] = 1\n",
    "            if field not in [\"id\", species]:\n",
    "                row[field] = 0\n",
    "        writer.writerow(row)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
