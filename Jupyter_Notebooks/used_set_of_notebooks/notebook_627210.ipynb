{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8781a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import numpy as np\n",
    "import os\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c31f983",
   "metadata": {},
   "source": [
    "# Building a Variational Autoencoder in MXNet\n",
    "\n",
    "#### Xiaoyu Lu,  July 5th, 2017\n",
    "\n",
    "This tutorial guides you through the process of building a variational encoder in MXNet. In this notebook we'll focus on an example using the MNIST handwritten digit recognition dataset. Refer to [Auto-Encoding Variational Bayes](https://arxiv.org/abs/1312.6114/) for more details on the model description.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad71dc2",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "To complete this tutorial, we need following python packages:\n",
    "\n",
    "- numpy, matplotlib "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53db5be5",
   "metadata": {},
   "source": [
    "## 1. Loading the Data\n",
    "\n",
    "We first load the MNIST dataset, which contains 60000 training and 10000 test examples. The following code imports required modules and loads the data. These images are stored in a 4-D matrix with shape (`batch_size, num_channels, width, height`). For the MNIST dataset, there is only one color channel, and both width and height are 28, so we reshape each image as a 28x28 array. See below for a visualization:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81855c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = mx.test_utils.get_mnist()\n",
    "image = np.reshape(mnist['train_data'],(60000,28*28))\n",
    "label = image\n",
    "image_test = np.reshape(mnist['test_data'],(10000,28*28))\n",
    "label_test = image_test\n",
    "[N,features] = np.shape(image)          #number of examples and features\n",
    "print(N,features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a7097d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples = 5\n",
    "idx = np.random.choice(len(mnist['train_data']), nsamples)\n",
    "_, axarr = plt.subplots(1, nsamples, sharex='col', sharey='row',figsize=(12,3))\n",
    "\n",
    "for i,j in enumerate(idx):\n",
    "    axarr[i].imshow(np.reshape(image[j,:],(28,28)), interpolation='nearest', cmap=cm.Greys)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8655dd",
   "metadata": {},
   "source": [
    "We can optionally save the parameters in the directory variable 'model_prefix'. We first create data iterators for MXNet, with each batch of data containing 100 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80be5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prefix = None\n",
    "\n",
    "batch_size = 100\n",
    "latent_dim = 5\n",
    "nd_iter = mx.io.NDArrayIter(data={'data':image},label={'loss_label':label},\n",
    "                            batch_size = batch_size)\n",
    "nd_iter_test = mx.io.NDArrayIter(data={'data':image_test},label={'loss_label':label_test},\n",
    "                            batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01d6849",
   "metadata": {},
   "source": [
    "## 2.  Building the Network Architecture\n",
    "\n",
    "### 2.1 Gaussian MLP as encoder\n",
    "Next we constuct the neural network, as in the [paper](https://arxiv.org/abs/1312.6114/), we use *Multilayer Perceptron (MLP)* for both the encoder and decoder. For encoder, a Gaussian MLP is used as follows:\n",
    "\n",
    "\\begin{align}\n",
    "\\log q_{\\phi}(z|x) &= \\log \\mathcal{N}(z:\\mu,\\sigma^2I) \\\\\n",
    "\\textit{ where } \\mu &= W_2h+b_2, \\log \\sigma^2 = W_3h+b_3\\\\\n",
    "h &= \\tanh(W_1x+b_1)\n",
    "\\end{align}\n",
    "\n",
    "where $\\{W_1,W_2,W_3,b_1,b_2,b_3\\}$ are the weights and biases of the MLP.\n",
    "Note below that `encoder_mu`(`mu`) and `encoder_logvar`(`logvar`) are symbols. So, we can use `get_internals()` to get the values of them, after which we can sample the latent variable $z$.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003b24aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define data and loss labels as symbols \n",
    "data = mx.sym.var('data')\n",
    "loss_label = mx.sym.var('loss_label')\n",
    "\n",
    "## define fully connected and activation layers for the encoder, where we used tanh activation function.\n",
    "encoder_h  = mx.sym.FullyConnected(data=data, name=\"encoder_h\",num_hidden=400)\n",
    "act_h = mx.sym.Activation(data=encoder_h, act_type=\"tanh\",name=\"activation_h\")\n",
    "\n",
    "## define mu and log variance which are the fully connected layers of the previous activation layer\n",
    "mu  = mx.sym.FullyConnected(data=act_h, name=\"mu\",num_hidden = latent_dim)\n",
    "logvar  = mx.sym.FullyConnected(data=act_h, name=\"logvar\",num_hidden = latent_dim)\n",
    "\n",
    "## sample the latent variables z according to Normal(mu,var)\n",
    "z = mu + mx.symbol.broadcast_mul(mx.symbol.exp(0.5 * logvar), \n",
    "                                 mx.symbol.random_normal(loc=0, scale=1, shape=(batch_size, latent_dim)),\n",
    "                                 name=\"z\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf326f0a",
   "metadata": {},
   "source": [
    "### 2.2 Bernoulli MLP as decoder\n",
    "\n",
    "In this case let $p_\\theta(x|z)$ be a multivariate Bernoulli whose probabilities are computed from $z$ with a feed forward neural network with a single hidden layer:\n",
    "\n",
    "\\begin{align}\n",
    "\\log p(x|z) &= \\sum_{i=1}^D x_i\\log y_i + (1-x_i)\\log (1-y_i) \\\\\n",
    "\\textit{ where }  y &= f_\\sigma(W_5\\tanh (W_4z+b_4)+b_5)\n",
    "\\end{align}\n",
    "\n",
    "where $f_\\sigma(\\dot)$ is the elementwise sigmoid activation function, $\\{W_4,W_5,b_4,b_5\\}$ are the weights and biases of the decoder MLP. A Bernouilli likelihood is suitable for this type of data but you can easily extend it to other likelihood types by parsing into the argument `likelihood` in the `VAE` class, see section 4 for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa845d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define fully connected and tanh activation layers for the decoder\n",
    "decoder_z = mx.sym.FullyConnected(data=z, name=\"decoder_z\",num_hidden=400)\n",
    "act_z = mx.sym.Activation(data=decoder_z, act_type=\"tanh\",name=\"activation_z\")\n",
    "\n",
    "# define the output layer with sigmoid activation function, where the dimension is equal to the input dimension\n",
    "decoder_x = mx.sym.FullyConnected(data=act_z, name=\"decoder_x\",num_hidden=features)\n",
    "y = mx.sym.Activation(data=decoder_x, act_type=\"sigmoid\",name='activation_x')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d588ca",
   "metadata": {},
   "source": [
    "### 2.3 Joint Loss Function for the Encoder and the Decoder\n",
    "\n",
    "The variational lower bound also called evidence lower bound (ELBO) can be estimated as:\n",
    "\n",
    "\\begin{align}\n",
    "\\mathcal{L}(\\theta,\\phi;x_{(i)}) \\approx \\frac{1}{2}\\left(1+\\log ((\\sigma_j^{(i)})^2)-(\\mu_j^{(i)})^2-(\\sigma_j^{(i)})^2\\right) + \\log p_\\theta(x^{(i)}|z^{(i)})\n",
    "\\end{align}\n",
    "\n",
    "where the first term is the KL divergence of the approximate posterior from the prior, and the second term is an expected negative reconstruction error. We would like to maximize this lower bound, so we can define the loss to be $-\\mathcal{L}$(minus ELBO) for MXNet to minimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42b1ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the objective loss function that needs to be minimized\n",
    "KL = 0.5*mx.symbol.sum(1+logvar-pow( mu,2)-mx.symbol.exp(logvar),axis=1)\n",
    "loss = -mx.symbol.sum(mx.symbol.broadcast_mul(loss_label,mx.symbol.log(y)) \n",
    "                      + mx.symbol.broadcast_mul(1-loss_label,mx.symbol.log(1-y)),axis=1)-KL\n",
    "output = mx.symbol.MakeLoss(sum(loss),name='loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e21cb09",
   "metadata": {},
   "source": [
    "## 3. Training the model\n",
    "\n",
    "Now, we can define the model and train it. First we will initilize the weights and the biases to be Gaussian(0,0.01), and then use stochastic gradient descent for optimization. To warm start the training, one may also initilize with pre-trainined parameters `arg_params` using `init=mx.initializer.Load(arg_params)`. \n",
    "\n",
    "To save intermediate results, we can optionally use `epoch_end_callback = mx.callback.do_checkpoint(model_prefix, 1)` which saves the parameters to the path given by model_prefix, and with period every $1$ epoch. To assess the performance, we output $-\\mathcal{L}$(minus ELBO) after each epoch, with the command `eval_metric = 'Loss'` which is defined above. We will also plot the training loss for mini batches by accessing the log and saving it to a list, and then parsing it to the argument `batch_end_callback`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222cbf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the log\n",
    "nd_iter.reset()\n",
    "logging.getLogger().setLevel(logging.DEBUG)  \n",
    "\n",
    "# define function to trave back training loss\n",
    "def log_to_list(period, lst):\n",
    "    def _callback(param):\n",
    "        \"\"\"The checkpoint function.\"\"\"\n",
    "        if param.nbatch % period == 0:\n",
    "            name, value = param.eval_metric.get()\n",
    "            lst.append(value)\n",
    "    return _callback\n",
    "\n",
    "# define the model\n",
    "model = mx.mod.Module(\n",
    "    symbol = output ,\n",
    "    data_names=['data'],\n",
    "    label_names = ['loss_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07fa56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model, save training loss as a list.\n",
    "training_loss=list()\n",
    "\n",
    "# initilize the parameters for training using Normal.\n",
    "init = mx.init.Normal(0.01)\n",
    "model.fit(nd_iter,  # train data\n",
    "          initializer=init,\n",
    "          # if eval_data is supplied, test loss will also be reported\n",
    "          # eval_data = nd_iter_test,\n",
    "          optimizer='sgd',  # use SGD to train\n",
    "          optimizer_params={'learning_rate':1e-3,'wd':1e-2},  \n",
    "          # save parameters for each epoch if model_prefix is supplied\n",
    "          epoch_end_callback = None if model_prefix==None else mx.callback.do_checkpoint(model_prefix, 1),\n",
    "          batch_end_callback = log_to_list(N/batch_size,training_loss), \n",
    "          num_epoch=100,\n",
    "          eval_metric = 'Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb80fc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "ELBO = [-training_loss[i] for i in range(len(training_loss))]\n",
    "plt.plot(ELBO)\n",
    "plt.ylabel('ELBO');plt.xlabel('epoch');plt.title(\"training curve for mini batches\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b4be3b",
   "metadata": {},
   "source": [
    "As expected, the ELBO is monotonically increasing over epoch, and we reproduced the results given in the paper [Auto-Encoding Variational Bayes](https://arxiv.org/abs/1312.6114/). Now we can extract/load the parameters and then feed the network forward to calculate $y$ which is the reconstructed image, and we can also calculate the ELBO for the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9030e368",
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_params = model.get_params()[0]\n",
    "nd_iter_test.reset()\n",
    "test_batch = nd_iter_test.next()\n",
    "\n",
    "# if saved the parameters, can load them using `load_checkpoint` method at e.g. 100th epoch\n",
    "# sym, arg_params, aux_params = mx.model.load_checkpoint(model_prefix, 100)\n",
    "# assert sym.tojson() == output.tojson()\n",
    "\n",
    "e = y.bind(mx.cpu(), {'data': test_batch.data[0],\n",
    "                     'encoder_h_weight': arg_params['encoder_h_weight'],\n",
    "                     'encoder_h_bias': arg_params['encoder_h_bias'],\n",
    "                     'mu_weight': arg_params['mu_weight'],\n",
    "                     'mu_bias': arg_params['mu_bias'],\n",
    "                     'logvar_weight':arg_params['logvar_weight'],\n",
    "                     'logvar_bias':arg_params['logvar_bias'],\n",
    "                     'decoder_z_weight':arg_params['decoder_z_weight'],\n",
    "                     'decoder_z_bias':arg_params['decoder_z_bias'],\n",
    "                     'decoder_x_weight':arg_params['decoder_x_weight'],\n",
    "                     'decoder_x_bias':arg_params['decoder_x_bias'],                \n",
    "                     'loss_label':label})\n",
    "\n",
    "x_fit = e.forward()\n",
    "x_construction = x_fit[0].asnumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5f2c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning images on the test set\n",
    "f, ((ax1, ax2, ax3, ax4)) = plt.subplots(1,4,  sharex='col', sharey='row',figsize=(12,3))\n",
    "ax1.imshow(np.reshape(image_test[0,:],(28,28)), interpolation='nearest', cmap=cm.Greys)\n",
    "ax1.set_title('True image')\n",
    "ax2.imshow(np.reshape(x_construction[0,:],(28,28)), interpolation='nearest', cmap=cm.Greys)\n",
    "ax2.set_title('Learned image')\n",
    "ax3.imshow(np.reshape(image_test[99,:],(28,28)), interpolation='nearest', cmap=cm.Greys)\n",
    "ax3.set_title('True image')\n",
    "ax4.imshow(np.reshape(x_construction[99,:],(28,28)), interpolation='nearest', cmap=cm.Greys)\n",
    "ax4.set_title('Learned image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22551cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the ELBO which is minus the loss for test set\n",
    "metric = mx.metric.Loss()\n",
    "model.score(nd_iter_test, metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d9157d",
   "metadata": {},
   "source": [
    "## 4. All together: MXNet-based class VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dd9fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from VAE import VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b347fb6b",
   "metadata": {},
   "source": [
    "One can directly call the class `VAE` to do the training:\n",
    "\n",
    "```VAE(n_latent=5,num_hidden_ecoder=400,num_hidden_decoder=400,x_train=None,x_valid=None,\n",
    "batch_size=100,learning_rate=0.001,weight_decay=0.01,num_epoch=100,optimizer='sgd',model_prefix=None,\n",
    "initializer = mx.init.Normal(0.01),likelihood=Bernoulli)```\n",
    "\n",
    "The outputs are the learned model and training loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698c9f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can initilize weights and biases with the learned parameters as follows: \n",
    "# init = mx.initializer.Load(params)\n",
    "\n",
    "# call the VAE, output model contains the learned model and training loss\n",
    "out = VAE(n_latent=2, x_train=image, x_valid=None, num_epoch=200) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ba4e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode test images to obtain mu and logvar which are used for sampling\n",
    "[mu,logvar] = VAE.encoder(out,image_test)\n",
    "# sample in the latent space\n",
    "z = VAE.sampler(mu,logvar)\n",
    "# decode from the latent space to obtain reconstructed images\n",
    "x_construction = VAE.decoder(out,z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dedc652",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ((ax1, ax2, ax3, ax4)) = plt.subplots(1,4,  sharex='col', sharey='row',figsize=(12,3))\n",
    "ax1.imshow(np.reshape(image_test[0,:],(28,28)), interpolation='nearest', cmap=cm.Greys)\n",
    "ax1.set_title('True image')\n",
    "ax2.imshow(np.reshape(x_construction[0,:],(28,28)), interpolation='nearest', cmap=cm.Greys)\n",
    "ax2.set_title('Learned image')\n",
    "ax3.imshow(np.reshape(image_test[146,:],(28,28)), interpolation='nearest', cmap=cm.Greys)\n",
    "ax3.set_title('True image')\n",
    "ax4.imshow(np.reshape(x_construction[146,:],(28,28)), interpolation='nearest', cmap=cm.Greys)\n",
    "ax4.set_title('Learned image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9739c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "z1 = z[:,0]\n",
    "z2 = z[:,1]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(z1,z2,'ko')\n",
    "plt.title(\"latent space\")\n",
    "\n",
    "#np.where((z1>3) & (z2<2) & (z2>0))\n",
    "#select the points from the latent space\n",
    "a_vec = [2,5,7,789,25,9993]\n",
    "for i in range(len(a_vec)):\n",
    "    ax.plot(z1[a_vec[i]],z2[a_vec[i]],'ro')  \n",
    "    ax.annotate('z%d' %i, xy=(z1[a_vec[i]],z2[a_vec[i]]), \n",
    "                xytext=(z1[a_vec[i]],z2[a_vec[i]]),color = 'r',fontsize=15)\n",
    "\n",
    "\n",
    "f, ((ax0, ax1, ax2, ax3, ax4,ax5)) = plt.subplots(1,6,  sharex='col', sharey='row',figsize=(12,2.5))\n",
    "for i in range(len(a_vec)):\n",
    "    eval('ax%d' %(i)).imshow(np.reshape(x_construction[a_vec[i],:],(28,28)), interpolation='nearest', cmap=cm.Greys)\n",
    "    eval('ax%d' %(i)).set_title('z%d'%i)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f47460a",
   "metadata": {},
   "source": [
    "Above is a plot of points in the 2D latent space and their corresponding decoded images, it can be seen that points that are close in the latent space get mapped to the same digit from the decoder, and we can see how it evolves from left to right."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
