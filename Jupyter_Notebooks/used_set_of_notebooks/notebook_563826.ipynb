{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "159c277a",
   "metadata": {},
   "source": [
    "# Ranking embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0e93af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd3de0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d2f6f0",
   "metadata": {},
   "source": [
    "The problem consists of ranking $m$ items. Let's suppose those items are denotes from $1$ to $m$.\n",
    "\n",
    "We consider $Y = \\mathfrak{S}_m$, \n",
    "for $\\sigma\\in Y$, $\\sigma(i) > \\sigma(j)$ means that item $i$ is prefered over item $j$.\n",
    "\n",
    "We represent $\\sigma\\in Y$ with $s = [\\sigma(1), \\cdots, \\sigma(m)]$.\n",
    "This representation can be thought as a canonical score associated to $\\sigma\\in Y$. \n",
    "If $s(i)$ is the score of item $i$, $s(i) > s(j)$ means that $i$ is prefered over $j$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd5c0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 10\n",
    "sigma = np.random.permutation(m)\n",
    "print(sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9aa4f8",
   "metadata": {},
   "source": [
    "We can derive a ranking represention $[\\sigma^{-1}(1), \\cdots, \\sigma^{-1}(m)]$ from the scoring one with an argsort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499541da",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = sigma.argsort()\n",
    "print(rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86888e4",
   "metadata": {},
   "source": [
    "This argsort allows to recover also the canonical representation from the rank one in the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1813f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rank.argsort())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29543a63",
   "metadata": {},
   "source": [
    "Let's now switch to the Kemeny embedding to represent permutation, that is\n",
    "$$\n",
    "        \\phi(\\sigma) = (\\text{sign}(\\sigma(i) - \\sigma(j)))\n",
    "$$\n",
    "To represent it, we will use the following indice mapping\n",
    "\n",
    " ind | j=1 | j=2 | j=3 | j=4\n",
    " --- | --- | --- | --- | ---\n",
    " i=1 |  *  |  1  |  2  |  4 \n",
    " i=2 |  *  |  *  |  3  |  5 \n",
    " i=3 |  *  |  *  |  *  |  6 \n",
    " i=4 |  *  |  *  |  *  |  * \n",
    "\n",
    "With the flat embedding, only based on pairs for which $i < j$\n",
    "$$\n",
    "   \\text{emb}(\\text{ind}(i, j)) = \\phi(\\sigma)_{ij}.\n",
    "$$\n",
    "To ease some calculation we will also use the symmetric embedding\n",
    "$$\n",
    "   \\text{sym emb}(i, j) = \\phi(\\sigma)_{ij}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df0c842",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit(\"i8[:, :](i8)\", nopython=True)\n",
    "def canonical_map(m):\n",
    "    ind_map = np.full((m, m), m**2, dtype=np.int64)\n",
    "    ind = 0\n",
    "    for j in range(m):\n",
    "        for i in range(j):\n",
    "            ind_map[i, j] = ind\n",
    "            ind += 1\n",
    "    return ind_map\n",
    "\n",
    "\n",
    "def get_emb(scores, ind_map):\n",
    "    m = len(scores)\n",
    "    m_emb = (m*(m-1))//2\n",
    "    emb = np.empty(m_emb, dtype=np.float64)\n",
    "    if scores.dtype == np.int64:\n",
    "        fill_emb_i8(scores, emb, ind_map)\n",
    "    else:\n",
    "        fill_emb_f8(scores, emb, ind_map)\n",
    "    return emb\n",
    "\n",
    "\n",
    "@numba.jit(\"(i8[:], f8[:], i8[:, :])\", nopython=True)\n",
    "def fill_emb_i8(scores, emb, ind_map):\n",
    "    m = len(ind_map)\n",
    "    for j in range(m):\n",
    "        for i in range(j):\n",
    "            emb[ind_map[i, j]] = scores[i] > scores[j]\n",
    "    emb *= 2\n",
    "    emb -= 1\n",
    "\n",
    "\n",
    "@numba.jit(\"(f8[:], f8[:], i8[:, :])\", nopython=True)\n",
    "def fill_emb_f8(scores, emb, ind_map):\n",
    "    m = len(ind_map)\n",
    "    for j in range(m):\n",
    "        for i in range(j):\n",
    "            emb[ind_map[i, j]] = scores[i] > scores[j]\n",
    "    emb *= 2\n",
    "    emb -= 1\n",
    "\n",
    "\n",
    "def get_emb_from_rank(rank, ind_map):\n",
    "    m = len(ind_map)\n",
    "    m_emb = (m*(m-1)) // 2\n",
    "    emb = np.zeros(m_emb, dtype=np.float64)\n",
    "    fill_emb_from_rank(rank, emb, ind_map)\n",
    "    return emb\n",
    "\n",
    "\n",
    "@numba.jit(\"(i8[:], f8[:], i8[:, :])\", nopython=True)\n",
    "def fill_emb_from_rank(rank, emb, ind_map):\n",
    "    for i_, i in enumerate(rank):\n",
    "        for j in rank[i_+1:]:\n",
    "            if i < j:\n",
    "                ind = ind_map[i, j]\n",
    "                emb[ind] = -1\n",
    "            if j < i:\n",
    "                ind = ind_map[j, i]\n",
    "                emb[ind] = 1\n",
    "\n",
    "\n",
    "def get_sym_emb(emb, ind_map):\n",
    "    m = len(ind_map)\n",
    "    sym_emb = np.zeros((m, m), dtype=np.float64)\n",
    "    fill_sym_emb(emb, sym_emb, ind_map)\n",
    "    return sym_emb\n",
    "\n",
    "\n",
    "@numba.jit(\"(f8[:], f8[:, :], i8[:, :])\", nopython=True)\n",
    "def fill_sym_emb(emb, sym_emb, ind_map):\n",
    "    m = len(ind_map)\n",
    "    for j in range(m):\n",
    "        sym_emb[j, j] = 0\n",
    "        for i in range(j):\n",
    "            ind = ind_map[i, j]\n",
    "            sym_emb[i, j] = emb[ind]\n",
    "            sym_emb[j, i] = -emb[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91f0d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_map = canonical_map(m)\n",
    "emb = get_emb(sigma, ind_map)\n",
    "print(np.abs(get_emb_from_rank(rank, ind_map) - emb).max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef97640",
   "metadata": {},
   "source": [
    "The symmetric embedding allows to recover easily a score, as the number of times, item $i$ was bigger than an item $j$ minus the number of time it was smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7631300f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sym_emb = get_sym_emb(emb, ind_map)\n",
    "new_scores = sym_emb.sum(axis=1)\n",
    "print(new_scores.argsort().argsort())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afb9694",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_emb = get_emb(new_scores, ind_map)\n",
    "print(np.abs(new_emb - emb).max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b417b64",
   "metadata": {},
   "source": [
    "## A basic FAS solver\n",
    "\n",
    "The precedent development allows to create an easy minimum feedback arc set solver.\n",
    "We will work directly with the Kemeny embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d21005",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicFasSolver:\n",
    "    def __init__(self, ind_map):\n",
    "        self.ind_map = ind_map\n",
    "        \n",
    "        # Placeholders\n",
    "        m = len(ind_map)\n",
    "        self.sym_pl = np.empty((m, m), dtype=np.float)\n",
    "        self.score_pl = np.empty(m, dtype=np.float)\n",
    "    \n",
    "    def solve(self, c):\n",
    "        \"\"\"\n",
    "        Solve inf_y <phi(y), c>.\n",
    "        \"\"\"\n",
    "        emb = np.empty(c.shape, dtype=np.float)\n",
    "        self.solve_out(c, emb)\n",
    "        return emb\n",
    "    \n",
    "    def solve_out(self, c, out):\n",
    "        fill_sym_emb(c, self.sym_pl, self.ind_map)\n",
    "        np.sum(self.sym_pl, axis=1, out=self.score_pl) \n",
    "        self.score_pl *= -1\n",
    "        fill_emb_f8(self.score_pl, out, self.ind_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4350b133",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = BasicFasSolver(ind_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31adc7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.abs(solver.solve(emb) + emb).max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfb260c",
   "metadata": {},
   "source": [
    "## Some function to gain time\n",
    "Just-in-time compilation allows to gain a lot of computation time in python. A lot of the embedding function are going to be called on a series of entry, implying a for loop, to accelerate it, it is nice to have it in JIT. Therefore we introduce those functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f35ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sym_emb(emb, ind_map):\n",
    "    m = len(ind_map)\n",
    "    sym_emb = np.zeros((m, m), dtype=np.float64)\n",
    "    fill_sym_emb(emb, sym_emb, ind_map)\n",
    "    return sym_emb\n",
    "\n",
    "\n",
    "@numba.jit(\"(f8[:], f8[:, :], i8[:, :])\", nopython=True)\n",
    "def fill_sym_emb(emb, sym_emb, ind_map):\n",
    "    m = len(ind_map)\n",
    "    for j in range(m):\n",
    "        sym_emb[j, j] = 0\n",
    "        for i in range(j):\n",
    "            ind = ind_map[i, j]\n",
    "            sym_emb[i, j] = emb[ind]\n",
    "            sym_emb[j, i] = -emb[ind]"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
