{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f466bee1",
   "metadata": {},
   "source": [
    "# Exercise 2: Data Augmentation\n",
    "Taking a picture of an object from a different angle does not change the type of the object. \n",
    "Machine learning models overfitting to learn to only recognize an object from a single angle or, worse, under certain lighting conditions or with certain backgrounds is a real problem.\n",
    "Luckily, it is possible to lower this risk without taking new data but, instead, altering existing images in a dataset.\n",
    "This process is called \"data agumentation\" and it will be the focus of this excercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd879c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.datasets import cifar10\n",
    "from keras import Sequential\n",
    "from keras import layers\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024de332",
   "metadata": {},
   "source": [
    "## Load in Data\n",
    "We are going to use the [CIFAR 10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset as an example.\n",
    "This dataset contains pictures of many differnet kinds of objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c3c67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7a7d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.imshow(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd23a419",
   "metadata": {},
   "source": [
    "I'm not sure what I'm looking at here. Let's hope our CNN does"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b31ebce",
   "metadata": {},
   "source": [
    "As before, we need to convert the labels into a binary representation and images into a floating point number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91198407",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354eb91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901866e0",
   "metadata": {},
   "source": [
    "## Illustrate Data Augmentation\n",
    "A few things we can do to this picture to emulate taking a picture with a different camera, view, etc are:\n",
    "- Rotate the image\n",
    "- Darken it\n",
    "- Magnify it\n",
    "Keras has a tool, [ImageDataGenerator](https://keras.io/preprocessing/image/), that helps with this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c022350",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True,\n",
    "                         rotation_range=45, shear_range=20, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86845da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2)\n",
    "\n",
    "for ax in axs.flatten():\n",
    "    ax.imshow(gen.random_transform(x_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd14bf73",
   "metadata": {},
   "source": [
    "Hopefully, this is the right kind of noise to help the model generalize better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a130ded",
   "metadata": {},
   "source": [
    "## Fitting without augmentation\n",
    "Just to serve as a baseline. We will borrow the architecture from the [Keras example for CIFAR](https://keras.io/examples/cifar10_cnn/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a48520",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    return Sequential([\n",
    "        layers.Conv2D(32, (3, 3), padding='same', activation='relu',\n",
    "                      input_shape=x_train.shape[1:]),\n",
    "        layers.Conv2D(32, (3, 3), padding='same', activation='relu',\n",
    "                      input_shape=x_train.shape[1:]),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "\n",
    "        layers.Conv2D(64, (3, 3), padding='same', activation='relu',\n",
    "                      input_shape=x_train.shape[1:]),\n",
    "        layers.Conv2D(64, (3, 3), padding='same', activation='relu',\n",
    "                      input_shape=x_train.shape[1:]),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d25a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd682e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('rmsprop', 'categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c4c00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, batch_size=64, epochs=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd83122",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(x_test, y_test)\n",
    "print('Accuracy: {}'.format(scores[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fa7013",
   "metadata": {},
   "source": [
    "## Fitting a CNN with Augmentation\n",
    "You now have a tool that will generate a new series of images given a current training set. \n",
    "Rather than generating all of the images in advance, Keras lets you generate them on-the-fly with the `fit_generator` function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ac21b3",
   "metadata": {},
   "source": [
    "Making a generator with [reasonable settings](https://keras.io/examples/cifar10_cnn/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cbf217",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        # randomly shift images horizontally (fraction of total width)\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically (fraction of total height)\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.,  # set range for random shear\n",
    "        zoom_range=0.,  # set range for random zoom\n",
    "        channel_shift_range=0.,  # set range for random channel shifts\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,  # value used for fill_mode = \"constant\"\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False,  # randomly flip images\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96dd4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model()\n",
    "model.compile('rmsprop', 'categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb97e3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen.fit(x_train)  # Need to fit the model for some of the random moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6706725e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(gen.flow(x_train, y_train, batch_size=64),\n",
    "                    steps_per_epoch=x_train.shape[0] // 64,\n",
    "                    epochs=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82722d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(x_test, y_test)\n",
    "print('Accuracy: {}'.format(scores[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdb09cf",
   "metadata": {},
   "source": [
    "Depending ont he random initialization, your accuracy should have gone up slightly!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26582cc",
   "metadata": {},
   "source": [
    "## Still curious?\n",
    "Try increasing the magnitude of the random changes. Can you reach a point where they cause more harm than good?"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
