{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4365a5d0",
   "metadata": {},
   "source": [
    "# Setup Notebook for Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139d526a",
   "metadata": {},
   "source": [
    "##### <span style=\"color:red\">IMPORTANT: Only modify cells which have the following comment:</span>\n",
    "```python\n",
    "# Modify this cell\n",
    "```\n",
    "##### <span style=\"color:red\">Do not add any new cells when you submit the homework</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd590ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5c8a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc=SparkContext(master=\"local[4]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12394213",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Tester.SparkBasics1 as SparkBasics1\n",
    "pickleFile=\"Tester/SparkBasics1.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcb434d",
   "metadata": {},
   "source": [
    "Importing all packages necessary to complete the homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59098826",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2612498a",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "\n",
    "Write a function called **mapcos** that has a single paramater: an RDD of numbers. Use **map** to return an RRD that is the `cos()` (cosine) of the input.\n",
    "\n",
    "######  <span style=\"color:blue\">Code:</span>\n",
    "```python\n",
    "A=sc.parallelize( range(3) )\n",
    "print mapcos(A)\n",
    "print mapcos(A).collect()\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "######  <span style=\"color:magenta\">Output:</span>\n",
    "PythonRDD[14] at RDD at PythonRDD.scala:48\n",
    "\n",
    "[1.0, 0.54030..., -0.41614...]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e59ab7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify this cell\n",
    "from math import cos\n",
    "\n",
    "def mapcos(A):\n",
    "    return A.map(lambda x: cos(x));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feab7fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Tester.SparkBasics1 as SparkBasics1\n",
    "SparkBasics1.exercise1_1(pickleFile, mapcos ,sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38bb86b",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "\n",
    "Write a function called **mapwords** that has a single paramater: an RDD of strings, and returns an RDD that contains a list of words for each string.\n",
    "\n",
    "######  <span style=\"color:blue\">Code:</span>\n",
    "```python\n",
    "stringRDD=sc.parallelize([\"Spring quarter\", \"Learning spark basics\", \"Big data analytics with Spark\"])\n",
    "print mapwords(stringRDD).collect()\n",
    "```\n",
    "\n",
    "######  <span style=\"color:magenta\">Output:</span>\n",
    "[['Spring', 'quarter'], ['Learning', 'spark', 'basics'], ['Big', 'data', 'analytics', 'with', 'Spark']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9253e618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapwords(stringRDD):\n",
    "    return stringRDD.map(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868a805e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Tester.SparkBasics1 as SparkBasics1\n",
    "SparkBasics1.exercise1_2(pickleFile, mapwords, sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b7a46b",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "\n",
    "Write a function **getMax** that uses **reduce** to find the maximum number from a list of numbers. \n",
    "\n",
    "######  <span style=\"color:blue\">Code:</span>\n",
    "```python\n",
    "RDD=sc.parallelize([0,2,1])\n",
    "print getMax(RDD)\n",
    "```\n",
    "\n",
    "######  <span style=\"color:magenta\">Output:</span>\n",
    "2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae226d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMax(C):\n",
    "    return C.reduce(lambda x, y: max(x, y));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bb3875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Tester.SparkBasics1 as SparkBasics1\n",
    "SparkBasics1.exercise1_3(pickleFile, getMax, sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38512fba",
   "metadata": {},
   "source": [
    "# Exercise 4\n",
    "\n",
    "Write a function called **reducewords** that uses **reduce** to create a single string which is the concatenation of all the strings in stringRDD(with a space between each string). Example:\n",
    "\n",
    "######  <span style=\"color:blue\">Code:</span>\n",
    "```python\n",
    "stringRDD=sc.parallelize([\"Spring quarter\", \"Learning spark basics\", \"Big data analytics with Spark\"])\n",
    "print reducewords(stringRDD)\n",
    "```\n",
    "\n",
    "######  <span style=\"color:magenta\">Output:</span>\n",
    "'Spring quarter Learning spark basics Big data analytics with Spark'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f674ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify this cell\n",
    "def reducewords(stringRDD):\n",
    "    return stringRDD.reduce(lambda x, y: x + \" \" + y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e5aca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Tester.SparkBasics1 as SparkBasics1\n",
    "SparkBasics1.exercise1_4(pickleFile, reducewords, sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bb974c",
   "metadata": {},
   "source": [
    "# Exercise 5\n",
    "\n",
    "Write a non-Spark function **maxFunc** that when called by the **reduce** command outputs the maximum element from a set of lists.\n",
    "\n",
    "######  <span style=\"color:blue\">Code:</span>\n",
    "```python\n",
    "listRDD=sc.parallelize([[3,4],[2,1],[7,9]])\n",
    "print listRDD.reduce(maxFunc)\n",
    "```\n",
    "\n",
    "######  <span style=\"color:magenta\">Output:</span>\n",
    " [9]\n",
    "\n",
    "     Note: The output is a list containing a single number rather than just a single number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171bb3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxFunc(x,y):\n",
    "    # x,y are lists of numbers\n",
    "    # write code here for exercise 5\n",
    "    return [max(x)] if max(x) > max(y) else [max(y)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8fc0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Tester.SparkBasics1 as SparkBasics1\n",
    "SparkBasics1.exercise1_5(pickleFile, maxFunc, sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ccebe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
