{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c5f974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn.linear_model as sklm\n",
    "import pywt\n",
    "\n",
    "from scipy.fftpack import fft, fftfreq, ifft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577b3a67",
   "metadata": {},
   "source": [
    "### Inversion principle of WRIM\n",
    "The original LORENTZ A1 is decomposed into coarse and fine two sub-spaces. The signal\n",
    "parts corresponding to the fine and coarse sub-spaces are A2, D2, respectively. A2 corresponds to the approximation part, namely, overall trend of ACF. D2 corresponds to the detail part, namely, removed noise form original LORENTZ. Then, the approximation part A2 continues to be decomposed into A3 and D3. Thus, the detail part is gradually removed from LORENTZ. This process continues repeatedly until the decomposition scale reaches the coarsest scale. With the increase of decomposition scale, LORENTZ noise of the coarser space is gradually removed, and then LORENTZ of this space becomes relatively smoother. LORENTZ can be  written as \n",
    "\n",
    "$ LORENTZ(A_1) = A_2 + D_2 = A_3 + D_3 + D_2 = A_4 + D_4 + D_3 + D_2 $  \n",
    "\n",
    "Through the multi-scale decomposition, the original LORENTZ is composed into the approximation parts A2, A3, and A4 in the different sub-spaces. Correspondingly, the original inversion problem is divided into many sub-problems.  \n",
    "$ A_ix_i = b, i = 1, 2, 3, 4 $  \n",
    "in which $ A_i, x_i $ are calculated in the diameter inversion range [dmin, dmax] of the different sub-spaces."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a745e3fd",
   "metadata": {},
   "source": [
    "![alt-текст](https://pp.userapi.com/c852320/v852320326/6e7e3/dEdhPGSU20Q.jpg \"Необязательный титул\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0033e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simulator:\n",
    "    \n",
    "    kb = 1.308064e-23 # Boltzmann constant\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "    def configure_experiment(self, \n",
    "                             lambda_lazer = 650e-9,\n",
    "                             temperature = 273.15,\n",
    "                             theta = np.pi / 3,\n",
    "                             n = 1.33,\n",
    "                             eta = 0.958e-3):\n",
    "        \n",
    "        self.lambda_lazer = lambda_lazer\n",
    "        self.temperature = temperature\n",
    "        self.theta = theta\n",
    "        self.n = n\n",
    "        self.eta = eta\n",
    "        \n",
    "        #Evaluate coefficient\n",
    "        self.coeff = 2*(Simulator.kb * self.temperature/(3 * np.pi * self.eta)) * (4 * np.pi * self.n / self.lambda_lazer)**2 * np.sin(self.theta / 2)**2\n",
    "    \n",
    "    \n",
    "    def get_lorentz(self, diameter, freq):\n",
    "        if diameter == 0:\n",
    "            raise ValueError('zero passed as a diameter')\n",
    "        \n",
    "        G = self.coeff / diameter\n",
    "        \n",
    "        return 1 / np.pi * G / ((2 * np.pi * freq)**2 + G**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50cec25",
   "metadata": {},
   "source": [
    "# Ideal Lorentz Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d2e240",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "simulator = Simulator()\n",
    "simulator.configure_experiment()\n",
    "\n",
    "N_f = 2**12\n",
    "f_max = 2**10\n",
    "\n",
    "freqs = np.linspace(0, f_max, N_f)\n",
    "ideal_lorentz = simulator.get_lorentz(100e-9, freqs)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(freqs, ideal_lorentz, label='Ideal lorentz')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6b37f1",
   "metadata": {},
   "source": [
    "# Experimental Lorentz Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae8c0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_level = 0.09\n",
    "deviation_noise_level = 0.09\n",
    "\n",
    "deviation_interval_size = 30\n",
    "num_deviation_intervals = int(len(ideal_lorentz) / deviation_interval_size) + 1\n",
    "deviation_noise_levels = np.random.uniform(-deviation_noise_level, deviation_noise_level, num_deviation_intervals)\n",
    "\n",
    "exp_lorentz_values = []\n",
    "\n",
    "for i in range(len(ideal_lorentz)):\n",
    "    value = ideal_lorentz[i]\n",
    "    \n",
    "    deviation_interval_index = int(i / deviation_interval_size)\n",
    "    value *= (1 + deviation_noise_levels[deviation_interval_index])\n",
    "    \n",
    "    value *= (1 + np.random.uniform(-noise_level, noise_level))\n",
    "    \n",
    "    exp_lorentz_values.append(value)\n",
    "\n",
    "exp_lorentz = np.array(exp_lorentz_values)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(freqs, exp_lorentz, label='Experimental')\n",
    "ax.plot(freqs, ideal_lorentz, label='Ideal')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b3ea49",
   "metadata": {},
   "source": [
    "# WRIM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd15085",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pywt\n",
    "import numpy as np\n",
    "import seaborn\n",
    "import pandas as pd\n",
    "from statsmodels.robust import mad\n",
    "\n",
    "def get_decomposition(initial_signal, level=1, wavelet='db25'):\n",
    "    # calculate the wavelet approximation coefficients\n",
    "    \n",
    "    approximation_coeffs = pywt.downcoef('a', initial_signal, wavelet, level=level)\n",
    "    signal = pywt.upcoef('a', approximation_coeffs, wavelet, level=level, take=len(initial_signal))\n",
    "   \n",
    "    return signal\n",
    "\n",
    "\n",
    "result_lorentz = get_decomposition(exp_lorentz, level=2)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(freqs, result_lorentz, label='Result')\n",
    "#ax.plot(freqs, ideal_lorentz, label='Ideal lorentz')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d770f374",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff = simulator.coeff\n",
    "\n",
    "# initial diameters\n",
    "d_min = 1e-9 # 1 нм\n",
    "d_max = 2000e-9\n",
    "\n",
    "# create net\n",
    "G_min = coeff/d_max\n",
    "G_max = coeff/d_min\n",
    "N = 256*8\n",
    "M = len(freqs)\n",
    "p = (G_max/G_min)**(1/(N-1))\n",
    "G = np.zeros(N)\n",
    "\n",
    "# uniform net\n",
    "for j in range(N):\n",
    "    G[j] = G_min * (p**j)\n",
    "\n",
    "A = np.zeros((M,N))\n",
    "\n",
    "# Maxtrix of coefficients\n",
    "for i in range(M):\n",
    "    for j in range(N):\n",
    "        A[i,j] = G[j] / ((2 * np.pi * freqs[i])**2 + G[j]**2)\n",
    "        \n",
    "clf = sklm.Ridge(alpha = 5e-7)\n",
    "clf.fit(A, result_lorentz)\n",
    "a1 = clf.coef_\n",
    "\n",
    "clf = sklm.Ridge(alpha = 5e-7)\n",
    "clf.fit(A, ideal_lorentz)\n",
    "a2 = clf.coef_\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(3,1,1)\n",
    "line, = plt.plot(1e+9 * coeff/G, a1,'.-', color='green', markersize=1,label='Experiment')\n",
    "line, = plt.plot(1e+9 * coeff/G, a2,'.-', color='orange', markersize=1, label='Ideal')\n",
    "ax.set_xscale('log')\n",
    "plt.xlim(1, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f86fad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 9):\n",
    "    approximation_lorentz = get_decomposition(exp_lorentz, level=i)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(freqs, approximation_lorentz, label=f'Approximation Lorentz IDS {i}')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9792513",
   "metadata": {},
   "source": [
    "# Main Study "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01aec97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrim(initial_lorentz, freqs, coeff, initial_decomposition_scale = 1, d_min = 1e-9, d_max = 2000e-9):\n",
    "    \n",
    "    diam_poss = pd.DataFrame(columns=['d', 'p'])\n",
    "    lorentz = initial_lorentz\n",
    "    count = initial_decomposition_scale # IDS\n",
    "    \n",
    "    while count >= 1:\n",
    "        \n",
    "        G_min = coeff/d_max\n",
    "        G_max = coeff/d_min\n",
    "    \n",
    "        N = 2**16\n",
    "        M = len(freqs)\n",
    "    \n",
    "        p = (G_max / G_min)**(1 / (N-1))\n",
    "        G = np.zeros(N)\n",
    "    \n",
    "        for j in range(N):\n",
    "            G[j] = G_min * (p**j)\n",
    "        \n",
    "        A = np.zeros((M,N))\n",
    "\n",
    "        for i in range(M):\n",
    "            for j in range(N):\n",
    "                A[i,j] = G[j] / ((2 * np.pi * freqs[i])**2 + G[j]**2)\n",
    "        \n",
    "        approximation_lorentz = get_decomposition(lorentz, level = count)\n",
    "        \n",
    "        clf = sklm.Ridge(alpha = 5e-5)\n",
    "        clf.fit(A, approximation_lorentz)\n",
    "        a1 = clf.coef_\n",
    "    \n",
    "        diam_poss['d'] = 1e+9 * coeff/G\n",
    "        diam_poss['p'] = a1\n",
    "        \n",
    "        count -= 1 \n",
    "        \n",
    "        threshold = diam_poss['d'][diam_poss['p'] == diam_poss['p'].max()].values[0] / 2\n",
    "        d_min = search_first_zero(diam_poss, 0.001)[0]\n",
    "        d_max = search_first_zero(diam_poss, 0.001)[1]\n",
    "        print(d_min, d_max)\n",
    "    \n",
    "    \n",
    "    clf.fit(A, ideal_lorentz)\n",
    "    a2 = clf.coef_\n",
    "        \n",
    "    fig = plt.figure()\n",
    "    ax = plt.subplot(3, 1, 1)\n",
    "    line,  = plt.plot(1e+9 * coeff/G, a1,'.-')\n",
    "    line_, = plt.plot(1e+9 * coeff/G, a2, color='black')\n",
    "    ax.set_xscale('log')\n",
    "    plt.xlim(1, 2000)\n",
    "    \n",
    "    return a1, d_min, dmax\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9218dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 8 # depth of decomposition \n",
    "count = m # iterator\n",
    "coeff = simulator.coeff\n",
    "\n",
    "# Initial interval\n",
    "d_min = 1e-9 # 1 нм\n",
    "d_max = 2000e-9\n",
    "\n",
    "# задаем сетку по Gamma\n",
    "G_min = coeff/d_max\n",
    "G_max = coeff/d_min\n",
    "N = 256*8 # Число узлов в сетке по \\Gamma\n",
    "M = len(freqs) # Число точек по частоте\n",
    "p = (G_max/G_min)**(1/(N-1))\n",
    "G = np.zeros(N)\n",
    "\n",
    "# неравнмерная сетка со сгущением к нулю (так как больщий вклад в интенсивность дают крупные частицы)\n",
    "# хотя такая сетка - это не единственно возможный вариант\n",
    "for j in range(N):\n",
    "    G[j] = G_min * (p**j)\n",
    "\n",
    "A = np.zeros((M,N))\n",
    "\n",
    "# Матрица коэффициентов (составляется по базисным ф-ям)\n",
    "for i in range(M):\n",
    "    for j in range(N):\n",
    "        A[i,j] = G[j] / ((2 * np.pi * freqs[i])**2 + G[j]**2)\n",
    "diam_poss = pd.DataFrame(columns=['d', 'p'])\n",
    "lorentz = exp_lorentz\n",
    "\n",
    "while count >= 1:\n",
    "    \n",
    "    new_lorentz = get_decoposition(lorentz, level=count)\n",
    "    \n",
    "    clf = sklm.Ridge(alpha = 5e-5)\n",
    "    clf.fit(A, new_lorentz)\n",
    "    a1 = clf.coef_\n",
    "    \n",
    "    clf.fit(A, ideal_lorentz)\n",
    "    a2 = clf.coef_\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = plt.subplot(3, 1, 1)\n",
    "    line,  = plt.plot(1e+9 * coeff/G, a1,'.-')\n",
    "    line_, = plt.plot(1e+9 * coeff/G, a2, color='black')\n",
    "    ax.set_xscale('log')\n",
    "    plt.xlim(1, 2000)\n",
    "    \n",
    "    lorentz = new_lorentz\n",
    "    diam_poss['d'] = 1e+9 * coeff/G\n",
    "    diam_poss['p'] = a1\n",
    "    count += 1 \n",
    "    threshold = diam_poss['d'][diam_poss['p'] == diam_poss['p'].max()].values[0] / 2\n",
    "    #d_min = search_first_zero(diam_poss)[0]\n",
    "    #d_max = search_first_zero(diam_poss)[1]\n",
    "    print(d_min, d_max)\n",
    "    # задаем сетку по Gamma\n",
    "    G_min = coeff/d_max\n",
    "    print(G_min)\n",
    "    G_max = coeff/d_min\n",
    "    N = 256*8 # Число узлов в сетке по \\Gamma\n",
    "    M = len(freqs) # Число точек по частоте\n",
    "    p = (G_max/G_min)**(1/(N-1))\n",
    "    G = np.zeros(N)\n",
    "\n",
    "    for j in range(N):\n",
    "        G[j] = G_min * (p**j)\n",
    "\n",
    "    # вот равномерная сетка\n",
    "    #G = np.linspace(G_min, G_max, N)    \n",
    "\n",
    "    A = np.zeros((M,N))\n",
    "\n",
    "    # Матрица коэффициентов (составляется по базисным ф-ям)\n",
    "    for i in range(M):\n",
    "        for j in range(N):\n",
    "            A[i,j] = G[j] / ((2 * np.pi * freqs[i])**2 + G[j]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bbf706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_first_zero(data, p_threshold):\n",
    "    d_max_p       = data[data['p'] == data['p'].max()]['d'].max()\n",
    "    d_max_p_index = data[data['p'] == data['p'].max()].index[0]\n",
    "    df_1 = data[:d_max_p_index]\n",
    "    df_2 = data[d_max_p_index:]\n",
    "    \n",
    "    d_max = df_1[df_1['p'] < p_threshold].tail(1)['d'].values[0] * 1e-9\n",
    "    d_min = df_2[df_2['p'] < p_threshold].head(1)['d'].values[0] * 1e-9\n",
    "    return [d_min, d_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9b7678",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "y = exp_lorentz\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(freqs, y, label='True')\n",
    "plt.legend()\n",
    "\n",
    "lorentz = exp_lorentz\n",
    "\n",
    "for i in range(1, 9):\n",
    "    CA = pywt.downcoef('a', exp_lorentz, wavelet='db25', level=i)\n",
    "    approx = pywt.upcoef('a', CA, wavelet='db25', level=i, take=len(exp_lorentz))\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(freqs, approx, label=f'Level {i}')\n",
    "    plt.legend()\n",
    "    \n",
    "    coeff = simulator.coeff\n",
    "\n",
    "    # Initial interval\n",
    "    d_min = 1e-9 # 1 нм\n",
    "    d_max = 2000e-9\n",
    "\n",
    "    # задаем сетку по Gamma\n",
    "    G_min = coeff/d_max\n",
    "    G_max = coeff/d_min\n",
    "    N = 256*8 # Число узлов в сетке по \\Gamma\n",
    "    M = len(freqs) # Число точек по частоте\n",
    "    p = (G_max/G_min)**(1/(N-1))\n",
    "    G = np.zeros(N)\n",
    "\n",
    "    # неравнмерная сетка со сгущением к нулю (так как больщий вклад в интенсивность дают крупные частицы)\n",
    "    # хотя такая сетка - это не единственно возможный вариант\n",
    "    for j in range(N):\n",
    "        G[j] = G_min * (p**j)\n",
    "\n",
    "    A = np.zeros((M,N))\n",
    "\n",
    "    # Матрица коэффициентов (составляется по базисным ф-ям)\n",
    "    for i in range(M):\n",
    "        for j in range(N):\n",
    "            A[i,j] = G[j] / ((2 * np.pi * freqs[i])**2 + G[j]**2)\n",
    "            \n",
    "    clf = sklm.Ridge(alpha = 5e-5)\n",
    "    clf.fit(A, approx)\n",
    "    a1 = clf.coef_\n",
    "    \n",
    "    clf.fit(A, ideal_lorentz)\n",
    "    a2 = clf.coef_\n",
    "    \n",
    "    \n",
    "    fig1 = plt.figure()\n",
    "    ax1 = plt.subplot(3, 1, 1)\n",
    "    line,  = plt.plot(1e+9 * coeff/G, a1,'.-', markersize=1, color='blue')\n",
    "    line_, = plt.plot(1e+9 * coeff/G, a2, markersize=1, color='orange')\n",
    "    ax1.set_xscale('log')\n",
    "    plt.xlim(1, 2000)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7095b76a",
   "metadata": {},
   "source": [
    "# Two peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab8a2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "simulator = Simulator()\n",
    "simulator.configure_experiment()\n",
    "\n",
    "N_f = 2**12\n",
    "f_max = 2**10\n",
    "\n",
    "freqs = np.linspace(0, f_max, N_f)\n",
    "ideal_lorentz = simulator.get_lorentz(100e-9, freqs) + simulator.get_lorentz(500e-9, freqs)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(freqs, ideal_lorentz, label='Ideal lorentz')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08daf619",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_level = 0.09\n",
    "deviation_noise_level = 0.09\n",
    "\n",
    "deviation_interval_size = 30\n",
    "num_deviation_intervals = int(len(ideal_lorentz) / deviation_interval_size) + 1\n",
    "deviation_noise_levels = np.random.uniform(-deviation_noise_level, deviation_noise_level, num_deviation_intervals)\n",
    "\n",
    "exp_lorentz_values = []\n",
    "\n",
    "for i in range(len(ideal_lorentz)):\n",
    "    value = ideal_lorentz[i]\n",
    "    \n",
    "    deviation_interval_index = int(i / deviation_interval_size)\n",
    "    value *= (1 + deviation_noise_levels[deviation_interval_index])\n",
    "    \n",
    "    value *= (1 + np.random.uniform(-noise_level, noise_level))\n",
    "    \n",
    "    exp_lorentz_values.append(value)\n",
    "\n",
    "exp_lorentz = np.array(exp_lorentz_values)\n",
    "\n",
    "#exp_lorentz = np.array(list(map(lambda x: x * (1 + np.random.uniform(-noise_level, noise_level)), ideal_lorentz)))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(freqs, exp_lorentz, label='Experimental')\n",
    "ax.plot(freqs, ideal_lorentz, label='Ideal')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e393c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "y = exp_lorentz\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(freqs, y, label='True')\n",
    "plt.legend()\n",
    "\n",
    "lorentz = exp_lorentz\n",
    "\n",
    "for i in range(1, 8):\n",
    "    CA = pywt.downcoef('a', exp_lorentz, wavelet='db25', level=i)\n",
    "    approx = pywt.upcoef('a', CA, wavelet='db25', level=i, take=len(exp_lorentz))\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(freqs, approx, label=f'Level {i}')\n",
    "    plt.legend()\n",
    "    \n",
    "    coeff = simulator.coeff\n",
    "\n",
    "    # Initial interval\n",
    "    d_min = 1e-9 # 1 нм\n",
    "    d_max = 2000e-9\n",
    "\n",
    "    # задаем сетку по Gamma\n",
    "    G_min = coeff/d_max\n",
    "    G_max = coeff/d_min\n",
    "    N = 256*8 # Число узлов в сетке по \\Gamma\n",
    "    M = len(freqs) # Число точек по частоте\n",
    "    p = (G_max/G_min)**(1/(N-1))\n",
    "    G = np.zeros(N)\n",
    "\n",
    "    # неравнмерная сетка со сгущением к нулю (так как больщий вклад в интенсивность дают крупные частицы)\n",
    "    # хотя такая сетка - это не единственно возможный вариант\n",
    "    for j in range(N):\n",
    "        G[j] = G_min * (p**j)\n",
    "\n",
    "    A = np.zeros((M,N))\n",
    "\n",
    "    # Матрица коэффициентов (составляется по базисным ф-ям)\n",
    "    for i in range(M):\n",
    "        for j in range(N):\n",
    "            A[i,j] = G[j] / ((2 * np.pi * freqs[i])**2 + G[j]**2)\n",
    "            \n",
    "    clf = sklm.Ridge(alpha = 5e-5)\n",
    "    clf.fit(A, approx)\n",
    "    a1 = clf.coef_\n",
    "    \n",
    "    clf.fit(A, ideal_lorentz)\n",
    "    a2 = clf.coef_\n",
    "    \n",
    "    \n",
    "    fig1 = plt.figure()\n",
    "    ax1 = plt.subplot(3, 1, 1)\n",
    "    line,  = plt.plot(1e+9 * coeff/G, a1,'.-', markersize=1, color='blue')\n",
    "    line_, = plt.plot(1e+9 * coeff/G, a2, markersize=1, color='orange')\n",
    "    ax1.set_xscale('log')\n",
    "    plt.xlim(1, 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ce43ec",
   "metadata": {},
   "source": [
    "# Effect of Lorentz noise on Optimal IDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8af1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Noise level 0.09\n",
    "noise_level = 0.09\n",
    "deviation_noise_level = 0.09\n",
    "\n",
    "deviation_interval_size = 30\n",
    "num_deviation_intervals = int(len(ideal_lorentz) / deviation_interval_size) + 1\n",
    "deviation_noise_levels = np.random.uniform(-deviation_noise_level, deviation_noise_level, num_deviation_intervals)\n",
    "\n",
    "exp_lorentz_values = []\n",
    "\n",
    "for i in range(len(ideal_lorentz)):\n",
    "    value = ideal_lorentz[i]\n",
    "    \n",
    "    deviation_interval_index = int(i / deviation_interval_size)\n",
    "    value *= (1 + deviation_noise_levels[deviation_interval_index])\n",
    "    \n",
    "    value *= (1 + np.random.uniform(-noise_level, noise_level))\n",
    "    \n",
    "    exp_lorentz_values.append(value)\n",
    "\n",
    "exp_lorentz_009 = np.array(exp_lorentz_values)\n",
    "\n",
    "\n",
    "#Noise level 0.05\n",
    "noise_level = 0.05\n",
    "deviation_noise_level = 0.05\n",
    "\n",
    "deviation_interval_size = 30\n",
    "num_deviation_intervals = int(len(ideal_lorentz) / deviation_interval_size) + 1\n",
    "deviation_noise_levels = np.random.uniform(-deviation_noise_level, deviation_noise_level, num_deviation_intervals)\n",
    "\n",
    "exp_lorentz_values = []\n",
    "\n",
    "for i in range(len(ideal_lorentz)):\n",
    "    value = ideal_lorentz[i]\n",
    "    \n",
    "    deviation_interval_index = int(i / deviation_interval_size)\n",
    "    value *= (1 + deviation_noise_levels[deviation_interval_index])\n",
    "    \n",
    "    value *= (1 + np.random.uniform(-noise_level, noise_level))\n",
    "    \n",
    "    exp_lorentz_values.append(value)\n",
    "\n",
    "exp_lorentz_005 = np.array(exp_lorentz_values)\n",
    "\n",
    "\n",
    "#Noise level 0.02\n",
    "noise_level = 0.02\n",
    "deviation_noise_level = 0.02\n",
    "\n",
    "deviation_interval_size = 30\n",
    "num_deviation_intervals = int(len(ideal_lorentz) / deviation_interval_size) + 1\n",
    "deviation_noise_levels = np.random.uniform(-deviation_noise_level, deviation_noise_level, num_deviation_intervals)\n",
    "\n",
    "exp_lorentz_values = []\n",
    "\n",
    "for i in range(len(ideal_lorentz)):\n",
    "    value = ideal_lorentz[i]\n",
    "    \n",
    "    deviation_interval_index = int(i / deviation_interval_size)\n",
    "    value *= (1 + deviation_noise_levels[deviation_interval_index])\n",
    "    \n",
    "    value *= (1 + np.random.uniform(-noise_level, noise_level))\n",
    "    \n",
    "    exp_lorentz_values.append(value)\n",
    "\n",
    "exp_lorentz_002 = np.array(exp_lorentz_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d19643",
   "metadata": {},
   "source": [
    "# Effect of noise (noise_level = 0.09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e5f7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for i in range(1, 2):\n",
    "    CA = pywt.downcoef('a', exp_lorentz_009, wavelet='db25', level=i)\n",
    "    approx = pywt.upcoef('a', CA, wavelet='db25', level=i, take=len(exp_lorentz_009))\n",
    "       \n",
    "    coeff = simulator.coeff\n",
    "\n",
    "    # Initial interval\n",
    "    d_min = 1e-9 # 1 нм\n",
    "    d_max = 2000e-9\n",
    "\n",
    "    # задаем сетку по Gamma\n",
    "    G_min = coeff/d_max\n",
    "    G_max = coeff/d_min\n",
    "    N = 256*8 # Число узлов в сетке по \\Gamma\n",
    "    M = len(freqs) # Число точек по частоте\n",
    "    p = (G_max/G_min)**(1/(N-1))\n",
    "    G = np.zeros(N)\n",
    "\n",
    "    # неравнмерная сетка со сгущением к нулю (так как больщий вклад в интенсивность дают крупные частицы)\n",
    "    # хотя такая сетка - это не единственно возможный вариант\n",
    "    for j in range(N):\n",
    "        G[j] = G_min * (p**j)\n",
    "\n",
    "    A = np.zeros((M,N))\n",
    "\n",
    "    # Матрица коэффициентов (составляется по базисным ф-ям)\n",
    "    for i in range(M):\n",
    "        for j in range(N):\n",
    "            A[i,j] = G[j] / ((2 * np.pi * freqs[i])**2 + G[j]**2)\n",
    "            \n",
    "    clf = sklm.Ridge(alpha = 5e-5)\n",
    "    clf.fit(A, approx)\n",
    "    a1 = clf.coef_\n",
    "\n",
    "    ax.plot(1e+9 * coeff/G, a1,'.-', markersize=1, color='blue')\n",
    "    ax.set_xscale('log')\n",
    "    plt.xlim(1, 2000)\n",
    "\n",
    "clf = sklm.Ridge(alpha = 5e-5)\n",
    "clf.fit(A, ideal_lorentz)\n",
    "a2 = clf.coef_\n",
    "\n",
    "ax.plot(1e+9 * coeff/G, a2,'.-', markersize=1, color='orange')\n",
    "plt.xlim(1, 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4f8d3b",
   "metadata": {},
   "source": [
    "# Effect of noise (noise_level 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea5293d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for i in range(1, 8):\n",
    "    CA = pywt.downcoef('a', exp_lorentz_005, wavelet='db25', level=i)\n",
    "    approx = pywt.upcoef('a', CA, wavelet='db25', level=i, take=len(exp_lorentz_009))\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(freqs, approx, label=f'Level {i}')\n",
    "    plt.legend()\n",
    "    \n",
    "    coeff = simulator.coeff\n",
    "\n",
    "    # Initial interval\n",
    "    d_min = 1e-9 # 1 нм\n",
    "    d_max = 2000e-9\n",
    "\n",
    "    # задаем сетку по Gamma\n",
    "    G_min = coeff/d_max\n",
    "    G_max = coeff/d_min\n",
    "    N = 256*8 # Число узлов в сетке по \\Gamma\n",
    "    M = len(freqs) # Число точек по частоте\n",
    "    p = (G_max/G_min)**(1/(N-1))\n",
    "    G = np.zeros(N)\n",
    "\n",
    "    # неравнмерная сетка со сгущением к нулю (так как больщий вклад в интенсивность дают крупные частицы)\n",
    "    # хотя такая сетка - это не единственно возможный вариант\n",
    "    for j in range(N):\n",
    "        G[j] = G_min * (p**j)\n",
    "\n",
    "    A = np.zeros((M,N))\n",
    "\n",
    "    # Матрица коэффициентов (составляется по базисным ф-ям)\n",
    "    for i in range(M):\n",
    "        for j in range(N):\n",
    "            A[i,j] = G[j] / ((2 * np.pi * freqs[i])**2 + G[j]**2)\n",
    "            \n",
    "    clf = sklm.Ridge(alpha = 5e-5)\n",
    "    clf.fit(A, approx)\n",
    "    a1 = clf.coef_\n",
    "\n",
    "    ax.plot(1e+9 * coeff/G, a1,'.-', markersize=1, color='blue')\n",
    "    ax.set_xscale('log')\n",
    "    plt.xlim(1, 2000)\n",
    "\n",
    "clf = sklm.Ridge(alpha = 5e-5)\n",
    "clf.fit(A, ideal_lorentz)\n",
    "a2 = clf.coef_\n",
    "\n",
    "ax.plot(1e+9 * coeff/G, a2,'.-', markersize=1, color='orange')\n",
    "plt.xlim(1, 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9f2194",
   "metadata": {},
   "source": [
    "# Effect of noise (noise_level = 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e8c1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for i in range(1, 8):\n",
    "    CA = pywt.downcoef('a', exp_lorentz_002, wavelet='db25', level=i)\n",
    "    approx = pywt.upcoef('a', CA, wavelet='db25', level=i, take=len(exp_lorentz_009))\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(freqs, approx, label=f'Level {i}')\n",
    "    plt.legend()\n",
    "    \n",
    "    coeff = simulator.coeff\n",
    "\n",
    "    # Initial interval\n",
    "    d_min = 1e-9\n",
    "    d_max = 2000e-9\n",
    "\n",
    "    G_min = coeff/d_max\n",
    "    G_max = coeff/d_min\n",
    "    N = 256*8\n",
    "    M = len(freqs)\n",
    "    p = (G_max/G_min)**(1/(N-1))\n",
    "    G = np.zeros(N)\n",
    "\n",
    "    for j in range(N):\n",
    "        G[j] = G_min * (p**j)\n",
    "\n",
    "    A = np.zeros((M,N))\n",
    "\n",
    "    for i in range(M):\n",
    "        for j in range(N):\n",
    "            A[i,j] = G[j] / ((2 * np.pi * freqs[i])**2 + G[j]**2)\n",
    "            \n",
    "    clf = sklm.Ridge(alpha = 5e-5)\n",
    "    clf.fit(A, approx)\n",
    "    a1 = clf.coef_\n",
    "\n",
    "    ax.plot(1e+9 * coeff/G, a1,'.-', markersize=1, color='blue')\n",
    "    ax.set_xscale('log')\n",
    "    plt.xlim(1, 2000)\n",
    "\n",
    "clf = sklm.Ridge(alpha = 5e-5)\n",
    "clf.fit(A, ideal_lorentz)\n",
    "a2 = clf.coef_\n",
    "\n",
    "ax.plot(1e+9 * coeff/G, a2,'.-', markersize=1, color='orange')\n",
    "plt.xlim(1, 2000)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
