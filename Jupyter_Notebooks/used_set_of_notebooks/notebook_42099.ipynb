{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36c0e6e0",
   "metadata": {},
   "source": [
    "### Aquiring and importing night-lights data \n",
    "\n",
    "Imagery displaying observed light at night over the country of Burundi was downloaded from the NOAA VIIRS website: https://ngdc.noaa.gov/eog/viirs/download_ut_mos.html Burundi is contained within Tile 5, just slightly below the equator. \n",
    "\n",
    "We will use satellite day and night time from 2017. Burundi's dry season spans June to late September. Imagery will be collected as close to August 15th, 2017 to minimize noise created from seasonality between the datasets and increase the likelhood the images will be cloud free. \n",
    "\n",
    "\n",
    "#### Preprocessing: \n",
    "\n",
    "Images downloaded from the above website are free of inherent geographic information. To convert the image from png to tiff while applying the coordinate system, I the following gdal command via the cli: \n",
    "\n",
    "```\n",
    "gdal_translate  -a_srs EPSG:4326  -co compress=LZW SVDNB_npp_d20170815.d.00N060W.png Burundi_20170815.tiff\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d96ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from pprint import pprint\n",
    "import descarteslabs as dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17b2076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *************FIND COUNTRY BOUNDARY ***************\n",
    "matches = dl.places.find('burundi')\n",
    "aoi = matches[0]\n",
    "pprint(aoi)\n",
    "shape = dl.places.shape(aoi['slug'], geom='low')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ad6a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *************OPEN AN EXISTING IMAGE FROM DISK ***************\n",
    "from osgeo import gdal\n",
    "import numpy as np\n",
    "raster_data_path = \"data/black-marble/night_lights_clipped.tif\"\n",
    "raster_dataset = gdal.Open(raster_data_path, gdal.GA_ReadOnly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4d9788",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_transform = raster_dataset.GetGeoTransform()\n",
    "#     (416415.0, 30.0, 0.0, 6663145.0, 0.0, -30.0)\n",
    "proj = raster_dataset.GetProjectionRef()\n",
    "#     PROJCS[\"WGS 84 / UTM zone 20S\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-63],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",10000000],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AUTHORITY[\"EPSG\",\"32720\"]]\n",
    "bands_data = []\n",
    "for b in range(1, raster_dataset.RasterCount+1):\n",
    "    band = raster_dataset.GetRasterBand(b)\n",
    "    bands_data.append(band.ReadAsArray())\n",
    "#     [array dtype=float32],[...], ...\n",
    "bands_data = np.dstack(bands_data)\n",
    "\n",
    "# Validate data\n",
    "rows, cols, n_bands = bands_data.shape\n",
    "# print (rows, cols, n_bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb76e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *************PLOT SINGLE IMAGE ***************\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "plot_data = bands_data.squeeze()\n",
    "plot_data.shape\n",
    "\n",
    "\n",
    "plt.figure(figsize=[16,16])\n",
    "plt.imshow(plot_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c935057",
   "metadata": {},
   "source": [
    "### Classification\n",
    "\n",
    "We need a library of functions to rasterize our training and test data for analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83479f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask_from_vector(vector_data_path, cols, rows, geo_transform,\n",
    "                            projection, target_value=1):\n",
    "    \"\"\"Rasterize the given vector (wrapper for gdal.RasterizeLayer).\"\"\"\n",
    "    print(vector_data_path)\n",
    "    data_source = gdal.OpenEx(vector_data_path, gdal.OF_VECTOR)\n",
    "    print(data_source)\n",
    "    layer = data_source.GetLayer(0)\n",
    "    driver = gdal.GetDriverByName('MEM')  # In memory dataset\n",
    "    target_ds = driver.Create('', cols, rows, 1, gdal.GDT_UInt16)\n",
    "    target_ds.SetGeoTransform(geo_transform)\n",
    "    target_ds.SetProjection(projection)\n",
    "    gdal.RasterizeLayer(target_ds, [1], layer, burn_values=[target_value])\n",
    "    return target_ds\n",
    "\n",
    "\n",
    "def vectors_to_raster(file_paths, rows, cols, geo_transform, projection):\n",
    "    \"\"\"Rasterize the vectors in the given directory in a single image.\"\"\"\n",
    "    labeled_pixels = np.zeros((rows, cols))\n",
    "    print\n",
    "    for i, path in enumerate(file_paths):\n",
    "        label = i+1\n",
    "        ds = create_mask_from_vector(path, cols, rows, geo_transform,\n",
    "                                     projection, target_value=label)\n",
    "        band = ds.GetRasterBand(1)\n",
    "        labeled_pixels += band.ReadAsArray()\n",
    "        ds = None\n",
    "    return labeled_pixels\n",
    "\n",
    "\n",
    "def write_geotiff(fname, data, geo_transform, projection):\n",
    "    \"\"\"Create a GeoTIFF file with the given data.\"\"\"\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    rows, cols = data.shape\n",
    "    dataset = driver.Create(fname, cols, rows, 1, gdal.GDT_Byte)\n",
    "    dataset.SetGeoTransform(geo_transform)\n",
    "    dataset.SetProjection(projection)\n",
    "    band = dataset.GetRasterBand(1)\n",
    "    band.WriteArray(data)\n",
    "    dataset = None  # Close the file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188683a4",
   "metadata": {},
   "source": [
    "Define training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9514bd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_fname = \"data/black-marble/classification.tiff\"\n",
    "train_data_path = \"data/black-marble/train/\"\n",
    "validation_data_path = \"data/black-marble/test/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2ece09",
   "metadata": {},
   "source": [
    "Let's process the input training dataset.  Project all the vector data, in the training dataset, into a numpy array. Each class is assigned a label (a number between 1 and the total number of classes). If the value v in the position (i, j) of this new array is not zero, that means that the pixel (i, j) must be used as a training sample of class v.\n",
    "\n",
    "```training_samples``` is the list of pixels to be used for training. In our case, a pixel is a point in the nth-dimensional space of the bands.\n",
    "\n",
    "```training_labels``` is a list of class labels such that the i-th position indicates the class for i-th pixel in ```training_samples```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0deacc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f for f in os.listdir(train_data_path) if f.endswith('.shp')]\n",
    "classes = [f.split('.')[0] for f in files]\n",
    "print(classes)\n",
    "shapefiles = [os.path.join(train_data_path, f)\n",
    "              for f in files if f.endswith('.shp')]\n",
    "\n",
    "labeled_pixels = vectors_to_raster(shapefiles, rows, cols, geo_transform,\n",
    "                                   proj)\n",
    "print(shapefiles, rows, cols, geo_transform, proj)\n",
    "is_train = np.nonzero(labeled_pixels)\n",
    "training_labels = labeled_pixels[is_train]\n",
    "training_samples = bands_data[is_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23de9250",
   "metadata": {},
   "source": [
    "Now that we have all our parameters, we can instantiate a RandomForestClassifier from Scikit-learn to train a model for the classification. \n",
    "\n",
    "I have used the bare minimum to get the classification going, but will fine tune the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f90c10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(n_jobs=-1)\n",
    "classifier.fit(training_samples, training_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a2f2e6",
   "metadata": {},
   "source": [
    "To see the training data plotted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d6c0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_labels.shape)\n",
    "print(training_samples.shape)\n",
    "# Make the plot\n",
    "plt.scatter(training_labels, training_samples, color='r', marker='o')\n",
    "\n",
    "# Add some axis labels\n",
    "plt.xlabel('Training Lables')\n",
    "plt.ylabel('Training Samples')\n",
    "\n",
    "# Add a title\n",
    "plt.title('Training Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80089bb8",
   "metadata": {},
   "source": [
    "Let's apply the model to the night lights image for classification. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2846199d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = rows*cols\n",
    "flat_pixels = bands_data.reshape((n_samples, n_bands))\n",
    "result = classifier.predict(flat_pixels)\n",
    "classification = result.reshape((rows, cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e811f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure(figsize=[16,16])\n",
    "plt.imshow(classification)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc05a590",
   "metadata": {},
   "source": [
    "### Accuracy assessment \n",
    "\n",
    "I will use a confusion matrix and p-scores to assess the accuracy of the classified image. We need to output our classified image and preproess our test datasets before performing out accuracy assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84747dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_geotiff(output_fname, classification, geo_transform, proj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223ed985",
   "metadata": {},
   "source": [
    "Preprocess the test vector datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc90323",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# shapefiles = [os.path.join(validation_data_path, \"%s.shp\" % c)\n",
    "#               for c in classes]\n",
    "\n",
    "shapefiles = ['data/black-marble/test/dark_test.shp', 'data/black-marble/test/light_test.shp']\n",
    "print(['data/black-marble/test/dark_test.shp', 'data/black-marble/test/light_test.shp'])\n",
    "\n",
    "print(rows)\n",
    "print(cols)\n",
    "print(geo_transform)\n",
    "                              \n",
    "\n",
    "verification_pixels = vectors_to_raster(shapefiles, rows, cols, geo_transform,\n",
    "                                   proj)\n",
    "\n",
    "for_verification = np.nonzero(verification_pixels)\n",
    "verification_labels = verification_pixels[for_verification]\n",
    "predicted_labels = classification[for_verification]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98989836",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confussion matrix:\\n%s\" %\n",
    "      metrics.confusion_matrix(verification_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b7139c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['Class %s' % s for s in classes]\n",
    "print(\"Classification report:\\n%s\" %\n",
    "      metrics.classification_report(verification_labels, predicted_labels,\n",
    "                                    target_names=target_names))\n",
    "print(\"Classification accuracy: %f\" %\n",
    "      metrics.accuracy_score(verification_labels, predicted_labels))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
