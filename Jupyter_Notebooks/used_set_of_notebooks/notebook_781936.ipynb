{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc1c98ba",
   "metadata": {},
   "source": [
    "# Predicting car prices with the k-nearest neighbors algorithm\n",
    "\n",
    "In this project, i will use the machine learning workflow k-nearest neighbors to predict a car's market price using its attributes. The data set i will be working with contains information on various cars. For each car i have information about the technical aspects of the vehicle such as the motor's displacement, the weight of the car, the miles per gallon, how fast the car accelerates, and more.\n",
    "\n",
    "I also want to see how the model performance of the k-nearest neighbors for this specific task is.\n",
    "\n",
    "You can find the originally from the University of California Irvine (UCI) [here](https://archive.ics.uci.edu/ml/datasets/automobile).\n",
    "\n",
    "## Summary of results\n",
    "\n",
    "The project shows how the k-nearest neighbor algorithm works in a univariate and a multivariate model. In the univariate model you can see that horsepower seems to be the best attribute to predict the price of the car. On the other hand you also have to consider the number of k neighbors in your model to get a better model performance. \n",
    "\n",
    "In the multivariate model it is interesting to see that the best outcome (or the lowest rmse) is with four attributes and a k value of 1.\n",
    "\n",
    "As a result you can say that more k doesn't mean always a lower rmse in a knn-model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d23e72",
   "metadata": {},
   "source": [
    "## Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7a023b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# The raw data contains no column names so i define the column names compared to the UCI data documentation\n",
    "cols = ['symboling', 'normalized-losses', 'make', 'fuel-type', 'aspiration', 'num-of-doors', 'body-style', \n",
    "        'drive-wheels', 'engine-location', 'wheel-base', 'length', 'width', 'height', 'curb-weight', 'engine-type', \n",
    "        'num-of-cylinders', 'engine-size', 'fuel-system', 'bore', 'stroke', 'compression-rate', 'horsepower', 'peak-rpm',\n",
    "        'city-mpg', 'highway-mpg', 'price']\n",
    "# Read in the data\n",
    "cars = pd.read_csv('imports-85.data.txt', names=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed71f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a first look on the data\n",
    "cars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6038a46",
   "metadata": {},
   "source": [
    "## Data Cleaning for Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a757fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the columns with continuous values because otherwise the KNN-Model won't work\n",
    "continuous_values_cols = ['normalized-losses', 'wheel-base', 'length', 'width', 'height', 'curb-weight', 'bore', 'stroke', 'compression-rate', 'horsepower', 'peak-rpm', 'city-mpg', 'highway-mpg', 'price']\n",
    "numeric_cars = cars[continuous_values_cols]\n",
    "numeric_cars.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bf8010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the data preview in the last step we saw that the column \"normalized-losses\" \n",
    "# contains missing values (?). We need to replace these missing values.\n",
    "numeric_cars = numeric_cars.replace('?', np.nan)\n",
    "\n",
    "# Set all values to float values\n",
    "numeric_cars = numeric_cars.astype('float')\n",
    "\n",
    "# Check if there are missing values in the dataset\n",
    "numeric_cars.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbd7ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to predict the price. So we want to remove any rows with missing \"price\" values.\n",
    "numeric_cars = numeric_cars.dropna(subset=['price'])\n",
    "\n",
    "# Check again for missing values\n",
    "numeric_cars.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8372ed94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values in other columns using column means.\n",
    "numeric_cars = numeric_cars.fillna(numeric_cars.mean())\n",
    "\n",
    "# Check again if there are no more missing values!\n",
    "numeric_cars.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ac19c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to normalize all columnns to range from 0 to 1 except the target column,\n",
    "# so that outliers don't deform our result.\n",
    "price_col = numeric_cars['price']\n",
    "numeric_cars = (numeric_cars - numeric_cars.min())/(numeric_cars.max() - numeric_cars.min())\n",
    "numeric_cars['price'] = price_col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cd87ab",
   "metadata": {},
   "source": [
    "# Univariate Model with default k value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86f8ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the needed scikit-learn libaries\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Creating the KNN-function\n",
    "def knn_train_test(train_col, target_col, df):\n",
    "    knn = KNeighborsRegressor()\n",
    "    np.random.seed(1)\n",
    "        \n",
    "    # Randomize order of rows in data frame.\n",
    "    shuffled_index = np.random.permutation(df.index)\n",
    "    rand_df = df.reindex(shuffled_index)\n",
    "\n",
    "    # Divide number of rows in half and round.\n",
    "    last_train_row = int(len(rand_df) / 2)\n",
    "    \n",
    "    # Select the first half and set as training set.\n",
    "    # Select the second half and set as test set.\n",
    "    train_df = rand_df.iloc[0:last_train_row]\n",
    "    test_df = rand_df.iloc[last_train_row:]\n",
    "    \n",
    "    # Fit a KNN model using default k value.\n",
    "    knn.fit(train_df[[train_col]], train_df[target_col])\n",
    "    \n",
    "    # Make predictions using model.\n",
    "    predicted_labels = knn.predict(test_df[[train_col]])\n",
    "\n",
    "    # Calculate and return RMSE.\n",
    "    mse = mean_squared_error(test_df[target_col], predicted_labels)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "rmse_results = {}\n",
    "train_cols = numeric_cars.columns.drop('price')\n",
    "\n",
    "# For each column (minus `price`), train a model, return RMSE value\n",
    "# and add to the dictionary `rmse_results`.\n",
    "for col in train_cols:\n",
    "    rmse_val = knn_train_test(col, 'price', numeric_cars)\n",
    "    rmse_results[col] = rmse_val\n",
    "\n",
    "# Create a Series object from the dictionary so \n",
    "# we can easily view the results, sort, etc\n",
    "rmse_results_series = pd.Series(rmse_results)\n",
    "rmse_results_series.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb62ffe",
   "metadata": {},
   "source": [
    "# Univariate Model with several k values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83426f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_train_test(train_col, target_col, df):\n",
    "    np.random.seed(1)\n",
    "        \n",
    "    # Randomize order of rows in data frame.\n",
    "    shuffled_index = np.random.permutation(df.index)\n",
    "    rand_df = df.reindex(shuffled_index)\n",
    "\n",
    "    # Divide number of rows in half and round.\n",
    "    last_train_row = int(len(rand_df) / 2)\n",
    "    \n",
    "    # Select the first half and set as training set.\n",
    "    # Select the second half and set as test set.\n",
    "    train_df = rand_df.iloc[0:last_train_row]\n",
    "    test_df = rand_df.iloc[last_train_row:]\n",
    "    \n",
    "    k_values = [1,3,5,7,9]\n",
    "    k_rmses = {}\n",
    "    \n",
    "    for k in k_values:\n",
    "        # Fit model using k nearest neighbors.\n",
    "        knn = KNeighborsRegressor(n_neighbors=k)\n",
    "        knn.fit(train_df[[train_col]], train_df[target_col])\n",
    "\n",
    "        # Make predictions using model.\n",
    "        predicted_labels = knn.predict(test_df[[train_col]])\n",
    "\n",
    "        # Calculate and return RMSE.\n",
    "        mse = mean_squared_error(test_df[target_col], predicted_labels)\n",
    "        rmse = np.sqrt(mse)\n",
    "        \n",
    "        k_rmses[k] = rmse\n",
    "    return k_rmses\n",
    "\n",
    "k_rmse_results = {}\n",
    "\n",
    "# For each column (minus `price`), train a model, return RMSE value\n",
    "# and add to the dictionary `rmse_results`.\n",
    "train_cols = numeric_cars.columns.drop('price')\n",
    "for col in train_cols:\n",
    "    rmse_val = knn_train_test(col, 'price', numeric_cars)\n",
    "    k_rmse_results[col] = rmse_val\n",
    "\n",
    "k_rmse_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2da1ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "for k,v in k_rmse_results.items():\n",
    "    x = list(v.keys())\n",
    "    y = list(v.values())\n",
    "    \n",
    "    plt.plot(x,y)\n",
    "    plt.xlabel('k value')\n",
    "    plt.ylabel('RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4deff28",
   "metadata": {},
   "source": [
    "# Multivariate Model with fixed k (k = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d672324a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to find the best features/attributes from the previous model\n",
    "# So we compute the average RMSE across different `k` values for each feature.\n",
    "feature_avg_rmse = {}\n",
    "for k,v in k_rmse_results.items():\n",
    "    avg_rmse = np.mean(list(v.values()))\n",
    "    feature_avg_rmse[k] = avg_rmse\n",
    "series_avg_rmse = pd.Series(feature_avg_rmse)\n",
    "series_avg_rmse.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7c523e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_train_test(train_cols, target_col, df):\n",
    "    np.random.seed(1)\n",
    "    \n",
    "    # Randomize order of rows in data frame.\n",
    "    shuffled_index = np.random.permutation(df.index)\n",
    "    rand_df = df.reindex(shuffled_index)\n",
    "\n",
    "    # Divide number of rows in half and round.\n",
    "    last_train_row = int(len(rand_df) / 2)\n",
    "    \n",
    "    # Select the first half and set as training set.\n",
    "    # Select the second half and set as test set.\n",
    "    train_df = rand_df.iloc[0:last_train_row]\n",
    "    test_df = rand_df.iloc[last_train_row:]\n",
    "    \n",
    "    k_values = [5]\n",
    "    k_rmses = {}\n",
    "    \n",
    "    for k in k_values:\n",
    "        # Fit model using k nearest neighbors.\n",
    "        knn = KNeighborsRegressor(n_neighbors=k)\n",
    "        knn.fit(train_df[train_cols], train_df[target_col])\n",
    "\n",
    "        # Make predictions using model.\n",
    "        predicted_labels = knn.predict(test_df[train_cols])\n",
    "\n",
    "        # Calculate and return RMSE.\n",
    "        mse = mean_squared_error(test_df[target_col], predicted_labels)\n",
    "        rmse = np.sqrt(mse)\n",
    "        \n",
    "        k_rmses[k] = rmse\n",
    "    return k_rmses\n",
    "\n",
    "k_rmse_results = {}\n",
    "\n",
    "two_best_features = ['horsepower', 'width']\n",
    "rmse_val = knn_train_test(two_best_features, 'price', numeric_cars)\n",
    "k_rmse_results[\"two best features\"] = rmse_val\n",
    "\n",
    "three_best_features = ['horsepower', 'width', 'curb-weight']\n",
    "rmse_val = knn_train_test(three_best_features, 'price', numeric_cars)\n",
    "k_rmse_results[\"three best features\"] = rmse_val\n",
    "\n",
    "four_best_features = ['horsepower', 'width', 'curb-weight', 'highway-mpg']\n",
    "rmse_val = knn_train_test(four_best_features, 'price', numeric_cars)\n",
    "k_rmse_results[\"four best features\"] = rmse_val\n",
    "\n",
    "five_best_features = ['horsepower', 'width', 'curb-weight' , 'highway-mpg' , 'length']\n",
    "rmse_val = knn_train_test(five_best_features, 'price', numeric_cars)\n",
    "k_rmse_results[\"five best features\"] = rmse_val\n",
    "\n",
    "six_best_features = ['horsepower', 'width', 'curb-weight' , 'highway-mpg' , 'length', 'city-mpg']\n",
    "rmse_val = knn_train_test(six_best_features, 'price', numeric_cars)\n",
    "k_rmse_results[\"six best features\"] = rmse_val\n",
    "\n",
    "k_rmse_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3bc9a9",
   "metadata": {},
   "source": [
    "# Multivariate Model with several k values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20afed80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_train_test(train_cols, target_col, df):\n",
    "    np.random.seed(1)\n",
    "    \n",
    "    # Randomize order of rows in data frame.\n",
    "    shuffled_index = np.random.permutation(df.index)\n",
    "    rand_df = df.reindex(shuffled_index)\n",
    "\n",
    "    # Divide number of rows in half and round.\n",
    "    last_train_row = int(len(rand_df) / 2)\n",
    "    \n",
    "    # Select the first half and set as training set.\n",
    "    # Select the second half and set as test set.\n",
    "    train_df = rand_df.iloc[0:last_train_row]\n",
    "    test_df = rand_df.iloc[last_train_row:]\n",
    "    \n",
    "    k_values = [i for i in range(1, 25)]\n",
    "    k_rmses = {}\n",
    "    \n",
    "    for k in k_values:\n",
    "        # Fit model using k nearest neighbors.\n",
    "        knn = KNeighborsRegressor(n_neighbors=k)\n",
    "        knn.fit(train_df[train_cols], train_df[target_col])\n",
    "\n",
    "        # Make predictions using model.\n",
    "        predicted_labels = knn.predict(test_df[train_cols])\n",
    "\n",
    "        # Calculate and return RMSE.\n",
    "        mse = mean_squared_error(test_df[target_col], predicted_labels)\n",
    "        rmse = np.sqrt(mse)\n",
    "        \n",
    "        k_rmses[k] = rmse\n",
    "    return k_rmses\n",
    "\n",
    "k_rmse_results = {}\n",
    "\n",
    "three_best_features = ['horsepower', 'width', 'curb-weight']\n",
    "rmse_val = knn_train_test(three_best_features, 'price', numeric_cars)\n",
    "k_rmse_results[\"three best features\"] = rmse_val\n",
    "\n",
    "four_best_features = ['horsepower', 'width', 'curb-weight', 'highway-mpg']\n",
    "rmse_val = knn_train_test(four_best_features, 'price', numeric_cars)\n",
    "k_rmse_results[\"four best features\"] = rmse_val\n",
    "\n",
    "five_best_features = ['horsepower', 'width', 'curb-weight' , 'highway-mpg' , 'length']\n",
    "rmse_val = knn_train_test(five_best_features, 'price', numeric_cars)\n",
    "k_rmse_results[\"five best features\"] = rmse_val\n",
    "\n",
    "k_rmse_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee33443",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in k_rmse_results.items():\n",
    "    x = list(v.keys())\n",
    "    y = list(v.values())\n",
    "    \n",
    "    plt.plot(x,y)\n",
    "    plt.xlabel('k value')\n",
    "    plt.ylabel('RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b128a872",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "The project shows how the k-nearest neighbor algorithm works in a univariate and a multivariate model. In the univariate model you can see that horsepower seems to be the best attribute to predict the price of the car. On the other hand you also have to consider the number of k neighbors in your model to get a better model performance.\n",
    "\n",
    "In the multivariate model it is interesting to see that the best outcome (or the lowest rmse) is with four attributes and a k value of 1."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
