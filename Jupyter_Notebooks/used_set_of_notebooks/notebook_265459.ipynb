{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3578b990",
   "metadata": {},
   "source": [
    "## Movie genre classifier: Dataset preparation and model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dda7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nltk\n",
    "import joblib\n",
    "\n",
    "import text_wrangling_util\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc159a8f",
   "metadata": {},
   "source": [
    "The dataset used in this exercise is \"The Movies Dataset\" from [Kaggle](https://www.kaggle.com/rounakbanik/the-movies-dataset/version/7#movies_metadata.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc116c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"the-movies-dataset/movies_metadata.csv\", sep = ',', header = 0, low_memory=False)\n",
    "movies = data[['title','overview','genres']].copy()\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28ad9a5",
   "metadata": {},
   "source": [
    "### Data wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5c10a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dictionaries of genres to lists\n",
    "def dict_to_list(genres_dict):\n",
    "    genres_dict = json.loads(genres_dict.replace(\"\\'\",\"\\\"\"))\n",
    "    genres_list = []\n",
    "    for genre in genres_dict:\n",
    "        genres_list.append(genre['name'])\n",
    "    return genres_list\n",
    "\n",
    "movies['genres'] = movies['genres'].apply(lambda x: dict_to_list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d18f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discard movies without specified genres\n",
    "movies_to_discard = (movies['genres'].str.len() == 0)\n",
    "movies = movies[~movies_to_discard]\n",
    "print(\"{} movies without genres were discarded from the dataset\".format(sum(movies_to_discard)))\n",
    "\n",
    "# Discard movies without a title or description\n",
    "movies_to_discard = (movies.title.isnull() | movies.overview.isnull())\n",
    "movies = movies[~movies_to_discard]\n",
    "print(\"{} movies without title or description were discarded from the dataset\".format(sum(movies_to_discard)))\n",
    "print(\"----\")\n",
    "print(\"{} movies remain in the dataset\".format(len(movies)))\n",
    "\n",
    "movies = movies.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156b85d7",
   "metadata": {},
   "source": [
    "The textual data preprocessing strategy is the following: (1) combine the movie title and description into one body of text, (2) remove apostrophes and other non-alphabetical symbols, (3) set all words to lower case, (4) remove stopwords and (5) perform stemming (see *text_wrangling_util.py* for more details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f4beac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare input text for training\n",
    "input_text = text_wrangling_util.prepare_input_text(title=list(movies[\"title\"]), description=list(movies[\"overview\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09838092",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_text[0])\n",
    "print('-----')\n",
    "print(input_text[121])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a629905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency distribution of genres\n",
    "all_genres = [item for sublist in movies[\"genres\"] for item in sublist]\n",
    "all_genres_distribution = nltk.FreqDist(all_genres) \n",
    "all_genres_dist_df = pd.DataFrame({\"genre\": list(all_genres_distribution.keys()), \n",
    "                              \"count\": list(all_genres_distribution.values())})\n",
    "all_genres_dist_df = all_genres_dist_df.sort_values(\"genre\")\n",
    "genres = list(all_genres_dist_df['genre'])\n",
    "\n",
    "plt.figure(figsize=(5,5)) \n",
    "ax = sns.barplot(data=all_genres_dist_df.sort_values(\"count\",ascending=False), x = \"count\", y = \"genre\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1cd2c6",
   "metadata": {},
   "source": [
    "Note that the dataset is quite imbalanced, which in principle should be somehow addressed. That could be done by, e.g., undersampling the overrepresented genres or synthesizing more examples of the underrepresented genres. Here, however, I will try to make do with the original dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479b5ca3",
   "metadata": {},
   "source": [
    "### Model training and selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf84660",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "multilabel_binarizer = MultiLabelBinarizer()\n",
    "Y = multilabel_binarizer.fit_transform(movies['genres'])\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(input_text, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "vectorizer = Pipeline([('tfidf_vectorizer', TfidfVectorizer(max_df=0.8, max_features=10000))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e35749",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr = Pipeline([('vectorizer', vectorizer),\n",
    "                 ('clf', OneVsRestClassifier(LogisticRegression(solver='liblinear')))])\n",
    "\n",
    "pipe_nb = Pipeline([('vectorizer', vectorizer),\n",
    "                 ('clf', OneVsRestClassifier(MultinomialNB()))])\n",
    "\n",
    "pipe_dt = Pipeline([('vectorizer', vectorizer),\n",
    "                 ('clf', OneVsRestClassifier(tree.DecisionTreeClassifier(max_depth=20)))])\n",
    "\n",
    "pipelines = [pipe_lr, pipe_nb, pipe_dt]\n",
    "pipe_dict = {0: 'Logistic Regression', 1: \"Multinomial Naive Bayes\", 2: 'Decision Tree'}\n",
    "\n",
    "for i, pipe in enumerate(pipelines):\n",
    "    print(\"Fitting model with \" + pipe_dict[i] + \" classifier...\")\n",
    "    pipe.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c50f945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best threshold value for obtaining classification from model probabilities\n",
    "def find_best_threshold(pipe, pipe_title, make_plots=True):\n",
    "    \n",
    "    Y_pred_prob = pipe.predict_proba(X_val)\n",
    "    threshold_values = np.linspace(0.1,0.9,17)\n",
    "    F1_scores = []\n",
    "    \n",
    "    for t in threshold_values:\n",
    "        Y_pred = (Y_pred_prob >= t).astype(int)\n",
    "        F1_scores.append(f1_score(Y_val, Y_pred, average=\"micro\"))\n",
    "\n",
    "    max_score = max(F1_scores)\n",
    "    threshold_value = threshold_values[F1_scores.index(max_score)]\n",
    "    \n",
    "    if make_plots:\n",
    "        F1_vs_threshold = pd.DataFrame({\"threshold\": threshold_values, \"F1\": F1_scores})\n",
    "        plt.figure()\n",
    "        ax = sns.lineplot(data=F1_vs_threshold, x=\"threshold\", y=\"F1\")\n",
    "        ax.set(title=pipe_title + \": Best F1-score={} at threshold={}\".format(round(max_score,2),threshold_value))\n",
    "    \n",
    "    return threshold_value, max(F1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e979bf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = []\n",
    "best_F1_scores = []\n",
    "\n",
    "for i, pipe in enumerate(pipelines):    \n",
    "    threshold,F1_score = find_best_threshold(pipe,pipe_dict[i])\n",
    "    thresholds.append(threshold)\n",
    "    best_F1_scores.append(F1_score)\n",
    " \n",
    "j = best_F1_scores.index(max(best_F1_scores))\n",
    "best_pipe = pipelines[j]\n",
    "best_score = best_F1_scores[j]\n",
    "threshold_value = thresholds[j]\n",
    "print(\"Best result is with {}!\".format(pipe_dict[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32249b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_genre(title, description):\n",
    "    \n",
    "    # Preprocess input\n",
    "    input_text = text_wrangling_util.prepare_input_text(title, description)\n",
    "    \n",
    "    # Inference\n",
    "    Y_pred_prob = best_pipe.predict_proba(input_text)\n",
    "    predicted_genres = (Y_pred_prob >= threshold_value).astype(int)\n",
    "    \n",
    "    # Visualize the probabilities of the five most likely genres\n",
    "    pred_prob_df = pd.DataFrame({\"genre\": genres, \"p\": Y_pred_prob[0]})\n",
    "    pred_prob_df = pred_prob_df.sort_values('p',ascending=False)\n",
    "    plt.figure(figsize=(3,3)) \n",
    "    ax = sns.barplot(data=pred_prob_df[0:6], x='p',y='genre')\n",
    "    ax.set(xlabel='probability')\n",
    "    \n",
    "    #return multilabel_binarizer.inverse_transform(predicted_genres)\n",
    "    return list(pred_prob_df.loc[pred_prob_df[\"p\"] >= threshold_value,\"genre\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0ea502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "joblib.dump({\"pipeline\": best_pipe,\"threshold\": threshold_value,\"genres\": genres,\"score\": best_score}, 'movie_genre_classifier.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1311d0b0",
   "metadata": {},
   "source": [
    "### Some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa58d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Sabrina: the Teenage Witch\"\n",
    "plot = \"Reimagines the origin and adventures of Sabrina: the Teenage Witch as a dark coming-of-age story that traffics in horror, the occult and, of course, witchcraft. Tonally in the vein of Rosemary's Baby and The Exorcist, this adaptation finds Sabrina Spellman wrestling to reconcile her dual nature - half-witch, half-mortal - while standing against the evil forces that threaten her, her family and the daylight world humans inhabit.\"\n",
    "print(plot)\n",
    "print('-----')\n",
    "print(infer_genre(title, plot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997eba23",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Modern Family\"\n",
    "plot = \"Told from the perspective of an unseen documentary filmmaker, the series offers an honest, often-hilarious perspective of family life. Parents Phil and Claire yearn for an honest, open relationship with their three kids, but a daughter who is trying to grow up too fast, another who is too smart for her own good, and a rambunctious young son make it challenging. Claire's dad Jay and his Latina wife Gloria are raising two sons together, but people sometimes believe Jay to be Gloria's father. Jay's gay son Mitchell and his partner Cameron have adopted a little Asian girl, completing one big -- straight, gay, multicultural, traditional -- happy family.\"\n",
    "print(plot)\n",
    "print('-----')\n",
    "print(infer_genre(title, plot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed79c1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"CSI\"\n",
    "plot = \"This show follows the nights of the detectives working at the Las Vegas Police Department Crime Scene Investigations bureau. Being the second busiest crime lab in America, CSI officers use the best scientific and technical methods to solve puzzles and catch criminals.\"\n",
    "print(plot)\n",
    "print('-----')\n",
    "print(infer_genre(title, plot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c92481",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Othello\"\n",
    "plot = \"The evil Iago pretends to be friend of Othello in order to manipulate him to serve his own end in the film version of this Shakespeare classic.\" \n",
    "print(plot)\n",
    "print('-----')\n",
    "print(infer_genre(title, plot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e67c7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.loc[0,\"overview\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20104917",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.loc[movies[\"title\"]==\"Paths of Glory\"][\"genres\"][1088]"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
