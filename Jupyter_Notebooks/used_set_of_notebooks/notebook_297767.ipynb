{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c709a555",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import time\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import datetime\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (12, 10)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6e4a05",
   "metadata": {},
   "source": [
    "Defining Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052ffb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'GPU/:0'\n",
    "\n",
    "DATASET_DIR = '../../../datasets/Dataset-IoT/'\n",
    "NETFLOW_DIR = DATASET_DIR + 'MC/NetFlow/'\n",
    "\n",
    "# MC_I_FIRST: Has infected data by Hajime, Aidra and BashLite botnets'\n",
    "# MC_I_SECOND: Has infected data from Mirai botnets\n",
    "# MC_I_THIR: Has infected data from Mirai, Doflo, Tsunami and Wroba botnets\n",
    "# MC_L: Has legitimate data, no infection\n",
    "MC_L = r'MC_L.csv'\n",
    "\n",
    "data_set_files = [r'MC_I{}.csv'.format(index) for index in range(1, 4)]\n",
    "data_set_files.insert(0, r'MC_L.csv')\n",
    "print (data_set_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e13399c",
   "metadata": {},
   "source": [
    "Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8cf3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "legitimate_file_path = NETFLOW_DIR + MC_L\n",
    "\n",
    "LABEL_COLUMN = 'Label'\n",
    "\n",
    "#reading data\n",
    "df = pd.read_csv (legitimate_file_path)\n",
    "\n",
    "# for file in data_set_files:\n",
    "#     aux_df = pd.read_csv(NETFLOW_DIR + file)\n",
    "#     df = pd.concat([df, aux_df], ignore_index=True)\n",
    "\n",
    "aux_df = pd.read_csv(NETFLOW_DIR + data_set_files[1])\n",
    "df = pd.concat([df, aux_df], ignore_index=True)\n",
    "\n",
    "#making the final DataFrame\n",
    "df = df.drop(df.columns[0], axis=1)\n",
    "df.describe()\n",
    "\n",
    "nUniques = df.nunique()\n",
    "for column, nUnique in zip (df.columns, nUniques):\n",
    "    if(nUnique == 1):\n",
    "        df.drop(axis='columns', columns=column, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05e42ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(axis='columns', columns=['ts', 'te', 'sa', 'da'], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccdae54",
   "metadata": {},
   "source": [
    "# Encoding the Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465f8c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "cat_cols, num_cols = df.columns[df.dtypes == 'O'], df.columns[df.dtypes != 'O']\n",
    "num_cols = num_cols[1:]\n",
    "\n",
    "categories = [df[column].unique() for column in df[cat_cols]]\n",
    "\n",
    "categorical_encoder = preprocessing.OrdinalEncoder(categories=categories)\n",
    "categorical_encoder.fit(df[cat_cols])\n",
    "df[cat_cols] = categorical_encoder.transform(df[cat_cols])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c134b171",
   "metadata": {},
   "source": [
    "# Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d165d2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split (df, test_size=0.2)\n",
    "train, val = train_test_split (train, test_size=0.2)\n",
    "print(len(train), 'train examples')\n",
    "print(len(val), 'validation examples')\n",
    "print(len(test), 'test examples')\n",
    "\n",
    "train_labels = np.array (train.pop('Label'))\n",
    "bool_train_labels = train_labels != 0\n",
    "val_labels = np.array(val.pop('Label'))\n",
    "test_labels = np.array (test.pop('Label'))\n",
    "\n",
    "train_features = np.array(train)\n",
    "val_features = np.array(val)\n",
    "test_features = np.array(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9a9cb5",
   "metadata": {},
   "source": [
    "How imbalanced is the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87a9731",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg, pos = np.bincount(df['Label'])\n",
    "print (\"Negative Examples: {}\".format(neg))\n",
    "print (\"Positive Examples: {}\".format(pos))\n",
    "\n",
    "#dropping the labels columns\n",
    "df = df.drop(df.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35281cb8",
   "metadata": {},
   "source": [
    "# Scaling the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e59a8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the index of the numerical columns\n",
    "index = [df.columns.get_loc(c) for c in num_cols]\n",
    "index = np.array(index)\n",
    "\n",
    "cat_index = [df.columns.get_loc(c) for c in cat_cols]\n",
    "cat_index = np.array(index)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_features[:, index] = scaler.fit_transform(train_features[:, index])\n",
    "\n",
    "val_features[:, index] = scaler.transform(val_features[:, index])\n",
    "\n",
    "test_features[:, index] = scaler.transform(test_features[:, index])\n",
    "\n",
    "train_features[:, index] = np.clip(train_features[:, index], -5, 5)\n",
    "val_features[:, index] = np.clip(val_features[:, index], -5, 5)\n",
    "test_features[:, index] = np.clip(test_features[:, index], -5, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b127da0",
   "metadata": {},
   "source": [
    "# Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16c03ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]\n",
    "\n",
    "\n",
    "def make_model(metrics = METRICS, output_bias=None, hidden_layer_size=32):\n",
    "  \n",
    "    if output_bias is not None:\n",
    "        output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "   \n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(hidden_layer_size, activation='relu', input_shape=(train_features.shape[-1],)),#, kernel_initializer=initializer),\n",
    "        keras.layers.Dense(hidden_layer_size, activation='relu'),#, kernel_initializer=initializer),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(hidden_layer_size, activation='relu'),#, kernel_initializer=initializer),\n",
    "        keras.layers.Dense(1, activation='sigmoid', bias_initializer=output_bias)#, kernel_initializer=initializer)\n",
    "\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(lr=1e-3),\n",
    "        loss=keras.losses.BinaryCrossentropy(),\n",
    "        metrics=metrics)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f837fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model()\n",
    "BATCH_SIZE = 2048\n",
    "\n",
    "results = model.evaluate (train_features, train_labels, batch_size=BATCH_SIZE, verbose=0)\n",
    "print (\"Loss: {:0.4f}\".format(results[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6495ea7a",
   "metadata": {},
   "source": [
    "# Dealing with the Imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cce0287",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = pos + neg\n",
    "weight_for_0 = (1/neg)*(total)/2.0\n",
    "weight_for_1 = (1/pos)*(total)/2.0\n",
    "\n",
    "class_weight={0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76d24c7",
   "metadata": {},
   "source": [
    "# Running the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8460cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "#we need a bigger batch_size to reduce the effects of the imbalanced data\n",
    "BATCH_SIZE = 2048\n",
    "\n",
    "initial_bias = np.log([neg/pos])\n",
    "\n",
    "with tf.device (DEVICE):\n",
    "    weighted_model = make_model(output_bias=initial_bias)\n",
    "    weighted_history = weighted_model.fit(\n",
    "        train_features,\n",
    "        train_labels,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=(val_features, val_labels),\n",
    "        class_weight=class_weight)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8c4192",
   "metadata": {},
   "source": [
    "Plotting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d986aaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(history):\n",
    "  metrics =  ['loss', 'auc', 'precision', 'recall']\n",
    "  for n, metric in enumerate(metrics):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    plt.subplot(2,2,n+1)\n",
    "    plt.plot(history.epoch,  history.history[metric], color=colors[0], label='Train')\n",
    "    plt.plot(history.epoch, history.history['val_'+metric],\n",
    "             color=colors[0], linestyle=\"--\", label='Val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(name)\n",
    "    if metric == 'loss':\n",
    "      plt.ylim([0, plt.ylim()[1]])\n",
    "    elif metric == 'auc':\n",
    "      plt.ylim([0.8,1])\n",
    "    else:\n",
    "      plt.ylim([0,1])\n",
    "\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe60fc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(weighted_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f306a7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(labels, predictions, p=0.5):\n",
    "  cm = confusion_matrix(labels, predictions > p)\n",
    "  plt.figure(figsize=(5,5))\n",
    "  sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "  plt.title('Confusion matrix @{:.2f}'.format(p))\n",
    "  plt.ylabel('Actual label')\n",
    "  plt.xlabel('Predicted label')\n",
    "\n",
    "  print('Legitimate Transactions Detected (True Negatives): ', cm[0][0])\n",
    "  print('Legitimate Transactions Incorrectly Detected (False Positives): ', cm[0][1])\n",
    "  print('Fraudulent Transactions Missed (False Negatives): ', cm[1][0])\n",
    "  print('Fraudulent Transactions Detected (True Positives): ', cm[1][1])\n",
    "  print('Total Fraudulent Transactions: ', np.sum(cm[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45ce9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_predictions_weighted = weighted_model.predict(val_features, batch_size=BATCH_SIZE)\n",
    "\n",
    "weighted_results = weighted_model.evaluate(val_features, val_labels,\n",
    "                                  batch_size=BATCH_SIZE, verbose=0)\n",
    "for name, value in zip(weighted_model.metrics_names, weighted_results):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "plot_cm(val_labels, val_predictions_weighted)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
