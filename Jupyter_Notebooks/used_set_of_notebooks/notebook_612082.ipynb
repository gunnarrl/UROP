{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a4f7807",
   "metadata": {},
   "source": [
    "# Classifying Urban sounds using Deep Learning\n",
    "\n",
    "## 3 Model Training and Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1591cd65",
   "metadata": {},
   "source": [
    "### Load Preprocessed data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1329edcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the preprocessed data from previous notebook\n",
    "\n",
    "%store -r x_train \n",
    "%store -r x_test \n",
    "%store -r y_train \n",
    "%store -r y_test \n",
    "%store -r yy \n",
    "%store -r le"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75535d27",
   "metadata": {},
   "source": [
    "### Initial model architecture - MLP\n",
    "\n",
    "We will start with constructing a Multilayer Perceptron (MLP) Neural Network using Keras and a Tensorflow backend. \n",
    "\n",
    "Starting with a `sequential` model so we can build the model layer by layer. \n",
    "\n",
    "We will begin with a simple model architecture, consisting of three layers, an input layer, a hidden layer and an output layer. All three layers will be of the `dense` layer type which is a standard layer type that is used in many cases for neural networks. \n",
    "\n",
    "The first layer will receive the input shape. As each sample contains 40 MFCCs (or columns) we have a shape of (1x40) this means we will start with an input shape of 40. \n",
    "\n",
    "The first two layers will have 256 nodes. The activation function we will be using for our first 2 layers is the `ReLU`, or `Rectified Linear Activation`. This activation function has been proven to work well in neural networks.\n",
    "\n",
    "We will also apply a `Dropout` value of 50% on our first two layers. This will randomly exclude nodes from each update cycle which in turn results in a network that is capable of better generalisation and is less likely to overfit the training data.\n",
    "\n",
    "Our output layer will have 10 nodes (num_labels) which matches the number of possible classifications. The activation is for our output layer is `softmax`. Softmax makes the output sum up to 1 so the output can be interpreted as probabilities. The model will then make its prediction based on which option has the highest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45ede63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics \n",
    "import tensorflow as tf\n",
    "\n",
    "num_labels = yy.shape[1]\n",
    "filter_size = 2\n",
    "\n",
    "# Construct model \n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(256, input_shape=(40,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c6ff01",
   "metadata": {},
   "source": [
    "### Compiling the model \n",
    "\n",
    "For compiling our model, we will use the following three parameters: \n",
    "\n",
    "* Loss function - we will use `categorical_crossentropy`. This is the most common choice for classification. A lower score indicates that the model is performing better.\n",
    "\n",
    "* Metrics - we will use the `accuracy` metric which will allow us to view the accuracy score on the validation data when we train the model. \n",
    "\n",
    "* Optimizer - here we will use `adam` which is a generally good optimizer for many use cases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e5373a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca9c3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display model architecture summary \n",
    "model.summary()\n",
    "\n",
    "# Calculate pre-training accuracy \n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d504ce93",
   "metadata": {},
   "source": [
    "### Training \n",
    "\n",
    "Here we will train the model. \n",
    "\n",
    "We will start with 100 epochs which is the number of times the model will cycle through the data. The model will improve on each cycle until it reaches a certain point. \n",
    "\n",
    "We will also start with a low batch size, as having a large batch size can reduce the generalisation ability of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b869674",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint \n",
    "from datetime import datetime \n",
    "\n",
    "num_epochs = 100\n",
    "num_batch_size = 32\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.basic_mlp.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_test, y_test), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640a3e6c",
   "metadata": {},
   "source": [
    "### Test the model \n",
    "\n",
    "Here we will review the accuracy of the model on both the training and test data sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e88032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score[1])\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f77055",
   "metadata": {},
   "source": [
    "The initial Training and Testing accuracy scores are quite high. As there is not a great difference between the Training and Test scores (~5%) this suggests that the model has not suffered from overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e5bcec",
   "metadata": {},
   "source": [
    "### Predictions  \n",
    "\n",
    "Here we will build a method which will allow us to test the models predictions on a specified audio .wav file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95164d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa \n",
    "\n",
    "\n",
    "def extract_feature(file_name):\n",
    "   \n",
    "    try:\n",
    "        audio_data, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=40)\n",
    "        mfccsscaled = np.mean(mfccs.T,axis=0)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file)\n",
    "        return None, None\n",
    "\n",
    "    return np.array([mfccsscaled])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77f6c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_prediction(file_name):\n",
    "    prediction_feature = extract_feature(file_name) \n",
    "\n",
    "    predicted_vector = model.predict_classes(prediction_feature)\n",
    "    predicted_class = le.inverse_transform(predicted_vector) \n",
    "    print(\"The predicted class is:\", predicted_class[0], '\\n') \n",
    "\n",
    "    predicted_proba_vector = model.predict_proba(prediction_feature) \n",
    "    predicted_proba = predicted_proba_vector[0]\n",
    "    for i in range(len(predicted_proba)): \n",
    "        category = le.inverse_transform(np.array([i]))\n",
    "        print(category[0], \"\\t\\t : \", format(predicted_proba[i], '.32f') )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4acb84",
   "metadata": {},
   "source": [
    "### Validation \n",
    "\n",
    "#### Test with sample data \n",
    "\n",
    "Initial sainity check to verify the predictions using a subsection of the sample audio files we explored in the first notebook. We expect the bulk of these to be classified correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e787b222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class: Air Conditioner\n",
    "\n",
    "filename = '../UrbanSound8K/audio/fold5/100852-0-0-0.wav' \n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94670e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class: Drilling\n",
    "\n",
    "filename = '../UrbanSound8K/audio/fold3/103199-4-0-0.wav'\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f48c50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class: Street music \n",
    "\n",
    "filename = '../UrbanSound8K/audio/fold7/101848-9-0-0.wav'\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ddc549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class: Car Horn \n",
    "\n",
    "filename = '../UrbanSound8K/audio/fold10/100648-1-0-0.wav'\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ceb0366",
   "metadata": {},
   "source": [
    "#### Observations \n",
    "\n",
    "From this brief sanity check the model seems to predict well. One errror was observed whereby a car horn was incorrectly classifed as a dog bark. \n",
    "\n",
    "We can see from the per class confidence that this was quite a low score (43%). This allows follows our early observation that a dog bark and car horn are similar in spectral shape. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af95db3",
   "metadata": {},
   "source": [
    "### Other audio\n",
    "\n",
    "Here we will use a sample of various copyright free sounds that we not part of either our test or training data to further validate our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac226df",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Evaluation audio/dog_bark_1.wav'\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee7aae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Evaluation audio/drilling_1.wav'\n",
    "\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b16bb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Evaluation audio/gun_shot_1.wav'\n",
    "\n",
    "print_prediction(filename) \n",
    "\n",
    "# sample data weighted towards gun shot - peak in the dog barking sample is simmilar in shape to the gun shot sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2c4daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Evaluation audio/siren_1.wav'\n",
    "\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db1d900",
   "metadata": {},
   "source": [
    "#### Observations \n",
    "\n",
    "The performance of our initial model is satisfactorry and has generalised well, seeming to predict well when tested against new audio data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c4da2f",
   "metadata": {},
   "source": [
    "### *In the next notebook we will refine our model*"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
