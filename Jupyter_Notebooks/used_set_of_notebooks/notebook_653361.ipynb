{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "314b05b5",
   "metadata": {},
   "source": [
    "# Recurrent neural network and dynamical system analysis\n",
    "\n",
    "In this tutorial, we will use supervised learning to train a recurrent neural network on a parametric working memory task, and analyze the trained network using dynamical system analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2971c326",
   "metadata": {},
   "source": [
    "## Defining a cognitive task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e81ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install neurogym to use cognitive tasks\n",
    "# ! git clone https://github.com/gyyang/neurogym.git\n",
    "# %cd neurogym/\n",
    "# ! pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d567bd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import neurogym as ngym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89df7cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment\n",
    "task = 'DelayComparison-v0'\n",
    "timing = {'delay': ('choice', [200, 400, 800, 1600, 3200]),\n",
    "          'response': ('constant', 500)\n",
    "         }\n",
    "kwargs = {'dt': 100, 'timing': timing}\n",
    "seq_len = 100\n",
    "\n",
    "# Make supervised dataset\n",
    "dataset = ngym.Dataset(task, env_kwargs=kwargs, batch_size=16,\n",
    "                       seq_len=seq_len)\n",
    "\n",
    "# A sample environment from dataset\n",
    "env = dataset.env\n",
    "# Visualize the environment with 2 sample trials\n",
    "_ = ngym.utils.plot_env(env, num_trials=2, def_act=0)\n",
    "\n",
    "# Network input and output size\n",
    "input_size = env.observation_space.shape[0]\n",
    "output_size = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb1e978",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, target = dataset()\n",
    "mask = target > 0\n",
    "print(inputs.shape)   # (N_time, batch_size, N_neuron)\n",
    "print(target.shape)   # (N_time, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb3b226",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(target[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3e41f5",
   "metadata": {},
   "source": [
    "## Define a vanilla continuous-time recurrent network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc89c9fb",
   "metadata": {},
   "source": [
    "Here we will define a continuous-time neural network but discretize it in time using the Euler method.\n",
    "\\begin{align}\n",
    "    \\tau \\frac{d\\mathbf{r}}{dt} = -\\mathbf{r}(t) + f(W_r \\mathbf{r}(t) + W_x \\mathbf{x}(t) + \\mathbf{b}_r).\n",
    "\\end{align}\n",
    "\n",
    "This continuous-time system can then be discretized using the Euler method with a time step of $\\Delta t$, \n",
    "\\begin{align}\n",
    "    \\mathbf{r}(t+\\Delta t) = \\mathbf{r}(t) + \\Delta \\mathbf{r} = \\mathbf{r}(t) + \\frac{\\Delta t}{\\tau}[-\\mathbf{r}(t) + f(W_r \\mathbf{r}(t) + W_x \\mathbf{x}(t) + \\mathbf{b}_r)].\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02712fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define networks\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "from torch.nn import functional as F\n",
    "import math\n",
    "    \n",
    "\n",
    "class CTRNN(nn.Module):\n",
    "    \"\"\"Continuous-time RNN.\n",
    "\n",
    "    Args:\n",
    "        input_size: Number of input neurons\n",
    "        hidden_size: Number of hidden neurons\n",
    "\n",
    "    Inputs:\n",
    "        input: (seq_len, batch, input_size), network input\n",
    "        hidden: (batch, hidden_size), initial hidden activity\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, dt=None, **kwargs):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.tau = 100\n",
    "        if dt is None:\n",
    "            alpha = 1\n",
    "        else:\n",
    "            alpha = dt / self.tau\n",
    "        self.alpha = alpha\n",
    "        self.oneminusalpha = 1 - alpha\n",
    "\n",
    "        self.input2h = nn.Linear(input_size, hidden_size)\n",
    "        self.h2h = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "    def init_hidden(self, input_shape):\n",
    "        batch_size = input_shape[1]\n",
    "        return torch.zeros(batch_size, self.hidden_size)\n",
    "\n",
    "    def recurrence(self, input, hidden):\n",
    "        \"\"\"Recurrence helper.\"\"\"\n",
    "        pre_activation = self.input2h(input) + self.h2h(hidden)\n",
    "        h_new = torch.relu(hidden * self.oneminusalpha +\n",
    "                           pre_activation * self.alpha)\n",
    "        return h_new\n",
    "\n",
    "    def forward(self, input, hidden=None):\n",
    "        \"\"\"Propogate input through the network.\"\"\"\n",
    "        if hidden is None:\n",
    "            hidden = self.init_hidden(input.shape).to(input.device)\n",
    "\n",
    "        output = []\n",
    "        steps = range(input.size(0))\n",
    "        for i in steps:\n",
    "            hidden = self.recurrence(input[i], hidden)\n",
    "            output.append(hidden)\n",
    "\n",
    "        output = torch.stack(output, dim=0)\n",
    "        return output, hidden\n",
    "\n",
    "\n",
    "class RNNNet(nn.Module):\n",
    "    \"\"\"Recurrent network model.\n",
    "\n",
    "    Args:\n",
    "        input_size: int, input size\n",
    "        hidden_size: int, hidden size\n",
    "        output_size: int, output size\n",
    "        rnn: str, type of RNN, lstm, rnn, ctrnn, or eirnn\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, output_size, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        # Continuous time RNN\n",
    "        self.rnn = CTRNN(input_size, hidden_size, **kwargs)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        rnn_activity, _ = self.rnn(x)\n",
    "        out = self.fc(rnn_activity)\n",
    "        return out, rnn_activity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1475c0bf",
   "metadata": {},
   "source": [
    "## Train the recurrent network on the decision-making task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d91283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Instantiate the network and print information\n",
    "hidden_size = 64\n",
    "net = RNNNet(input_size=input_size, hidden_size=hidden_size,\n",
    "             output_size=output_size, dt=env.dt)\n",
    "print(net)\n",
    "\n",
    "# Use Adam optimizer\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "running_loss = 0\n",
    "running_acc = 0\n",
    "for i in range(2000):\n",
    "    inputs, labels_np = dataset()\n",
    "    labels_np = labels_np.flatten()\n",
    "    inputs = torch.from_numpy(inputs).type(torch.float)\n",
    "    labels = torch.from_numpy(labels_np).type(torch.long)\n",
    "\n",
    "    # in your training loop:\n",
    "    optimizer.zero_grad()   # zero the gradient buffers\n",
    "    output, _ = net(inputs)\n",
    "    output = output.view(-1, output_size)\n",
    "    loss = criterion(output, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()    # Does the update\n",
    "\n",
    "    running_loss += loss.item()\n",
    "    # Compute performance\n",
    "    output_np = np.argmax(output.detach().numpy(), axis=-1)\n",
    "    ind = labels_np > 0  # Only analyze time points when target is not fixation\n",
    "    running_acc += np.mean(labels_np[ind] == output_np[ind])\n",
    "    if i % 100 == 99:\n",
    "        running_loss /= 100\n",
    "        running_acc /= 100\n",
    "        print('Step {}, Loss {:0.4f}, Acc {:0.3f}'.format(i+1, running_loss, running_acc))\n",
    "        running_loss = 0\n",
    "        running_acc = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1961327",
   "metadata": {},
   "source": [
    "## Visualize neural activity for in sample trials\n",
    "\n",
    "We will run the network for 100 sample trials, then visual the neural activity trajectories in a PCA space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c39cf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "# Set delay to 3000ms for analysis\n",
    "kwargs = {'timing': {'delay': ('constant', 3000)}}\n",
    "env = gym.make(task, **kwargs)\n",
    "env.reset(no_step=True)\n",
    "env.timing\n",
    "\n",
    "perf = 0\n",
    "num_trial = 100\n",
    "activity_dict = {}\n",
    "trial_infos = {}\n",
    "for i in range(num_trial):\n",
    "    env.new_trial()\n",
    "    ob, gt = env.ob, env.gt\n",
    "    inputs = torch.from_numpy(ob[:, np.newaxis, :]).type(torch.float)\n",
    "    action_pred, rnn_activity = net(inputs)\n",
    "    rnn_activity = rnn_activity[:, 0, :].detach().numpy()\n",
    "    activity_dict[i] = rnn_activity[env.start_ind['delay']:env.end_ind['delay']]\n",
    "    trial_infos[i] = env.trial.copy()\n",
    "\n",
    "# Concatenate activity for PCA\n",
    "activity = np.concatenate(list(activity_dict[i] for i in range(num_trial)), axis=0)\n",
    "print('Shape of the neural activity: (Time points, Neurons): ', activity.shape)\n",
    "\n",
    "# Print trial informations\n",
    "for i in range(5):\n",
    "    print('Trial ', i, trial_infos[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c66079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute PCA and visualize\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(activity)\n",
    "# print('Shape of the projected activity: (Time points, PCs): ', activity_pc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272d8adb",
   "metadata": {},
   "source": [
    "Transform individual trials and Visualize in PC space based on ground-truth color. We see that the neural activity is organized by stimulus ground-truth in PC1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b386946f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True, sharex=True, figsize=(6, 3))\n",
    "for i in range(num_trial):\n",
    "    trial = trial_infos[i]\n",
    "    activity_pc = pca.transform(activity_dict[i])\n",
    "    \n",
    "    color = 'red' if trial['ground_truth'] == 1 else 'blue'\n",
    "    \n",
    "    _ = ax1.plot(activity_pc[:, 0], activity_pc[:, 1], 'o-', color=color)\n",
    "    \n",
    "    if i < 1:\n",
    "        _ = ax2.plot(activity_pc[:, 0], activity_pc[:, 1], 'o-', color=color)\n",
    "\n",
    "ax1.set_xlabel('PC 1')\n",
    "ax1.set_ylabel('PC 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2868c32b",
   "metadata": {},
   "source": [
    "## Dynamical system analysis\n",
    "\n",
    "### Search for approximate fixed points\n",
    "Here we search for approximate fixed points and visualize them in the same PC space. In a generic dynamical system,\n",
    "\\begin{align}\n",
    "    \\frac{d\\mathbf{x}}{dt} = F(\\mathbf{x}),\n",
    "\\end{align}\n",
    "We can search for fixed points by doing the optimization\n",
    "\\begin{align}\n",
    "    \\mathrm{argmin}_{\\mathbf{x}} |F(\\mathbf{x})|^2.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63da3cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a56c926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze for parameters in the recurrent network\n",
    "for param in net.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# Inputs should be the 0-coherence mean input during stimulus period\n",
    "# This will be task-specific\n",
    "input = np.tile([1, 0], (batch_size, 1))\n",
    "input = torch.tensor(input, dtype=torch.float32)\n",
    "\n",
    "# Here hidden activity is the variable to be optimized\n",
    "# Initialized randomly for search in parallel (activity all positive)\n",
    "# hidden_init = np.random.rand(batch_size, hidden_size)*3\n",
    "hidden_init = activity[np.random.randint(activity.shape[0], size=(batch_size,))]\n",
    "hidden_init = np.random.uniform(0.5, 1.5, size=hidden_init.shape) * hidden_init\n",
    "hidden = torch.tensor(hidden_init, requires_grad=True, dtype=torch.float32)\n",
    "\n",
    "# Use Adam optimizer\n",
    "optimizer = optim.Adam([hidden], lr=0.01)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "running_loss = 0\n",
    "for i in range(10000):\n",
    "    optimizer.zero_grad()   # zero the gradient buffers\n",
    "    \n",
    "    # Take the one-step recurrent function from the trained network\n",
    "    new_h = net.rnn.recurrence(input, hidden)\n",
    "    loss = criterion(new_h, hidden)\n",
    "    loss.backward()\n",
    "    optimizer.step()    # Does the update\n",
    "\n",
    "    running_loss += loss.item()\n",
    "    if i % 1000 == 999:\n",
    "        running_loss /= 1000\n",
    "        print('Step {}, Loss {:0.4f}'.format(i+1, running_loss))\n",
    "        running_loss = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06321c8",
   "metadata": {},
   "source": [
    "### Visualize the found approximate fixed points.\n",
    "\n",
    "We see that they found an approximate line attrator, corresponding to our PC1, along which evidence is integrated during the stimulus period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846bd483",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixedpoints = hidden.detach().numpy()\n",
    "print(fixedpoints.shape)\n",
    "\n",
    "# Plot in the same space as activity\n",
    "plt.figure()\n",
    "for i in range(5):\n",
    "    activity_pc = pca.transform(activity_dict[i])\n",
    "    trial = trial_infos[i]\n",
    "    color = 'red' if trial['ground_truth'] == 0 else 'blue'\n",
    "    plt.plot(activity_pc[:, 0], activity_pc[:, 1], 'o-',\n",
    "             color=color, alpha=0.1)\n",
    "\n",
    "# Fixed points are shown in cross\n",
    "fixedpoints_pc = pca.transform(fixedpoints)\n",
    "plt.plot(fixedpoints_pc[:, 0], fixedpoints_pc[:, 1], 'x')\n",
    "\n",
    "plt.xlabel('PC 1')\n",
    "plt.ylabel('PC 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85979236",
   "metadata": {},
   "source": [
    "### Computing the Jacobian and finding the line attractor\n",
    "\n",
    "First we will compute the Jacobian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef910b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index of fixed point to focus on\n",
    "# choose one close to center by sorting PC1\n",
    "i_fp = np.argsort(fixedpoints[:, 0])[int(fixedpoints.shape[0]/2)]\n",
    "\n",
    "fp = torch.from_numpy(fixedpoints[i_fp])\n",
    "fp.requires_grad = True\n",
    "\n",
    "# Inputs should be the 0-coherence mean input during stimulus period\n",
    "# This will be task-specific\n",
    "input = torch.tensor([1, 0], dtype=torch.float32)\n",
    "deltah = net.rnn.recurrence(input, fp) - fp\n",
    "\n",
    "jacT = torch.zeros(hidden_size, hidden_size)\n",
    "for i in range(hidden_size):                                                                                                                     \n",
    "    output = torch.zeros(hidden_size)                                                                                                          \n",
    "    output[i] = 1.                                                                                                                     \n",
    "    jacT[:,i] = torch.autograd.grad(deltah, fp, grad_outputs=output, retain_graph=True)[0]\n",
    "    \n",
    "jac = jacT.detach().numpy().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0a5f02",
   "metadata": {},
   "source": [
    "Here we plot the direction of the eigenvector corresponding to the highest eigenvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890f5140",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigval, eigvec = np.linalg.eig(jac)\n",
    "vec = np.real(eigvec[:, np.argmax(eigval)])\n",
    "end_pts = np.array([+vec, -vec]) * 10\n",
    "end_pts = pca.transform(fp.detach().numpy() + end_pts)\n",
    "\n",
    "# Plot in the same space as activity\n",
    "plt.figure()\n",
    "for i in range(5):\n",
    "    activity_pc = pca.transform(activity_dict[i])\n",
    "    trial = trial_infos[i]\n",
    "    color = 'red' if trial['ground_truth'] == 0 else 'blue'\n",
    "    plt.plot(activity_pc[:, 0], activity_pc[:, 1], 'o-',\n",
    "             color=color, alpha=0.1)\n",
    "\n",
    "# Fixed points are shown in cross\n",
    "fixedpoints_pc = pca.transform(fixedpoints)\n",
    "plt.plot(fixedpoints_pc[:, 0], fixedpoints_pc[:, 1], 'x')\n",
    "\n",
    "# Line attractor\n",
    "plt.plot(end_pts[:, 0], end_pts[:, 1])\n",
    "\n",
    "plt.xlabel('PC 1')\n",
    "plt.ylabel('PC 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c123d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of eigenvalues in a 2-d real-imaginary plot\n",
    "plt.figure()\n",
    "plt.scatter(np.real(eigval), np.imag(eigval))\n",
    "plt.plot([0, 0], [-1, 1], '--')\n",
    "plt.xlabel('Real')\n",
    "plt.ylabel('Imaginary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85398281",
   "metadata": {},
   "source": [
    "# Supplementary Materials\n",
    "\n",
    "Code for making publication quality figures as it appears in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9579231f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert information into pandas dataframe\n",
    "import pandas as pd\n",
    "df = pd.DataFrame()\n",
    "for i in range(len(trial_infos)):\n",
    "    df = df.append(trial_infos[i], ignore_index=True)\n",
    "# Example selection of conditions\n",
    "# print(df[df['f1']==22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1e7575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "plot_fp = True\n",
    "\n",
    "# Plot in the same space as activity\n",
    "# fig = plt.figure(figsize=(3, 3))\n",
    "fig, axes = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(4, 2))\n",
    "\n",
    "for i in range(2):\n",
    "    ax = axes[i]\n",
    "    plot_fp = i == 1\n",
    "#     ax = fig.add_axes([0.2, 0.2, 0.6, 0.6])\n",
    "\n",
    "    colors = np.array([[27,158,119], [117,112,179], [217,95,2]])/255.\n",
    "\n",
    "    # Search for two trials with similar conditions\n",
    "    values = np.unique(df['f1'])\n",
    "\n",
    "    color_intensity = [0.4, 0.7, 1.0, 1.3]\n",
    "    cmap = mpl.cm.get_cmap('winter')\n",
    "    if plot_fp:\n",
    "        alpha = 0.2\n",
    "    else:\n",
    "        alpha = 1.0\n",
    "    for i, val in enumerate(values):\n",
    "        trials = df[df['f1']==val].index\n",
    "        activity = np.mean(np.array([activity_dict[i] for i in trials]), axis=0)\n",
    "\n",
    "        activity_pc = pca.transform(activity)\n",
    "        label = '{:0.1f}'.format(val)\n",
    "        color = cmap(i/len(values))\n",
    "        ax.plot(activity_pc[:, 0], activity_pc[:, 1], 'o-',\n",
    "                 color=color, ms=3, markeredgecolor='none',\n",
    "                 lw=1, label=label, alpha=alpha)\n",
    "        ax.plot(activity_pc[0, 0], activity_pc[0, 1], 'o-', alpha=alpha,\n",
    "                marker='^', color=color, ms=5)\n",
    "\n",
    "    if plot_fp:\n",
    "        # Fixed points are shown in cross\n",
    "        color = colors[2]\n",
    "        fixedpoints_pc = pca.transform(fixedpoints)\n",
    "        ax.plot(fixedpoints_pc[:, 0], fixedpoints_pc[:, 1], 'x', ms=3, color=color, alpha=0.3)\n",
    "\n",
    "        # Line attractor\n",
    "        ax.plot(fixedpoints_pc[i_fp, 0], fixedpoints_pc[i_fp, 1], 'x', ms=5, color=color, lw=1)\n",
    "        ax.plot(end_pts[:, 0], end_pts[:, 1], color=color)\n",
    "    else:\n",
    "        ax.legend(title='Stimulus', loc='upper left', bbox_to_anchor=(1.0, 1.0), frameon=False)\n",
    "\n",
    "\n",
    "    ax.set_xlabel('PC 1', fontsize=7)\n",
    "    ax.set_ylabel('PC 2', fontsize=7)\n",
    "\n",
    "    # plt.xlim([-5, 5])\n",
    "    # plt.ylim([-1, 5])\n",
    "\n",
    "    # Beautification\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    # ax.spines['left'].set_position(('data', -5))\n",
    "    # ax.spines['bottom'].set_position(('data', -1.5))\n",
    "plt.tight_layout()\n",
    "plt.locator_params(nbins=2)\n",
    "from pathlib import Path\n",
    "# if plot_fp:\n",
    "#     fname = Path('figures/lineattractors_parametricWM')\n",
    "# else:\n",
    "#     fname = Path('figures/rnndynamics_parametricWM')\n",
    "fname = Path('figures/rnndynamics_parametricWM')\n",
    "fig.savefig(fname.with_suffix('.pdf'), transparent=True)\n",
    "fig.savefig(fname.with_suffix('.png'), dpi=300)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
