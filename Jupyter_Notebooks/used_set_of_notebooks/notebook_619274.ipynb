{"cells":[{"cell_type":"markdown","id":"1278f24c","metadata":{"id":"1278f24c"},"source":["# Generate crossvalidation"]},{"cell_type":"markdown","id":"50cb6468","metadata":{"id":"50cb6468"},"source":["## Preliminaries"]},{"cell_type":"markdown","id":"9fd25c20","metadata":{"id":"9fd25c20"},"source":["### Imports"]},{"cell_type":"code","execution_count":null,"id":"91485f22","metadata":{"id":"91485f22"},"outputs":[],"source":["# Imports\n","import joblib\n","import json\n","import pandas as pd\n","import os\n","import sys\n","\n","\n","from os.path import dirname\n","from joblib import Parallel, delayed\n","from sklearn.model_selection import KFold"]},{"cell_type":"code","execution_count":null,"id":"88009193","metadata":{"id":"88009193"},"outputs":[],"source":["# Custom imports\n","\n","root_dir = dirname(dirname(os.getcwd()))\n","src_dir = os.path.join(root_dir, 'src')\n","resc_dir = os.path.join(root_dir, 'resc')\n","libs_dir = os.path.join(root_dir, 'resc')\n","data_dir = os.path.join(resc_dir, 'data')\n","tidy_dir = os.path.join(data_dir, 'tidy')\n","\n","sys.path.append(libs_dir)\n","sys.path.append(src_dir)\n","\n","from exp.runner.RunMercs import RunMercs\n","from exp.runner.RunExp import RunExp\n","\n","from exp.utils import filesystem as fs"]},{"cell_type":"markdown","id":"69be0a72","metadata":{"id":"69be0a72"},"source":["### Global Variables"]},{"cell_type":"markdown","id":"82b1bee2","metadata":{"id":"82b1bee2"},"source":["## Basic Script\n","\n","Here I just try to achieve what I want, by any means required."]},{"cell_type":"markdown","id":"afe83403","metadata":{"id":"afe83403"},"source":["### Basic Methods"]},{"cell_type":"code","execution_count":null,"id":"12336b28","metadata":{"id":"12336b28"},"outputs":[],"source":["def build_single_csv(config, dataset):\n","    config['io']['dirs']['raw_dataset'] = fs.make_dname(name=dataset, parent_dir=config['io']['dirs']['raw'])\n","    config['io']['dirs']['data_dataset'] = fs.make_dname(name=dataset, parent_dir=config['io']['dirs']['input_data'])\n","\n","    config['io']['file']['raw'] = fs.make_fname(name=dataset,\n","                                                extension='csv',\n","                                                dname=config['io']['dirs']['raw_dataset'])\n","\n","    # Joining test, valid and train\n","    fnames = os.listdir(config['io']['dirs']['raw_dataset'])\n","    fnames = [os.path.join(config['io']['dirs']['raw_dataset'],f)\n","              for f in fnames\n","              if ('train' in f or 'test' in f or 'valid' in f)]\n","\n","    dfs = [pd.read_csv(f, header=None) for f in fnames]\n","\n","    # Join\n","    df_all=pd.concat(dfs)\n","\n","    # Drop constant columns (These for sure need to go.)\n","    df_all = drop_constant_columns(df_all)\n","\n","    # Save\n","    df_all.to_csv(config['io']['file']['raw'], header=None, index=False)\n","\n","    msg = \"\"\"\n","    Done building single csv for dataset:  {}\n","    \"\"\".format(dataset)\n","    #print(msg)\n","    return msg\n"]},{"cell_type":"code","execution_count":null,"id":"18c02f4a","metadata":{"id":"18c02f4a"},"outputs":[],"source":["def drop_constant_columns(df):\n","    for col in df:\n","        if df[col].nunique() < 2:\n","            df = df.drop([col], axis=1)\n","\n","    return df\n"]},{"cell_type":"code","execution_count":null,"id":"2c4bdc61","metadata":{"id":"2c4bdc61"},"outputs":[],"source":["def split_in_folds(config, dataset, **kwargs):\n","\n","    config['io']['dirs']['raw_dataset'] = fs.make_dname(name=dataset, parent_dir=config['io']['dirs']['raw'])\n","    config['io']['dirs']['data_dataset'] = fs.make_dname(name=dataset, parent_dir=config['io']['dirs']['input_data'])\n","\n","    fs.ensure_dir(config['io']['dirs']['data_dataset'])\n","\n","    config['io']['file']['raw'] = fs.make_fname(name=dataset,\n","                                                extension='csv',\n","                                                dname=config['io']['dirs']['raw_dataset'])\n","\n","    fname = config['io']['file']['raw']\n","    X = pd.read_csv(fname, header=None)\n","\n","    kf = KFold(**kwargs)\n","\n","    for f_idx, (train_idx, test_idx) in enumerate(kf.split(X)):\n","        dfs = {'Train': X.iloc[train_idx, :],\n","               'Test':  X.iloc[test_idx, :]}\n","\n","        for mode in ['Train', 'Test']:\n","            msg = [mode, fs.gen_appendix(f_idx, kind='fold')]\n","            fold_fname = fs.insert_msg_in_fname(fname, msg)\n","            fold_fname = fs.alter_directory_fname(fold_fname, config['io']['dirs']['data_dataset'])\n","\n","            dfs[mode].to_csv(fold_fname, header=None, index=False)\n","    return\n"]},{"cell_type":"code","execution_count":null,"id":"b01a3aad","metadata":{"id":"b01a3aad"},"outputs":[],"source":["def detect_constant_cols(directory):\n","\n","    ds_fnames = [os.path.join(directory, f) for f in os.listdir(directory)\n","                   if 'bayesfusion' not in f]\n","\n","    ds_train_fnames = [os.path.join(directory, f) for f in os.listdir(directory)\n","                       if 'Train' in f\n","                       if 'bayesfusion' not in f]\n","\n","    cte_cols = []\n","\n","    # Detect constant colums\n","    for ds_fn in ds_train_fnames:\n","        # Read\n","        df = pd.read_csv(ds_fn, header=None)\n","\n","        cte_cols_here = [c for c in df if df[c].nunique() < 2]\n","        cte_cols.extend(cte_cols_here)\n","\n","        del df\n","\n","    cte_cols = list(set(cte_cols))\n","\n","    print(cte_cols)\n","\n","    # Remove these cols everywhere\n","    for ds_fn in ds_fnames:\n","        df = pd.read_csv(ds_fn, header=None)\n","        for col in cte_cols:\n","            df = df.drop([col], axis=1)\n","\n","        df.to_csv(ds_fn, header=None, index=False)\n","        del df\n","\n","    msg = \"\"\"\n","    Finished directory: {}\n","    \"\"\".format(directory)\n","    #print(msg)\n","\n","    return msg\n"]},{"cell_type":"markdown","id":"54c57abe","metadata":{"id":"54c57abe"},"source":["## Actions\n","\n"]},{"cell_type":"markdown","id":"03e8e9b2","metadata":{"id":"03e8e9b2"},"source":["### Joining CSVs\n","\n","Probably I need do this better and use methods from the filesystem file in exp. (i.e. collect_files_from_folder). But for now, this seems to work"]},{"cell_type":"code","execution_count":null,"id":"32e1b586","metadata":{"id":"32e1b586"},"outputs":[],"source":["config = {}\n","config['io'] = {}\n","config['io']['dirs']={}\n","config['io']['file']={}"]},{"cell_type":"code","execution_count":null,"id":"33a0ccf3","metadata":{"id":"33a0ccf3"},"outputs":[],"source":["config['io']['dirs']['data'] = data_dir\n","config['io']['dirs']['raw'] = fs.make_dname(name='raw', parent_dir=config['io']['dirs']['data'])\n","config['io']['dirs']['input_data'] = fs.make_dname(name='tidy', parent_dir=config['io']['dirs']['data'])"]},{"cell_type":"code","execution_count":null,"id":"c6d41913","metadata":{"id":"c6d41913"},"outputs":[],"source":["datasets = os.listdir(config['io']['dirs']['raw'])\n","datasets.sort()\n","\n","for ds in datasets:\n","    build_single_csv(config, ds)\n","    msg = \"\"\"\n","    Done building dataset: {}\n","    \"\"\".format(ds)\n","    print(msg)"]},{"cell_type":"code","execution_count":null,"id":"a1997505","metadata":{"id":"a1997505"},"outputs":[],"source":["datasets = os.listdir(config['io']['dirs']['raw'])\n","datasets.sort()"]},{"cell_type":"code","execution_count":null,"id":"78152098","metadata":{"id":"78152098"},"outputs":[],"source":["Parallel(n_jobs=6)(delayed(build_single_csv)(config, ds)\n","                   for ds in datasets)"]},{"cell_type":"markdown","id":"f33cab11","metadata":{"id":"f33cab11"},"source":["### Split in folds\n","\n","Now we focus on creating the different folds."]},{"cell_type":"code","execution_count":null,"id":"7e3a568c","metadata":{"id":"7e3a568c"},"outputs":[],"source":["datasets = os.listdir(config['io']['dirs']['raw'])\n","datasets.sort()\n","for ds in datasets:\n","    split_in_folds(config, ds, n_splits=10, random_state=997, shuffle=True)\n","    msg = \"\"\"\n","    Done splitting dataset: {}\n","    \"\"\".format(ds)\n","    print(msg)"]},{"cell_type":"code","execution_count":null,"id":"04ab38bd","metadata":{"id":"04ab38bd"},"outputs":[],"source":["datasets = os.listdir(config['io']['dirs']['raw'])\n","datasets.sort()"]},{"cell_type":"code","execution_count":null,"id":"51fb0bbd","metadata":{"id":"51fb0bbd"},"outputs":[],"source":["Parallel(n_jobs=4)(delayed(split_in_folds)(config, ds, n_splits=10, random_state=997, shuffle=True)\n","                   for ds in datasets)"]},{"cell_type":"markdown","id":"fe9fb429","metadata":{"id":"fe9fb429"},"source":["## Checking for constant columns in training data\n","\n","These are not accepted in Bayesian Networks..."]},{"cell_type":"code","execution_count":null,"id":"bc01181d","metadata":{"id":"bc01181d"},"outputs":[],"source":["datasets = os.listdir(tidy_dir)\n","datasets.sort()\n","ds_dirs = [os.path.join(tidy_dir, ds) for ds in datasets]\n","ds_dirs"]},{"cell_type":"code","execution_count":null,"id":"e8e5cef3","metadata":{"id":"e8e5cef3"},"outputs":[],"source":["Parallel(n_jobs=6)(delayed(detect_constant_cols)(ds_dir) for ds_dir in ds_dirs)"]},{"cell_type":"markdown","id":"d4c54cac","metadata":{"id":"d4c54cac"},"source":["## Bayesfusionize\n","\n","Bayesfusion needs headers.."]},{"cell_type":"code","execution_count":null,"id":"21ae90ba","metadata":{"id":"21ae90ba"},"outputs":[],"source":["def read_modify_write(in_fname):\n","\n","    if 'bayesfusion' in in_fname:\n","        return\n","    elif '.csv' not in in_fname:\n","        return\n","    else:\n","        # Read\n","        df = pd.read_csv(in_fname, header=None)\n","\n","        # Modify\n","        bf_columns = [\"att_{}\".format(x) for x in df.columns.values]\n","        df.columns = bf_columns\n","\n","        # Write\n","        base, ext = os.path.splitext(in_fname)\n","        out_fname = base+\"_bayesfusion\"+ext\n","        df.to_csv(out_fname, index=False)\n","\n","        msg = \"\"\"\n","        Succesful modification of file: {}\n","        Results written to: {}\n","        \"\"\".format(in_fname, out_fname)\n","        #print(msg)\n","\n","    return"]},{"cell_type":"code","execution_count":null,"id":"f6b1bb1a","metadata":{"id":"f6b1bb1a"},"outputs":[],"source":["def bayesfusionize_dir(directory):\n","    ds_fnames = [os.path.join(directory, x) for x in os.listdir(directory)]\n","    ds_fnames.sort()\n","    for f in ds_fnames:\n","        read_modify_write(f)\n","    return \"Ready for Bayesfusion\""]},{"cell_type":"code","execution_count":null,"id":"11b40db4","metadata":{"id":"11b40db4"},"outputs":[],"source":["\n","\n","Parallel(n_jobs=6)(delayed(bayesfusionize_dir)(ds) for ds in ds_dirs)"]}],"metadata":{"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}