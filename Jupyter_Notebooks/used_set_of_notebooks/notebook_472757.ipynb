{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c9555c6",
   "metadata": {},
   "source": [
    "# Automated ML for time series predicion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2dd66e",
   "metadata": {},
   "source": [
    "We used one of the dataset in [Numenta Anomaly Benchmark (NAB)](https://github.com/numenta/NAB) for demo, i.e. NYC taxi passengers dataset, which contains 10320 records, each indicating the total number of taxi passengers in NYC at a corresonponding time spot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8b1304",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4baa1ce2",
   "metadata": {},
   "source": [
    "## 0. Helper function definations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79c1b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the predicted values and actual values (for the test data)\n",
    "def plot_result(test_df, pred_df):\n",
    "    # target column of dataframe is \"value\"\n",
    "    # past sequence length is 50\n",
    "    pred_value = pred_df[\"value\"].values\n",
    "    true_value = test_df[\"value\"].values[50:]\n",
    "    fig, axs = plt.subplots()\n",
    "\n",
    "    axs.plot(pred_value,color='red', label='predicted values')\n",
    "    axs.plot(true_value,color='blue', label='actual values')\n",
    "    axs.set_title('the predicted values and actual values (for the test data)')\n",
    "\n",
    "    plt.xlabel('test data index')\n",
    "    plt.ylabel('number of taxi passengers')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6a9c44",
   "metadata": {},
   "source": [
    "## 1. load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbf3e39",
   "metadata": {},
   "source": [
    "We have implemented load_nytaxi_data_df method to load nyc taxi data into train/val/test dataframe. You can change val_split_ratio, test_split_ratio and data_path as you want. Train/val/test dataframe all have two columns: \"datetime\" and \"value\", where \"value\" column is the target to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe60f5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "%pylab inline\n",
    "import seaborn\n",
    "import matplotlib.dates as md\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072d46dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load nyc taxi data\n",
    "from zoo.automl.common.util import load_nytaxi_data_df\n",
    "train_df, val_df, test_df = load_nytaxi_data_df(val_split_ratio=0.1, test_split_ratio=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43731e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedf2d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac9a2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape of the dataframe\n",
    "print(\"The shape of train_df is\", train_df.shape)\n",
    "print(\"The shape of val_df is\", val_df.shape)\n",
    "print(\"The shape of test_df is\", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff887c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualisation of anomaly throughout time in train_df\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "# pd.plotting.deregister_matplotlib_converters()\n",
    "\n",
    "ax.plot(train_df['datetime'], train_df['value'], color='blue', linewidth=0.6)\n",
    "ax.set_title('NYC taxi passengers throughout time')\n",
    "\n",
    "plt.xlabel('datetime')\n",
    "plt.xticks(rotation=45) \n",
    "plt.ylabel('The Number of NYC taxi passengers')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3c4d7a",
   "metadata": {},
   "source": [
    "## 2. Train and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79daa691",
   "metadata": {},
   "source": [
    "You can use analytices zoo automl to predict time series data by simply define a `TimeSequencePredictor`. Currently, our automl support searching feature combinations in a predefined feature space, and searching model hyper-parameters. Model selection is not supported yet.  \n",
    "\n",
    "We use feature tools to generate features from the given datetime. The generated features are \\['HOUR', 'DAY', 'MONTH'. 'IS_AWAKE', 'IS_BUSY_HOURS'\\]. Our feature space comprises these generated features as well as the original inputs such as \\['datetime','value'\\].  \n",
    "\n",
    "We use a vanilla LSTM model to predict time series data. The model search space contains the unit num of lstm layers ,dropout rate and hyper-parameters for training, such as batch_size, learning rate, etc. \n",
    "\n",
    "Currently, We use RNN to learn from 50 previous values, and predict just the 1 next value. You can specify the sequence length to predict while creating `TimeSequencePredictor` with arg: `future_seq_len`. The previous sequence length will be  considered as a tunable variable in our future version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2409b024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build time sequence predictor\n",
    "from zoo.automl.regression.time_sequence_predictor import TimeSequencePredictor\n",
    "\n",
    "# you need to specify the name of datetime column and target column\n",
    "# The default names are \"datetime\" and \"value\" respectively.\n",
    "tsp = TimeSequencePredictor(dt_col=\"datetime\",\n",
    "                            target_col=\"value\",\n",
    "                            extra_features_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62c697e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# fit train_df and validate with val_df, return the best trial as pipeline.\n",
    "# the default trail num is 10, need about 5.5 mins.\n",
    "pipeline = tsp.fit(train_df,\n",
    "                   validation_df=val_df,\n",
    "                   metric=\"mean_squared_error\")\n",
    "print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fa2fee",
   "metadata": {},
   "source": [
    "## 3. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81ac7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict test_df with the best trial\n",
    "pred_df = pipeline.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8802224",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49e87f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction value start from 50\n",
    "test_df[50:55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1e7f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate test_df\n",
    "mse, rs = pipeline.evaluate(test_df, metric=[\"mean_squared_error\", \"r_square\"])\n",
    "print(\"Evaluate: the mean square error is\", mse)\n",
    "print(\"Evaluate: the r_squared value is\", rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5336d1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the predicted values and actual values\n",
    "plot_result(test_df, pred_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db612803",
   "metadata": {},
   "source": [
    "## 4. save and restore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d3551d",
   "metadata": {},
   "source": [
    "We provide save and restore interface to save the pipeline with the best trial for easily rebuilding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3444097b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the pipeline with best trial\n",
    "saved_pipeline_file = \"../../../saved_pipeline/\"\n",
    "pipeline.save(saved_pipeline_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04f062d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new pipeline and specify the pipeline path to restore\n",
    "from zoo.automl.pipeline.time_sequence import TimeSequencePipeline\n",
    "\n",
    "new_pipeline = TimeSequencePipeline()\n",
    "new_pipeline.restore(saved_pipeline_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b073928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can do predict and evaluate again\n",
    "# to compare results before and after restore, we use test_df as input\n",
    "new_pred = new_pipeline.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06089bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pred.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc474017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate test_df\n",
    "mse, rs = new_pipeline.evaluate(test_df, metric=[\"mean_squared_error\", \"r_square\"])\n",
    "print(\"Evaluate: the mean square error is\", mse)\n",
    "print(\"Evaluate: the r_square value is\", rs)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
