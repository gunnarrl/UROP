{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e308047",
   "metadata": {},
   "source": [
    "# On this notebook the test and training sets will be defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa1a779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import scipy.optimize as spo\n",
    "import sys\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (20.0, 10.0)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7aed62",
   "metadata": {},
   "source": [
    "## Let's test the scikit learn example for TimeSeriesSplit (with some modifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d67670",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "num_samples = 30\n",
    "dims = 2\n",
    "\n",
    "X = np.random.random((num_samples,dims))\n",
    "y = np.array(range(num_samples))\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "print(tscv)  \n",
    "TimeSeriesSplit(n_splits=3)\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    print(\"TRAIN_indexes:\", train_index, \"TEST_indexes:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae12a42e",
   "metadata": {},
   "source": [
    "### It may be useful for validation purposes. The test set will be separated before, anyway. The criterion to follow is to always keep causality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d2a0e8",
   "metadata": {},
   "source": [
    "## Let's get the data and preserve one part as the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4e2b1c",
   "metadata": {},
   "source": [
    "Note: The way the test set will be used, is still not defined. Also, the definition of X and y may depend on the length of the base time interval used for training. But, in any case, it is a good practise to separate a fraction of the data for test, that will be untouched regardless of all those decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9842e854",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_pickle('../../data/data_df.pkl')\n",
    "print(data_df.shape)\n",
    "data_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05043a38",
   "metadata": {},
   "source": [
    "### I will save about two years worth of data for the test set (it wouldn't be correct to save a fixed fraction of the total set because the size of the \"optimal\" training set is still to be defined; I may end up using much less than the total dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75162d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_samples = 252 * 2\n",
    "\n",
    "data_train_val_df, data_test_df = data_df.unstack().iloc[:-num_test_samples], data_df.unstack().iloc[-num_test_samples:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed5735e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_df_basic(df):\n",
    "    print(df.shape)\n",
    "    print('Starting value: %s\\nEnding value: %s' % (df.index.get_level_values(0)[0], df.index.get_level_values(0)[-1]))\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b6fbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_df_basic(data_train_val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e71ab23",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_df_basic(data_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc997cc4",
   "metadata": {},
   "source": [
    "### I could select the Close values, for example, like below..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6710a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_df.loc[slice(None),(slice(None),'Close')].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f5c1b1",
   "metadata": {},
   "source": [
    "### Or like this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b31df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_df.xs('Close', level=1, axis=1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a43b03",
   "metadata": {},
   "source": [
    "### But I think it will be more clear if I swap the levels in the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ec21dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_val_df = data_train_val_df.swaplevel(0, 1, axis=1).stack().unstack()\n",
    "show_df_basic(data_train_val_df)\n",
    "data_test_df = data_test_df.swaplevel(0, 1, axis=1).stack().unstack()\n",
    "show_df_basic(data_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f686efb",
   "metadata": {},
   "source": [
    "## Now it's very easy to select one of the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd626e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_val_df['Close']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5bf21b",
   "metadata": {},
   "source": [
    "## Let's pickle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02277de",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_val_df.to_pickle('../../data/data_train_val_df.pkl')\n",
    "data_test_df.to_pickle('../../data/data_test_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b863f5",
   "metadata": {},
   "source": [
    "## No validation set will be needed as I will use \"time\" cross-validation for that."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
