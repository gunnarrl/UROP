{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9b050a8",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    "\n",
    "Let's say we have an equation and its derivative : <br><br>\n",
    "$f(x) = x^{2}$ &ensp; &ensp; &ensp; $\\frac{dy}{dx} = 2x$<br><br>\n",
    "\n",
    "We can get the lowest value of x using the equation : <br><br>\n",
    "$x_{new} = x_{old} - \\alpha(2x_{old})$ $\n",
    "\\begin{bmatrix}\n",
    "\\ 1 \\\\\n",
    "\\ 1 - 0.1(2)(1) = 0.8 \\\\\n",
    "\\ 0.8 - 0.1(2)(0.8) = 0.64 \\\\\n",
    "\\ 0.64 - 0.1(2)(0.64) = 0.512 \\\\\n",
    "\\vdots \\\\\n",
    "\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdfbdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 10\n",
    "derivative = []\n",
    "y = []\n",
    "\n",
    "for i in range(1000):\n",
    "    old_value = x\n",
    "    y.append(old_value ** 2)\n",
    "    derivative.append(old_value - 0.01 * 2 * old_value)\n",
    "    x = old_value - 0.01 * 2 * old_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1585e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a4953b",
   "metadata": {},
   "source": [
    "Gradient descent is dependent on the running rate $\\alpha$ and the number of loops. If $\\alpha$ and running rate is too small, we will not be able to reach the minimum value, and it is time-inefficient.\n",
    "\n",
    "Same is true if the parameters are too big."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45382f2",
   "metadata": {},
   "source": [
    "## Linear Regression with Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9636e70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61b572c",
   "metadata": {},
   "source": [
    "### 1. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568c89f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe\n",
    "df = pd.read_csv('slr06.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993b91e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape the x_column\n",
    "raw_X = df[\"X\"].values.reshape(-1, 1)\n",
    "y = df[\"Y\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ae19a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8d5b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the values\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(raw_X, y, 'o', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382e5493",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preview the data points\n",
    "raw_X[:5], y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de62f548",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill the first column of raw_X with ones\n",
    "np.ones((len(raw_X),1))[:3]\n",
    "X = np.concatenate( (np.ones((len(raw_X),1)), raw_X ), axis=1)\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac8f413",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.random.normal((2,1)) \n",
    "# w = np.array([5,3]) w is theta\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9c6239",
   "metadata": {},
   "source": [
    "**Note**: w[0] is the expected intercept and w[1] is the expected slope. The reason why we have the first column of X filled with ones is because we want to dot product X and w, where the first column of X is 1 and the first column of w is just the expected intercept (multiplication of the two yields just the intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6ee079",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "y_predict = np.dot(X, w)\n",
    "plt.plot(raw_X,y,'o', color='blue', alpha=0.5) #raw_X and y are from the dataset we imported\n",
    "plt.plot(raw_X,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c1fad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d8e11c",
   "metadata": {},
   "source": [
    "### 2. Hypothesis and Cost Function\n",
    "\n",
    "Hypothesis function : \n",
    "$$\\large h_{\\theta}(x^{(i)})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b586e9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypothesis_function(X, theta):\n",
    "    \"\"\"\n",
    "    input: matrix X and theta values\n",
    "    output: expected values of y from matrix X and theta values\n",
    "    \"\"\"\n",
    "    return X.dot(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7a7f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a vector containing expected values of y from random weight values\n",
    "# note that this is the same as y_predict values from section 1\n",
    "h = hypothesis_function(X,w)\n",
    "h[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052928ec",
   "metadata": {},
   "source": [
    "Cost function is as follows : \n",
    "\n",
    "$$\\large J(w_0, w_1) = \\large \\frac{1}{2m} \\sum\\limits_{i=1}^m (h_{\\theta}(x^{(i)}) - y^{(i)})^{2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d62e855",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(h, y):\n",
    "    \"\"\"\n",
    "    input: hypothesis function and y-values\n",
    "    output: cost_function output\n",
    "    \"\"\"\n",
    "    return (1/(2*len(y))) * np.sum((h-y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a61b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = hypothesis_function(X,w)\n",
    "cost_function(h, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7177be",
   "metadata": {},
   "source": [
    "### 3. Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4836a889",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, w, alpha, iterations):\n",
    "    theta = w\n",
    "    m = len(y)\n",
    "    \n",
    "    theta_list = [theta.tolist()]\n",
    "    cost = cost_function(hypothesis_function(X, theta), y)\n",
    "    cost_list = [cost]\n",
    "\n",
    "    for i in range(iterations):\n",
    "        t0 = theta[0] - (alpha / m) * np.sum(np.dot(X, theta) - y)\n",
    "        t1 = theta[1] - (alpha / m) * np.sum((np.dot(X, theta) - y) * X[:,1])\n",
    "        theta = np.array([t0, t1])\n",
    "        \n",
    "        if i % 10== 0:\n",
    "            theta_list.append(theta.tolist())\n",
    "            cost = cost_function(hypothesis_function(X, theta), y)\n",
    "            cost_list.append(cost)\n",
    "\n",
    "\n",
    "    return theta, theta_list, cost_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45aab0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 10000\n",
    "alpha = 0.001\n",
    "\n",
    "theta, theta_list, cost_list = gradient_descent(X, y, w, alpha, iterations)\n",
    "cost = cost_function(hypothesis_function(X, theta), y)\n",
    "\n",
    "print(\"theta:\", theta)\n",
    "print('cost:', cost_function(hypothesis_function(X, theta), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d038e592",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_list = np.array(theta_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65bfc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "y_predict_step= np.dot(X, theta_list.transpose())\n",
    "\n",
    "y_predict_step\n",
    "plt.plot(raw_X,y,\"o\", alpha=0.5)\n",
    "for i in range (0,len(cost_list),100):\n",
    "    plt.plot(raw_X,y_predict_step[:,i], label='Line %d'%i)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
