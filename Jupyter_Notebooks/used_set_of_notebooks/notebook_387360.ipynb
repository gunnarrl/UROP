{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6abb8ac",
   "metadata": {},
   "source": [
    "# import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be863686",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def read_feature(folder, num):\n",
    "    filename = glob.glob(os.path.join(folder, '*'))\n",
    "    img_arr = np.zeros([len(filename), 100, 100, 3])\n",
    "    label = num * np.ones(len(filename), dtype=\"float32\")\n",
    "    for i, name in enumerate(filename):\n",
    "        img = Image.open(name)\n",
    "        img_arr[i, :, :, :] = np.asarray(img, dtype=\"uint8\")\n",
    "    return img_arr, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac34ada8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_img_arr, tb_label = read_feature('./TB_Image', 1)\n",
    "non_tb_img_arr, non_tb_label = read_feature('./Non-TB_Image', 0)\n",
    "images = np.concatenate((tb_img_arr, non_tb_img_arr))\n",
    "labels = np.concatenate((tb_label, non_tb_label))\n",
    "\n",
    "print(np.shape(images))\n",
    "print(np.shape(labels))\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.1)\n",
    "\n",
    "X_train = X_train.astype(np.int)\n",
    "X_val = X_val.astype(np.int)\n",
    "y_train = y_train.astype(np.int)\n",
    "y_val = y_val.astype(np.int)\n",
    "\n",
    "# change into one-hot vector\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 2) \n",
    "y_val = tf.keras.utils.to_categorical(y_val, 2)\n",
    "\n",
    "# reshape dataset\n",
    "X_train = X_train.reshape(X_train.shape[0], 100, 100, 3)\n",
    "X_val = X_val.reshape(X_val.shape[0], 100, 100, 3)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print('Training data shape', X_train.shape)\n",
    "_, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(X_train[0].reshape(100, 100, 3), cmap=plt.cm.Greys);\n",
    "ax2.imshow(X_train[1].reshape(100, 100, 3), cmap=plt.cm.Greys);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b73bf81",
   "metadata": {},
   "source": [
    "## Define trainning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312ea050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data(model):\n",
    "    loss = []\n",
    "    acc = []\n",
    "    val_loss = []\n",
    "    val_acc = []\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=3)\n",
    "    tensorboard = tf.keras.callbacks.TensorBoard(log_dir='logs/{}'.format('model_name'))\n",
    "    hist = model.fit(X_train, y_train,\n",
    "                     batch_size=64,\n",
    "                     epochs=50,  # Run thru all the data point in each epoch\n",
    "                     verbose=1,\n",
    "                     validation_data=(X_val, y_val),\n",
    "                     #callbacks=[tensorboard])\n",
    "                     callbacks=[early_stop, tensorboard])\n",
    "    #val_err.append(hist.history['val_mean_absolute_error'][-1]) # a dict\n",
    "    loss.append(hist.history['loss'][-1])\n",
    "    val_loss.append(hist.history['val_loss'][-1])\n",
    "    acc.append(hist.history['acc'][-1])\n",
    "    val_acc.append(hist.history['val_acc'][-1])   \n",
    "    \n",
    "    return loss, val_loss, hist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5925713e",
   "metadata": {},
   "source": [
    "## Define a VGG network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5de0422",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG(activ):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(64, (3,3), padding='same', activation=activ, input_shape=(100, 100, 3)),\n",
    "        tf.keras.layers.MaxPool2D(padding='same'),\n",
    "\n",
    "        tf.keras.layers.Conv2D(128, (3,3), padding='same', activation=activ),\n",
    "        tf.keras.layers.MaxPool2D(padding='same'),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(256, (3,3), padding='same', activation=activ),\n",
    "        tf.keras.layers.Conv2D(256, (3,3), padding='same', activation=activ),\n",
    "        tf.keras.layers.MaxPool2D(padding='same'),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(512, (3,3), padding='same', activation=activ),\n",
    "        tf.keras.layers.Conv2D(512, (3,3), padding='same', activation=activ),\n",
    "        tf.keras.layers.MaxPool2D(padding='same'),\n",
    "\n",
    "        tf.keras.layers.Conv2D(512, (3,3), padding='same', activation=activ),\n",
    "        tf.keras.layers.Conv2D(512, (3,3), padding='same', activation=activ),\n",
    "        tf.keras.layers.MaxPool2D(padding='same'),\n",
    "\n",
    "\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(4096, activation=activ),\n",
    "        tf.keras.layers.Dense(4096, activation=activ),\n",
    "        tf.keras.layers.Dense(1000, activation=activ),\n",
    "        tf.keras.layers.Dense(2, activation='softmax')\n",
    "    ])\n",
    "    param = model.count_params()\n",
    "    model.compile(optimizer=tf.train.AdamOptimizer(0.000001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "   \n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    return model, param"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc5b1b2",
   "metadata": {},
   "source": [
    "## Define a DNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01493c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnnmodel(n, activ):\n",
    "    param = []\n",
    "    model = tf.keras.Sequential([])\n",
    "    model.add(tf.keras.layers.Flatten(input_shape=(100, 100, 3)))\n",
    "    for i in range(n):\n",
    "        model.add(tf.keras.layers.Dense(100, activation=activ))\n",
    "    model.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
    "    # model.summary()\n",
    "    # model.count_params()\n",
    "    param.append(model.count_params())\n",
    "    model.compile(optimizer=tf.train.AdamOptimizer(0.000001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy', 'mae'])\n",
    "    return model, param"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22392b1a",
   "metadata": {},
   "source": [
    "## Trainning with VGG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df6452e",
   "metadata": {},
   "source": [
    "### VGG with activation \"relu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cbdc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "activ = 'relu'\n",
    "model_VGG1, param_VGG1 = VGG(activ)\n",
    "loss_VGG1, val_loss_VGG1, hist_VGG1= train_data(model_VGG1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a173fd3f",
   "metadata": {},
   "source": [
    "### Define the function for plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bf54ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acc_and_loss(hist):\n",
    "    acc = hist.history['acc']\n",
    "    loss = hist.history['loss']\n",
    "    val_acc = hist.history['val_acc']\n",
    "    val_loss = hist.history['val_loss']\n",
    "    \n",
    "    plt.plot(acc, 'r-o')\n",
    "    plt.title(\"Trainning accuracy\")\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(loss, 'g-o')\n",
    "    plt.title(\"Trainning loss\")\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(val_acc, 'b-o')\n",
    "    plt.title(\"Validation accuracy\")\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(val_loss, 'm-o')\n",
    "    plt.title(\"Validation loss\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed71935d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acc_and_loss(hist_VGG1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb79c3e",
   "metadata": {},
   "source": [
    "### Calculate sensitivity and specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c47627",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "predictions = model_VGG1.predict(X_val)\n",
    "y_val = np.argmax(y_val, axis=-1)\n",
    "predictions = np.argmax(predictions, axis=-1)\n",
    "c = confusion_matrix(y_val, predictions)\n",
    "print('Confusion matrix:\\n', c)\n",
    "print('sensitivity', c[0, 0] / (c[0, 1] + c[0, 0]))\n",
    "print('specificity', c[1, 1] / (c[1, 1] + c[1, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3e918a",
   "metadata": {},
   "source": [
    "### VGG with activation \"relu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0c2ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "activ = 'tanh'\n",
    "model_VGG2, param_VGG2 = VGG(activ)\n",
    "loss_VGG2, val_loss_VGG2, hist_VGG2= train_data(model_VGG2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86711908",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acc_and_loss(hist_VGG2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e087098",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_VGG2.predict(X_val)\n",
    "y_val1 = np.argmax(y_val, axis=-1)\n",
    "predictions = np.argmax(predictions, axis=-1)\n",
    "c = confusion_matrix(y_val1, predictions)\n",
    "print('Confusion matrix:\\n', c)\n",
    "print('sensitivity', c[0, 0] / (c[0, 1] + c[0, 0]))\n",
    "print('specificity', c[1, 1] / (c[1, 1] + c[1, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b64bb96",
   "metadata": {},
   "source": [
    "## DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba022d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "activ = 'relu'\n",
    "model_DNN, param1_DNN = dnnmodel(15, activ)\n",
    "loss_DNN, val_loss_DNN, hist_DNN= train_data(model_DNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c72831",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acc_and_loss(hist_DNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c50e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_DNN.predict(X_val)\n",
    "y_val1 = np.argmax(y_val, axis=-1)\n",
    "predictions = np.argmax(predictions, axis=-1)\n",
    "c = confusion_matrix(y_val1, predictions)\n",
    "print('Confusion matrix:\\n', c)\n",
    "print('sensitivity', c[0, 0] / (c[0, 1] + c[0, 0]))\n",
    "print('specificity', c[1, 1] / (c[1, 1] + c[1, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77d0cc3",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf52366b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "def resnet():\n",
    "    input_tensor = tf.keras.layers.Input(shape=(100, 100, 3))\n",
    "    model = ResNet50(include_top=True, weights=None, input_tensor=input_tensor, input_shape=None, pooling=None, classes=2)\n",
    "    param = model.count_params()\n",
    "    model.compile(optimizer=tf.train.AdamOptimizer(0.00001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model, param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de0575d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet, param_resnet = resnet()\n",
    "loss_resnet, val_loss_resnet, hist_resnet= train_data(model_resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5286c70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acc_and_loss(hist_resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b93f749",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_resnet.predict(X_val)\n",
    "y_val1 = np.argmax(y_val, axis=-1)\n",
    "predictions = np.argmax(predictions, axis=-1)\n",
    "c = confusion_matrix(y_val1, predictions)\n",
    "print('Confusion matrix:\\n', c)\n",
    "print('sensitivity', c[0, 0] / (c[0, 1] + c[0, 0]))\n",
    "print('specificity', c[1, 1] / (c[1, 1] + c[1, 0]))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
