{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45d7967e",
   "metadata": {},
   "source": [
    "## Linear regression with one variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6230e577",
   "metadata": {},
   "source": [
    "### Assignment 2.1: Plotting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48644024",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "train_data = np.genfromtxt('ex1data1.txt', delimiter=',')\n",
    "print(\"Dimentions of training samples: [%d\" % train_data.shape[0], \", %d]\" % train_data.shape[1])\n",
    "\n",
    "X = train_data[:, 0]\n",
    "y = train_data[:, 1]\n",
    "m = y.shape[0]\n",
    "print(\"Size of training samples: %d\" % m)\n",
    "\n",
    "X = X.reshape(m, 1)\n",
    "y = y.reshape(m, 1)\n",
    "\n",
    "# Scatter plot\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.xlabel(\"Population of city in 10,000s\")\n",
    "plt.ylabel(\"Profit in $10,000s\")\n",
    "plt.title(\"Scatter plot of training data\")\n",
    "plt.plot(X, y, 'rx');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9015726",
   "metadata": {},
   "source": [
    "### Assignment 2.2: Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bb448d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Method to compute Cost Function\n",
    "def compute_cost(X, y, theta):\n",
    "    diff = X.dot(theta) - y\n",
    "    ssq = np.sum(diff**2)\n",
    "    return ssq / (2 * m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4880a261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add one additional column of all ones to X representing x0\n",
    "x0 = np.ones((m, 1))\n",
    "original_X = X\n",
    "X = np.append(x0, X, axis=1)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bc4388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize thetas to zeros\n",
    "# Iteration count to 1500\n",
    "# Alpha to 0.01\n",
    "theta = np.zeros((2, 1))\n",
    "iterations = 1500\n",
    "alpha = 0.01\n",
    "\n",
    "# Tests on compute_cost\n",
    "J = compute_cost(X, y, theta)\n",
    "print(\"Expected cost value 32.07; Calculated cost value %f\" % J)\n",
    "\n",
    "theta_temp = np.array([[-1], [2]])\n",
    "J = compute_cost(X, y, theta_temp)\n",
    "print(\"Expected cost value 54.24; Calculated cost value %f\" % J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe06ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to calculate gradient descent\n",
    "def gradient_descent(X, y, theta, alpha, num_iters):\n",
    "    J_history = np.zeros(num_iters)\n",
    "    for step in range(num_iters):\n",
    "        if step >= 1:\n",
    "            theta_0 = theta[0, 0] - alpha * np.sum(X.dot(theta) - y) / m\n",
    "            theta_1 = theta[1, 0] - alpha * np.sum((X.dot(theta) - y) * X) / m\n",
    "            theta[0, 0] = theta_0\n",
    "            theta[1, 0] = theta_1\n",
    "        J_curr = compute_cost(X, y, theta)\n",
    "        J_history[step - 1] = J_curr\n",
    "        print(\"Current Cost Value %f\" % J_curr)\n",
    "    return theta\n",
    "        \n",
    "# Calculate theta\n",
    "theta = gradient_descent(X, y, theta, alpha, iterations)\n",
    "print(\"\\nObtained theta values: \")\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c9a7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "### Plot the resultant linear regression \n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.xlabel(\"Population of city in 10,000s\")\n",
    "plt.ylabel(\"Profit in $10,000s\")\n",
    "plt.title(\"Scatter plot of training data\")\n",
    "plt.plot(original_X, y, 'rx', X[:, 1], X.dot(theta), 'b-', lw=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d1138c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Predictions\n",
    "test1 = np.array([1, 3.5]).reshape(1, 2)\n",
    "test2 = np.array([1, 7]).reshape(1, 2)\n",
    "predict1 = test1.dot(theta)\n",
    "print('For population = 35,000, we predict a profit of %f\\n' % (predict1 * 10000))\n",
    "predict2 = test2.dot(theta)\n",
    "print('For population = 70,000, we predict a profit of %f\\n' % (predict2 * 10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc56882",
   "metadata": {},
   "source": [
    "### Assignment 2.4: Visualizing J(Î¸)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8aa528",
   "metadata": {},
   "source": [
    "## Linear regression with multiple variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed2e9aa",
   "metadata": {},
   "source": [
    "### Assignment 3.1: Feature Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536f96e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "data_multi = np.genfromtxt('ex1data2.txt', delimiter=',')\n",
    "print(\"Dimentions of training samples: [%d\" % data_multi.shape[0], \", %d]\" % data_multi.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98624c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_multi = data_multi[:, 0:2]\n",
    "print(X_multi.shape)\n",
    "y = data_multi[:, 2]\n",
    "multi = y.shape[0]\n",
    "print(\"Size of training samples: %d\" % multi)\n",
    "\n",
    "y = y.reshape(multi, 1)\n",
    "\n",
    "print('First 10 examples from the dataset: \\n')\n",
    "print(X_multi[0:10,:])\n",
    "print(y[0:10,:])\n",
    "\n",
    "def featureNormalize(X):\n",
    "    X_norm = X\n",
    "    mu = np.mean(X, axis = 0)\n",
    "    sigma = np.std(X, axis = 0)\n",
    "    # Tile rows together for matrix operations\n",
    "    mu_matrix = np.tile(mu, (X.shape[0], 1))\n",
    "    sigma_matrix = np.tile(sigma, (X.shape[0], 1))\n",
    "    X_norm = (X_norm - mu_matrix) / sigma_matrix\n",
    "    mu = mu.reshape(1, X.shape[1])\n",
    "    sigma = sigma.reshape(1, X.shape[1])\n",
    "    return X_norm, mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5560cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm, mu, sigma = featureNormalize(X_multi)\n",
    "print(mu)\n",
    "print(sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c475eb94",
   "metadata": {},
   "source": [
    "### Assignment 3.2: Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743fdeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add x0 column into training dataset\n",
    "x0 = np.ones((multi, 1))\n",
    "original_X_multi = X_norm\n",
    "X_norm = np.append(x0, X_norm, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5818456",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Method to calculate cost value for multi-variant\n",
    "def compute_cost_multi(X, y, theta):\n",
    "    T = X.dot(theta) - y\n",
    "    return np.transpose(T).dot(T) / (2 * multi)\n",
    "    \n",
    "### Method to calculate gradient descent for multi-variant\n",
    "def gradient_descent_multi(X, y, theta, alpha, num_iters):\n",
    "    J_history = np.zeros(num_iters)\n",
    "    for step in range(num_iters):\n",
    "        delta = (1 / multi) * np.sum(X * np.tile((X.dot(theta) - y), (1, X.shape[1])))\n",
    "        theta = np.transpose(np.transpose(theta) - alpha * delta)\n",
    "        J_curr = compute_cost_multi(X, y, theta)\n",
    "        J_history[step - 1] = J_curr\n",
    "        print(\"Current Cost Value %f\" % J_curr)\n",
    "    return theta\n",
    "\n",
    "theta = np.zeros((X_norm.shape[1], 1))\n",
    "iterations = 1500\n",
    "alpha = 0.01\n",
    "\n",
    "theta = gradient_descent_multi(X_norm, y, theta, alpha, iterations)\n",
    "print(theta)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
