{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01324fd3",
   "metadata": {},
   "source": [
    "# Version of DogFaceNet implementation for MNIST dataset\n",
    "We will train to stick on the pairs learning technique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11460d9",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f99a101",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import skimage as sk\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80ed87b",
   "metadata": {},
   "source": [
    "### Dataset implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ad497c",
   "metadata": {},
   "source": [
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b022391e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "SIZE = (28,28)\n",
    "PATH_SAVE = '../output/history/'\n",
    "\n",
    "x_train = x_train.astype(np.float32)\n",
    "x_test = x_test.astype(np.float32)\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b0ad45",
   "metadata": {},
   "source": [
    "Create the triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3035d4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbof_triplets = len(y_train)\n",
    "\n",
    "triplets = np.empty((nbof_triplets,28,28))\n",
    "y_triplets = np.empty(nbof_triplets)\n",
    "issame = np.empty(nbof_triplets)\n",
    "\n",
    "for i in tqdm_notebook(range(0,nbof_triplets,3)):\n",
    "    # Pair of same classes\n",
    "    # Chose a class\n",
    "    clas = np.random.randint(10)\n",
    "    y_class = np.arange(len(y_train))[np.equal(y_train,clas)]\n",
    "\n",
    "    # Select two images from this class\n",
    "    idx_image1 = y_class[np.random.randint(len(y_class))]\n",
    "    idx_image2 = y_class[np.random.randint(len(y_class))]\n",
    "    while idx_image1 == idx_image2:\n",
    "        idx_image2 = y_class[np.random.randint(len(y_class))]\n",
    "\n",
    "    triplets[i] = x_train[idx_image1]\n",
    "    triplets[i+1] = x_train[idx_image2]\n",
    "    issame[i] = issame[i+1] = 1\n",
    "    y_triplets[i] = y_triplets[i+1] = clas\n",
    "\n",
    "    # Pair of different classes\n",
    "    # Chose the classes:\n",
    "    class2 = np.random.randint(10)\n",
    "    while clas==class2:\n",
    "        class2 = np.random.randint(10)\n",
    "\n",
    "    # Extract images of this class:\n",
    "    y_class2 = np.arange(len(y_train))[np.equal(y_train,class2)]\n",
    "\n",
    "    # Chose an image amoung these selected images\n",
    "    triplets[i+2] = x_train[y_class2[np.random.randint(len(y_class2))]]\n",
    "    issame[i+2] = 0\n",
    "    y_triplets[i+2] = class2\n",
    "\n",
    "triplets_exp = np.expand_dims(triplets, -1)\n",
    "triplets_exp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f147d41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check some triplets\n",
    "s = 10\n",
    "n = 5\n",
    "print(issame[3*s:(n+s)*3])\n",
    "print(y_triplets[3*s:(n+s)*3])\n",
    "fig = plt.figure(figsize=(7,3*n))\n",
    "for i in range(s,s+n):\n",
    "    plt.subplot(n,3,3*(i-s)+1)\n",
    "    plt.imshow(triplets[3*i])\n",
    "    plt.subplot(n,3,3*(i-s)+2)\n",
    "    plt.imshow(triplets[3*i+1])\n",
    "    plt.subplot(n,3,3*(i-s)+3)\n",
    "    plt.imshow(triplets[3*i+2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed9383a",
   "metadata": {},
   "source": [
    "### Define the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7eaadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "alpha = 0.3\n",
    "def triplet_acc(y_true,y_pred):\n",
    "    a = y_pred[0::3]\n",
    "    p = y_pred[1::3]\n",
    "    n = y_pred[2::3]\n",
    "    \n",
    "    ap = K.sum(K.square(a-p), axis = -1)\n",
    "    an = K.sum(K.square(a-n), axis = -1)\n",
    "    return K.less(ap,an)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e46413",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def robert(y_true,y_pred):\n",
    "    \"\"\"\n",
    "    Robert tries to increase the angle between the centers\n",
    "    of each classes (=increase the deviation of the centers)\n",
    "    and to decrease the angle between elements of a certain class\n",
    "    (=decrease the deviation of the elements of a class).\n",
    "    \"\"\"\n",
    "    extract = tf.cast(y_true[:,0], dtype=tf.int32)\n",
    "    classes = tf.one_hot(extract,depth=10)\n",
    "    classes = tf.cast(classes, dtype=tf.float32)\n",
    "    \n",
    "    centers = K.transpose(K.dot(K.transpose(y_pred), classes / (K.sum(classes, axis=0, keepdims=True) + 1)))\n",
    "    centers = tf.math.l2_normalize(centers,axis=-1)\n",
    "    centers_classes = K.dot(classes, centers)\n",
    "    \n",
    "    # \"dist\" computes the angle\n",
    "    dist = (K.sum(centers_classes * y_pred, axis=-1) * -1. + .5)*5\n",
    "    dist = K.sum(K.sigmoid(dist))\n",
    "\n",
    "    identity = K.arange(0,10)\n",
    "    identity = tf.one_hot(identity,10)\n",
    "    \n",
    "    gram = K.dot(centers,K.transpose(centers)) * 0.5 + 0.5\n",
    "    dev = K.sum(K.pow(gram-identity,10))\n",
    "    return dev + dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6890bfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bobby(y_true,y_pred):\n",
    "    extract = tf.cast(y_true[:,0], dtype=tf.int32)\n",
    "    classes = tf.one_hot(extract,depth=10)\n",
    "    classes = tf.cast(classes, dtype=tf.float32)\n",
    "    \n",
    "    dot_y_pred = K.dot(y_pred,K.transpose(y_pred))\n",
    "    is_same_mask = K.dot(classes,K.transpose(classes))\n",
    "\n",
    "    return K.binary_crossentropy(is_same_mask,dot_y_pred*0.5+0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b243fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 30.\n",
    "m = 0.1\n",
    "def cosine(y_true,y_pred):\n",
    "    \n",
    "    exp_s = K.exp(s * y_pred)\n",
    "    exp_s_m = K.exp(s * (y_pred - m))\n",
    "    \n",
    "    masked_exp_s_m = exp_s_m * y_true\n",
    "    \n",
    "    inv_mask = 1. - y_true\n",
    "    masked_exp_s = exp_s * inv_mask\n",
    "    \n",
    "    den = K.sum(masked_exp_s + masked_exp_s_m, axis=-1, keepdims=True)\n",
    "    out = masked_exp_s_m / den\n",
    "    out = K.sum(out,axis=-1)\n",
    "    ret = - K.log(out)\n",
    "    ret = K.sum(ret)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648dcdad",
   "metadata": {},
   "source": [
    "### Define the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199d3315",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "class Cosine(Layer):\n",
    "\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(Cosine, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        shape = tf.TensorShape((input_shape[-1],self.output_dim))\n",
    "\n",
    "        self.kernel = self.add_weight(name='kernel', \n",
    "                                      shape=shape,\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        super(Cosine, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = tf.math.l2_normalize(x, axis=-1)\n",
    "        w = tf.math.l2_normalize(self.kernel, axis=0)\n",
    "        \n",
    "        return K.dot(x, w)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40923c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from triplet_loss import batch_all_triplet_loss\n",
    "def triplet(y_true,y_pred):\n",
    "    y_true = y_true[:,0]\n",
    "    y_true = tf.reshape(y_true,[-1])\n",
    "    loss,_ = batch_all_triplet_loss(y_true,y_pred,0.3)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add0046b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from triplet_loss import batch_hard_triplet_loss\n",
    "def triplet_hard(y_true,y_pred):\n",
    "    y_true = y_true[:,0]\n",
    "    y_true = tf.reshape(y_true,[-1])\n",
    "    loss = batch_hard_triplet_loss(y_true,y_pred,0.3)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c641da22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small net and cosine loss\n",
    "emb_size = 2\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Lambda\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(emb_size))\n",
    "model.add(Lambda(lambda x: tf.math.l2_normalize(x, axis=-1)))\n",
    "\n",
    "model.compile(loss=triplet,\n",
    "              optimizer='rmsprop',\n",
    "              metrics=[triplet_acc]\n",
    "             )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309c331e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.expand_dims(y_triplets,-1)\n",
    "y2 = np.hstack([y]*emb_size)\n",
    "y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58cbc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    triplets_exp,\n",
    "    y2,\n",
    "    batch_size = 30*3,\n",
    "    epochs = 100,\n",
    "    validation_split=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d6be1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "history_ = np.array([loss,val_loss,acc,val_acc])\n",
    "np.save(PATH_SAVE+'2018.01.31.small_net.cosine.s_30.m_0.1.npy',history_)\n",
    "np.savetxt(PATH_SAVE+'2018.01.31.small_net.cosine.s_30.m_0.1.txt',history_)\n",
    "\n",
    "epochs = np.arange(len(loss))\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epochs,loss, '-o', label=\"loss\")\n",
    "plt.plot(epochs,val_loss, '-o', label=\"val_loss\")\n",
    "plt.xlabel(\"Number of epochs\")\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epochs,acc, '-o', label=\"acc\")\n",
    "plt.plot(epochs,val_acc, '-o', label=\"val_acc\")\n",
    "plt.xlabel(\"Number of epochs\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a409e8c",
   "metadata": {},
   "source": [
    "### Evaluate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28397de",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbof_images = 6000\n",
    "\n",
    "triplets_test = triplets_exp[:nbof_images]\n",
    "mod = tf.keras.Model(model.input, model.layers[-2].output)\n",
    "emb = mod.predict(triplets_test)\n",
    "emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c21d260",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = emb[0::3]\n",
    "p = emb[1::3]\n",
    "n = emb[2::3]\n",
    "\n",
    "# Computes distance between pairs\n",
    "dist1 = np.sum(np.square(a-p),1)\n",
    "dist2 = np.sum(np.square(a-n),1)\n",
    "less = np.less(dist1,dist2)\n",
    "acc = np.sum(less.astype(int))/len(less)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a275426f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the wrong examples\n",
    "idx_wrong = np.logical_not(less)\n",
    "idx_wrong = np.stack([idx_wrong]*3, axis = -1)\n",
    "idx_wrong = np.reshape(idx_wrong, [-1])\n",
    "\n",
    "wrong = triplets_test[idx_wrong]\n",
    "wrong = np.squeeze(wrong)\n",
    "print(len(wrong)//3)\n",
    "s = 0\n",
    "n = 7\n",
    "e = n + s\n",
    "plt.figure(figsize=(7,3*n))\n",
    "for i in range(s,e):\n",
    "    for j in range(3):\n",
    "        plt.subplot(n,3,(i-s)*3+1+j)\n",
    "        plt.imshow(wrong[i*3+j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12215ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.zeros((10,2))\n",
    "nb = np.zeros(10)\n",
    "y_int = y_triplets[:nbof_images].astype(int)\n",
    "predict = emb\n",
    "# y_train = y_train.astype(int)\n",
    "# y_int = np.empty(len(y_train),dtype=int)\n",
    "# for i in range(len(y_train)):\n",
    "#     idx = 0\n",
    "#     while (y_train[i][idx]!=1):\n",
    "#         idx += 1\n",
    "#     y_int[i] = int(idx)\n",
    "\n",
    "for i in range(len(predict)):\n",
    "    mean[y_int[i]] += predict[i]\n",
    "    nb[y_int[i]] += 1\n",
    "\n",
    "for i in range(len(mean)):\n",
    "    mean[i] /= nb[i]\n",
    "print(mean)\n",
    "\n",
    "std_vect = np.zeros((10,2)) + mean\n",
    "std = np.zeros(10)\n",
    "for i in range(len(predict)):\n",
    "    std[y_int[i]] += np.sum(np.square(predict[i]-mean))\n",
    "\n",
    "for i in range(len(mean)):\n",
    "    std[i] /= nb[i]\n",
    "print(np.sqrt(std))\n",
    "\n",
    "plt.axis('equal')\n",
    "n = 10\n",
    "for i in range(n):\n",
    "    y = predict[np.equal(i,y_int)]\n",
    "    #y = y / np.linalg.norm(y, axis=-1,keepdims=True)\n",
    "    plt.plot(y[:,0],y[:,1],'o',label=str(i))\n",
    "#mean = mean/np.linalg.norm(mean, axis=-1,keepdims=True)\n",
    "plt.plot(mean[:n,0],mean[:n,1],'ko')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18eb61b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e118af",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = tf.keras.Model(model.inputs, model.layers[-2].output)\n",
    "predict = mod.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bd889d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.zeros((10,2))\n",
    "nb = np.zeros(10)\n",
    "y_int = y_train\n",
    "# y_train = y_train.astype(int)\n",
    "# y_int = np.empty(len(y_train),dtype=int)\n",
    "# for i in range(len(y_train)):\n",
    "#     idx = 0\n",
    "#     while (y_train[i][idx]!=1):\n",
    "#         idx += 1\n",
    "#     y_int[i] = int(idx)\n",
    "\n",
    "for i in range(len(predict)):\n",
    "    mean[y_int[i]] += predict[i]\n",
    "    nb[y_int[i]] += 1\n",
    "\n",
    "for i in range(len(mean)):\n",
    "    mean[i] /= nb[i]\n",
    "print(mean)\n",
    "\n",
    "std_vect = np.zeros((10,2)) + mean\n",
    "std = np.zeros(10)\n",
    "for i in range(len(predict)):\n",
    "    std[y_int[i]] += np.sum(np.square(predict[i]-mean))\n",
    "\n",
    "for i in range(len(mean)):\n",
    "    std[i] /= nb[i]\n",
    "print(np.sqrt(std))\n",
    "\n",
    "plt.axis('equal')\n",
    "n = 10\n",
    "for i in range(n):\n",
    "    y = predict[np.equal(i,y_int)]\n",
    "    #y = y / np.linalg.norm(y, axis=-1,keepdims=True)\n",
    "    plt.plot(y[:,0],y[:,1],'o',label=str(i))\n",
    "#mean = mean/np.linalg.norm(mean, axis=-1,keepdims=True)\n",
    "plt.plot(mean[:n,0],mean[:n,1],'ko')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
