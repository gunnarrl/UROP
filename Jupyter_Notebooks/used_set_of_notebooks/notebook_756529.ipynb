{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5189cd6",
   "metadata": {},
   "source": [
    "This sample shows how to use the distribution strategy APIs when writing a custom training loop on TPU:\n",
    " * instantiate a `TPUStrategy()`\n",
    " * create the model and all other trainin objects in a strategy scope `with strategy.scope(): ...`\n",
    " * distribute the dataset with `strategy.experimental_distribute_dataset(ds)`\n",
    " * run the training step distributed with `strategy.run(step_fn)`\n",
    " * aggregate results returned by distributed workers with `strategy.reduce(...)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96474c5b",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f931da52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import re, time\n",
    "print(\"Tensorflow version \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db364e4",
   "metadata": {},
   "source": [
    "## TPU or GPU detection\n",
    "TPUClusterResolver() automatically detects a connected TPU on all Gooogle's\n",
    "platforms: Colaboratory, AI Platform (ML Engine), Kubernetes, Kaggle, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb9ecaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: # detect TPUs\n",
    "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n",
    "  tf.config.experimental_connect_to_cluster(tpu)\n",
    "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "  strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "except ValueError: # detect GPUs\n",
    "  strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\n",
    "  #strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
    "  #strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy() # for clusters of multi-GPU machines\n",
    "\n",
    "print(\"Number of accelerators: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6db977",
   "metadata": {},
   "source": [
    "## Configuration and learning rate schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b62f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 60\n",
    "\n",
    "if strategy.num_replicas_in_sync == 1: # GPU\n",
    "    BATCH_SIZE = 16\n",
    "    VALIDATION_BATCH_SIZE = 16\n",
    "    START_LR = 0.01\n",
    "    MAX_LR = 0.01\n",
    "    MIN_LR = 0.01\n",
    "    LR_RAMP = 0 # epochs\n",
    "    LR_SUSTAIN = 0 #epochs\n",
    "    LR_DECAY = 1\n",
    "    \n",
    "elif strategy.num_replicas_in_sync == 8: # single TPU\n",
    "    BATCH_SIZE = 16 * strategy.num_replicas_in_sync # use 32 on TPUv3\n",
    "    VALIDATION_BATCH_SIZE = 256\n",
    "    START_LR = 0.01\n",
    "    MAX_LR = 0.01 * strategy.num_replicas_in_sync\n",
    "    MIN_LR = 0.001\n",
    "    LR_RAMP = 0 # epochs\n",
    "    LR_SUSTAIN = 13 # epochs\n",
    "    LR_DECAY = .95\n",
    "\n",
    "else: # TPU pod\n",
    "    BATCH_SIZE = 16 * strategy.num_replicas_in_sync  # Gobal batch size.\n",
    "    VALIDATION_BATCH_SIZE = 256\n",
    "    START_LR = 0.06\n",
    "    MAX_LR = 0.012 * strategy.num_replicas_in_sync\n",
    "    MIN_LR = 0.01\n",
    "    LR_RAMP = 5 # epochs\n",
    "    LR_SUSTAIN = 8 # epochs\n",
    "    LR_DECAY = 0.95\n",
    "\n",
    "CLASSES = ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips'] # do not change, maps to the labels in the data (folder names)\n",
    "\n",
    "IMAGE_SIZE = [331, 331] # supported images sizes: 192x192, 331x331, 512,512\n",
    "                        # make sure you load the appropriate dataset on the next line\n",
    "#GCS_PATTERN = 'gs://flowers-public/tfrecords-jpeg-192x192-2/*.tfrec'\n",
    "GCS_PATTERN = 'gs://flowers-public/tfrecords-jpeg-331x331/*.tfrec'\n",
    "#GCS_PATTERN = 'gs://flowers-public/tfrecords-jpeg-512x512/*.tfrec'\n",
    "VALIDATION_SPLIT = 0.19\n",
    "\n",
    "def lrfn(epoch):\n",
    "    if LR_RAMP > 0 and epoch < LR_RAMP:  # linear ramp from START_LR to MAX_LR\n",
    "        lr = (MAX_LR - START_LR)/(LR_RAMP*1.0) * epoch + START_LR\n",
    "    elif epoch < LR_RAMP + LR_SUSTAIN:  # constant ar MAX_LR\n",
    "        lr = MAX_LR\n",
    "    else:  # exponential decay from MAX_LR to MIN_LR\n",
    "        lr = (MAX_LR - MIN_LR) * LR_DECAY**(epoch-LR_RAMP-LR_SUSTAIN) + MIN_LR\n",
    "    return lr\n",
    "    \n",
    "@tf.function\n",
    "def lrfn_tffun(epoch):\n",
    "    return lrfn(epoch)\n",
    "\n",
    "print(\"Learning rate schedule:\")\n",
    "rng = [i for i in range(EPOCHS)]\n",
    "plt.plot(rng, [lrfn(x) for x in rng])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de445f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title display utilities [RUN ME]\n",
    "\n",
    "def dataset_to_numpy_util(dataset, N):\n",
    "  dataset = dataset.batch(N)\n",
    "  \n",
    "  if tf.executing_eagerly():\n",
    "    # In eager mode, iterate in the Datset directly.\n",
    "    for images, labels in dataset:\n",
    "      numpy_images = images.numpy()\n",
    "      numpy_labels = labels.numpy()\n",
    "      break;\n",
    "      \n",
    "  else: # In non-eager mode, must get the TF note that \n",
    "        # yields the nextitem and run it in a tf.Session.\n",
    "    get_next_item = dataset.make_one_shot_iterator().get_next()\n",
    "    with tf.Session() as ses:\n",
    "      numpy_images, numpy_labels = ses.run(get_next_item)\n",
    "\n",
    "  return numpy_images, numpy_labels\n",
    "\n",
    "def title_from_label_and_target(label, correct_label):\n",
    "  label = np.argmax(label, axis=-1)  # one-hot to class number\n",
    "  correct_label = np.argmax(correct_label, axis=-1) # one-hot to class number\n",
    "  correct = (label == correct_label)\n",
    "  return \"{} [{}{}{}]\".format(CLASSES[label], str(correct), ', shoud be ' if not correct else '',\n",
    "                              CLASSES[correct_label] if not correct else ''), correct\n",
    "\n",
    "def display_one_flower(image, title, subplot, red=False):\n",
    "    plt.subplot(subplot)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image)\n",
    "    plt.title(title, fontsize=16, color='red' if red else 'black')\n",
    "    return subplot+1\n",
    "  \n",
    "def display_9_images_from_dataset(dataset):\n",
    "  subplot=331\n",
    "  plt.figure(figsize=(13,13))\n",
    "  images, labels = dataset_to_numpy_util(dataset, 9)\n",
    "  for i, image in enumerate(images):\n",
    "    title = CLASSES[np.argmax(labels[i], axis=-1)]\n",
    "    subplot = display_one_flower(image, title, subplot)\n",
    "    if i >= 8:\n",
    "      break;\n",
    "              \n",
    "  #plt.tight_layout() # bug in tight layout in this version of matplotlib\n",
    "  plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "  plt.show()\n",
    "  \n",
    "def display_9_images_with_predictions(images, predictions, labels):\n",
    "  subplot=331\n",
    "  plt.figure(figsize=(13,13))\n",
    "  for i, image in enumerate(images):\n",
    "    title, correct = title_from_label_and_target(predictions[i], labels[i])\n",
    "    subplot = display_one_flower(image, title, subplot, not correct)\n",
    "    if i >= 8:\n",
    "      break;\n",
    "              \n",
    "  #plt.tight_layout() # bug in tight layout in this version of matplotlib\n",
    "  plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "  plt.show()\n",
    "  \n",
    "def display_training_curves(training, validation, title, subplot):\n",
    "  if subplot%10==1: # set up the subplots on the first call\n",
    "    plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n",
    "    #plt.tight_layout() # bug in tight layout in this version of matplotlib\n",
    "  ax = plt.subplot(subplot)\n",
    "  ax.set_facecolor('#F8F8F8')\n",
    "  ax.plot(training)\n",
    "  ax.plot(validation)\n",
    "  ax.set_title('model '+ title)\n",
    "  ax.set_ylabel(title)\n",
    "  #ax.set_ylim(0.28,1.05)\n",
    "  ax.set_xlabel('epoch')\n",
    "  ax.legend(['train', 'valid.'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dbb09d",
   "metadata": {},
   "source": [
    "## Read images and labels from TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad52d850",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "def count_data_items(filenames):\n",
    "    # trick: the number of data items is written in the name of\n",
    "    # the .tfrec files a flowers00-230.tfrec = 230 data items\n",
    "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
    "    return int(np.sum(n))\n",
    "\n",
    "def data_augment(image, one_hot_class):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_saturation(image, 0, 2)\n",
    "    return image, one_hot_class\n",
    "\n",
    "def read_tfrecord(example):\n",
    "    features = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n",
    "        \"class\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means scalar\n",
    "        \"one_hot_class\": tf.io.VarLenFeature(tf.float32),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, features)\n",
    "    image = tf.image.decode_jpeg(example['image'], channels=3)\n",
    "    image = tf.cast(image, tf.float32) / 255.0  # convert image to floats in [0, 1] range\n",
    "    image = tf.reshape(image, [*IMAGE_SIZE, 3]) # force the image size so that the shape of the tensor is known to Tensorflow\n",
    "    class_label = tf.cast(example['class'], tf.int32)\n",
    "    one_hot_class = tf.sparse.to_dense(example['one_hot_class'])\n",
    "    one_hot_class = tf.reshape(one_hot_class, [5])\n",
    "    return image, one_hot_class\n",
    "\n",
    "def load_dataset(filenames):\n",
    "    # read from TFRecords. For optimal performance, use TFRecordDataset with\n",
    "    # num_parallel_calls=AUTOTUNE to read from multiple TFRecord files at once\n",
    "    # band set the option experimental_deterministic = False\n",
    "    # to allow order-altering optimizations.\n",
    "\n",
    "    opt = tf.data.Options()\n",
    "    opt.experimental_deterministic = False\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(filenames).with_options(opt)\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=16) # can be AUTOTUNE in TF 2.1\n",
    "    dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "def batch_dataset(filenames, batch_size, train):\n",
    "    dataset = load_dataset(filenames)\n",
    "    n = count_data_items(filenames)\n",
    "    \n",
    "    if train:\n",
    "        dataset = dataset.repeat() # training dataset must repeat\n",
    "        dataset = dataset.map(data_augment, num_parallel_calls=AUTOTUNE)\n",
    "        dataset = dataset.shuffle(2048)\n",
    "    else:\n",
    "        # usually fewer validation files than workers so disable FILE auto-sharding on validation\n",
    "        if strategy.num_replicas_in_sync > 1: # option not useful if there is no sharding (not harmful either)\n",
    "            opt = tf.data.Options()\n",
    "            opt.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.DATA\n",
    "            dataset = dataset.with_options(opt)\n",
    "        # validation dataset does not need to repeat\n",
    "        # also no need to shuffle or apply data augmentation\n",
    "    if train:\n",
    "        dataset = dataset.batch(batch_size)\n",
    "    else:\n",
    "        # little wrinkle: drop_remainder is NOT necessary but validation on the last\n",
    "        # partial batch sometimes returns a \"nan\" loss (probably a bug). You can remove\n",
    "        # this if you do not care about the validatoin loss.\n",
    "        dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "    dataset = dataset.prefetch(AUTOTUNE) # prefetch next batch while training (autotune prefetch buffer size)\n",
    "    return dataset, n//batch_size\n",
    "\n",
    "def get_training_dataset(filenames):\n",
    "    dataset, steps = batch_dataset(filenames, BATCH_SIZE, train=True)\n",
    "    return dataset, steps\n",
    "\n",
    "def get_validation_dataset(filenames):\n",
    "    dataset, steps = batch_dataset(filenames, VALIDATION_BATCH_SIZE, train=False)\n",
    "    return dataset, steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef15083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate datasets\n",
    "filenames = tf.io.gfile.glob(GCS_PATTERN)\n",
    "split = len(filenames) - int(len(filenames) * VALIDATION_SPLIT)\n",
    "train_filenames = filenames[:split]\n",
    "valid_filenames = filenames[split:]\n",
    "\n",
    "training_dataset, steps_per_epoch = get_training_dataset(train_filenames)\n",
    "validation_dataset, validation_steps = get_validation_dataset(valid_filenames)\n",
    "\n",
    "print(\"TRAINING   IMAGES: \", count_data_items(train_filenames), \", STEPS PER EPOCH: \", steps_per_epoch)\n",
    "print(\"VALIDATION IMAGES: \", count_data_items(valid_filenames), \", STEPS PER EPOCH: \", validation_steps)\n",
    "\n",
    "# numpy data to test predictions\n",
    "some_flowers, some_labels = dataset_to_numpy_util(load_dataset(valid_filenames), 160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a71935",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_9_images_from_dataset(load_dataset(train_filenames))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c886126d",
   "metadata": {},
   "source": [
    "## The model: squeezenet with 12 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45655eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    bnmomemtum=0.9 # with only a handful of batches per epoch, the batch norm running average period must be lowered\n",
    "    def fire(x, squeeze, expand):\n",
    "        y  = tf.keras.layers.Conv2D(filters=squeeze, kernel_size=1, activation=None, padding='same', use_bias=False)(x)\n",
    "        y = tf.keras.layers.BatchNormalization(momentum=bnmomemtum, scale=False, center=True)(y)\n",
    "        y = tf.keras.layers.Activation('relu')(y)\n",
    "        y1 = tf.keras.layers.Conv2D(filters=expand//2, kernel_size=1, activation=None, padding='same', use_bias=False)(y)\n",
    "        y1 = tf.keras.layers.BatchNormalization(momentum=bnmomemtum, scale=False, center=True)(y1)\n",
    "        y1 = tf.keras.layers.Activation('relu')(y1)\n",
    "        y3 = tf.keras.layers.Conv2D(filters=expand//2, kernel_size=3, activation=None, padding='same', use_bias=False)(y)\n",
    "        y3 = tf.keras.layers.BatchNormalization(momentum=bnmomemtum, scale=False, center=True)(y3)\n",
    "        y3 = tf.keras.layers.Activation('relu')(y3)\n",
    "        return tf.keras.layers.concatenate([y1, y3])\n",
    "\n",
    "    def fire_module(squeeze, expand):\n",
    "        return lambda x: fire(x, squeeze, expand)\n",
    "\n",
    "    x = tf.keras.layers.Input(shape=(*IMAGE_SIZE, 3)) # input is 331x331 pixels RGB\n",
    "    y = tf.keras.layers.Conv2D(kernel_size=3, filters=32, padding='same', use_bias=True, activation='relu')(x)\n",
    "    y = tf.keras.layers.BatchNormalization(momentum=bnmomemtum)(y)\n",
    "    y = fire_module(24, 48)(y)\n",
    "    y = tf.keras.layers.MaxPooling2D(pool_size=2)(y)\n",
    "    y = fire_module(48, 96)(y)\n",
    "    y = tf.keras.layers.MaxPooling2D(pool_size=2)(y)\n",
    "    y = fire_module(64, 128)(y)\n",
    "    y = tf.keras.layers.MaxPooling2D(pool_size=2)(y)\n",
    "    y = fire_module(48, 96)(y)\n",
    "    y = tf.keras.layers.MaxPooling2D(pool_size=2)(y)\n",
    "    y = fire_module(24, 48)(y)\n",
    "    y = tf.keras.layers.GlobalAveragePooling2D()(y)\n",
    "    y = tf.keras.layers.Dropout(0.4)(y)\n",
    "    y = tf.keras.layers.Dense(5, activation='softmax')(y)\n",
    "    return tf.keras.Model(x, y)\n",
    "\n",
    "# Custom learning rate schedule\n",
    "class LRSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "        def __call__(self, step):\n",
    "            return lrfn_tffun(epoch=step//steps_per_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0745a534",
   "metadata": {},
   "source": [
    "## Instantiate all objects in the strategy scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2118d3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = create_model()\n",
    "    \n",
    "    # Instiate optimizer with learning rate schedule\n",
    "    optimizer = tf.keras.optimizers.SGD(nesterov=True, momentum=0.9, learning_rate=LRSchedule())\n",
    "    train_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "    valid_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "    loss_fn = lambda labels, probabilities: tf.reduce_mean(tf.keras.losses.categorical_crossentropy(labels, probabilities))\n",
    "        \n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d202894",
   "metadata": {},
   "source": [
    "## Step functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a713ce30",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        probabilities = model(images, training=True)\n",
    "        loss = loss_fn(labels, probabilities)\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    train_accuracy.update_state(labels, probabilities)\n",
    "    return loss\n",
    "\n",
    "@tf.function\n",
    "def valid_step(images, labels):\n",
    "    probabilities = model(images, training=False)\n",
    "    loss = loss_fn(labels, probabilities)\n",
    "    valid_accuracy.update_state(labels, probabilities)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe8aae5",
   "metadata": {},
   "source": [
    "## Custom training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f876b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribute the datset according to the strategy\n",
    "train_dist_ds = strategy.experimental_distribute_dataset(training_dataset)\n",
    "valid_dist_ds = strategy.experimental_distribute_dataset(validation_dataset)\n",
    "\n",
    "print(\"Steps per epoch: \", steps_per_epoch)\n",
    "\n",
    "epoch = 0\n",
    "train_losses=[]\n",
    "start_time = epoch_start_time = time.time()\n",
    "\n",
    "for step, (images, labels) in enumerate(train_dist_ds):\n",
    "\n",
    "    # batch losses from all replicas\n",
    "    loss = strategy.run(train_step, args=(images, labels))\n",
    "    # reduced to a single number both across replicas and across the bacth size\n",
    "    loss = strategy.reduce(tf.distribute.ReduceOp.MEAN, loss, axis=None)\n",
    "    # or use strategy.experimental_local_results(loss) to access the raw set of losses returned from all replicas\n",
    "\n",
    "    # validation run at the end of each epoch\n",
    "    if ((step+1) // steps_per_epoch) > epoch:\n",
    "        valid_loss = []\n",
    "        for image, labels in valid_dist_ds:\n",
    "            batch_loss = strategy.run(valid_step, args=(image, labels)) # just one batch\n",
    "            batch_loss = strategy.reduce(tf.distribute.ReduceOp.MEAN, batch_loss, axis=None)\n",
    "            valid_loss.append(batch_loss.numpy())\n",
    "        valid_loss = np.mean(valid_loss)\n",
    "\n",
    "        epoch = (step+1) // steps_per_epoch\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        print('\\nEPOCH: ', epoch)\n",
    "        print('time: {:0.1f}s'.format(epoch_time),\n",
    "              ', loss: ', loss.numpy(),\n",
    "              ', accuracy_: ', train_accuracy.result().numpy(),\n",
    "              ', val_loss: ', valid_loss,\n",
    "              ', val_acc_: ', valid_accuracy.result().numpy(),\n",
    "              ', lr: ', lrfn(epoch)\n",
    "             )\n",
    "        \n",
    "        epoch_start_time = time.time()\n",
    "        train_accuracy.reset_states()\n",
    "        valid_accuracy.reset_states()\n",
    "        if epoch >= EPOCHS:\n",
    "            break\n",
    "            \n",
    "    train_losses.append(loss)\n",
    "    print('=', end='')\n",
    "    \n",
    "training_time = time.time() - start_time\n",
    "print(\"TOTAL TRAINING TIME: {:0.1f}s\".format(training_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb021d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Detailed training loss:\")\n",
    "plt.plot(train_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bebb43",
   "metadata": {},
   "source": [
    "## Predictions\n",
    "(not distributed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0193470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomize the input so that you can execute multiple times to change results\n",
    "permutation = np.random.permutation(8*20)\n",
    "some_flowers, some_labels = (some_flowers[permutation], some_labels[permutation])\n",
    "\n",
    "predictions = model.predict(some_flowers, batch_size=16)\n",
    "  \n",
    "print(np.array(CLASSES)[np.argmax(predictions, axis=-1)].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3193448",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_9_images_with_predictions(some_flowers, predictions, some_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1fce1d",
   "metadata": {},
   "source": [
    "## License"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13c413e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "author: Martin Gorner<br>\n",
    "twitter: @martin_gorner\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Copyright 2020 Google LLC\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "This is not an official Google product but sample code provided for an educational purpose\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
