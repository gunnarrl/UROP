{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce83875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing as process\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import keras as k\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b520c09f",
   "metadata": {},
   "source": [
    "### Quick Look at the Feature Data\n",
    "\n",
    "Most of the fields are quantities, save for the Job number and the Company. Job numbers increment in value, so the highest number jobs are the most recent. For now we will exclude those two categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47195f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/features.csv', encoding='utf-8')\n",
    "df = df[df.Company == 'HEM']  # drop SMC data?\n",
    "del df['Company']\n",
    "del df['JobNum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e122ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ea9ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032cb1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059b2f1a",
   "metadata": {},
   "source": [
    "### Split And Standardize and Transform The Data\n",
    "Standard Scaler brings the mean to 0 and the standard deviation to 1. Quantile Transformer shifts the distribution to look more gaussian, smoothing out unusual distributions and is less influenced by outliers than scaling methods. It does, however, distort correlations and distances within and across features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515451e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "# 80% of the samples will be used for training\n",
    "m = np.floor(df.shape[0] * 0.8).astype('int')\n",
    "\n",
    "# Processing X: standardize feature values\n",
    "X = df.iloc[:m, :-1].values\n",
    "x_test = df.iloc[m:, :-1].values\n",
    "\n",
    "scale = process \\\n",
    "    .StandardScaler() \\\n",
    "    .fit(X)\n",
    "\n",
    "joblib.dump(scale, 'app/scaler.pkl')  # saving the transformation for deployed system\n",
    "\n",
    "X = scale.transform(X)\n",
    "x_test = scale.transform(x_test)\n",
    "\n",
    "# Processing Y: to categories by week (over 25 weeks aka 6 months are just grouped together)\n",
    "Y = df.iloc[:m, -1:].apply(lambda x: np.where(x // 5 < 25, x // 5, 25)).values\n",
    "Y = k.utils.to_categorical(Y, num_classes=26)\n",
    "\n",
    "y_test = df.iloc[m:, -1:].apply(lambda x: np.where(x // 5 < 25, x // 5, 25)).values\n",
    "y_test = k.utils.to_categorical(y_test, num_classes=26)\n",
    "\n",
    "\n",
    "#### NOT USED ###############\n",
    "# Log shift data to get a gaussian distribution for each feature\n",
    "shift = process \\\n",
    "    .QuantileTransformer(random_state=0) \\\n",
    "    .fit(X)\n",
    "\n",
    "# Shuffling function for k-folds (model.train_on_batch)\n",
    "ss = ShuffleSplit(n_splits=5, \n",
    "                  test_size=0.25, \n",
    "                  random_state=0)\n",
    "\n",
    "def preprocess(x):\n",
    "#     x = scale.transform(x)\n",
    "    x = shift.transform(x)\n",
    "    return x\n",
    "#### NOT USED ###############"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25467be",
   "metadata": {},
   "source": [
    "### Model Architecture And Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2941e90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras import regularizers\n",
    "\n",
    "I = Input(shape=(7,))\n",
    "H = Dense(24, activation='tanh')(I)\n",
    "O = Dense(26, activation='softmax', activity_regularizer=regularizers.l2(0.01))(H)\n",
    "\n",
    "model = Model(inputs=I, outputs=O)\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aedb51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cafae87",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719fd9d7",
   "metadata": {},
   "source": [
    "### Train Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d8a396",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "from keras import metrics\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "model = Model(inputs=I, outputs=O)\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=[metrics.categorical_accuracy])\n",
    "hist = model.fit(X,Y, validation_split=0.2, epochs=50, batch_size=5, verbose=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb23f07",
   "metadata": {},
   "source": [
    "### Visualize Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b038ebbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.gca().set_title('Training Loss History', size=20)\n",
    "plt.gca().set_ylabel('error', size=14)\n",
    "plt.gca().set_xlabel('epoch', size=14)\n",
    "plt.plot(hist.history['loss'], 'o', markersize=2, label='Train')\n",
    "plt.plot(hist.history['val_loss'], 'ro', markersize=2, label='Test')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5bf756",
   "metadata": {},
   "source": [
    "### Continue Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c64f9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.set_value(model.optimizer.lr, 0.0005)\n",
    "new_hist = model.fit(X,Y, validation_split=0.2, epochs=20, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8635c9f",
   "metadata": {},
   "source": [
    "### Check Prediction Abilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a600dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert business-week categories to business days\n",
    "pred = np.argmax(model.predict(x_test), axis=1) * 5 + 5\n",
    "act = np.argmax(y_test, axis=1) * 5 + 5\n",
    "\n",
    "# calculate Mean Absolute Error\n",
    "mae = np.sum(np.abs(pred - act)) / x_test.shape[0]\n",
    "print(\"Model predicts with a {0:.0f} business day average lead time error\".format(mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b717b089",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e94fe87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('app/model.json', 'w') as outfile:\n",
    "    json.dump(model.to_json(), outfile)\n",
    "    \n",
    "model.save_weights('app/weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb01527",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51d005d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "with open('app/model.json') as json_data:\n",
    "    json_string = json.load(json_data)\n",
    "    model_v2 = model_from_json(json_string)\n",
    "    \n",
    "model_v2.load_weights('app/weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ad243d",
   "metadata": {},
   "source": [
    "### Double Check Prediction Capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14774bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert business-week categories to business days\n",
    "pred = np.argmax(model_v2.predict(x_test), axis=1) * 5 + 5\n",
    "act = np.argmax(y_test, axis=1) * 5 + 5\n",
    "\n",
    "# calculate Mean Absolute Error\n",
    "mae = np.sum(np.abs(pred - act)) / x_test.shape[0]\n",
    "print(\"Model predicts with a {0:.0f} business day average lead time error\".format(mae))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
