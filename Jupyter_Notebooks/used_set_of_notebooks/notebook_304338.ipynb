{"cells":[{"cell_type":"markdown","id":"46547a42","metadata":{"id":"46547a42"},"source":["<a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/training-data-analyst/blob/master/courses/fast-and-lean-data-science/07_Keras_Flowers_TPU_squeezenet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","id":"491e6a56","metadata":{"id":"491e6a56"},"source":["You can try this notebook on a GPU but you will quickly be switching to a TPU. For this model it's worth it."]},{"cell_type":"markdown","id":"52219ff9","metadata":{"id":"52219ff9"},"source":["## Imports"]},{"cell_type":"code","execution_count":null,"id":"ff61fa3b","metadata":{"id":"ff61fa3b"},"outputs":[],"source":["import os, math, json, random, time\n","import numpy as np\n","from matplotlib import pyplot as plt\n","import tensorflow as tf\n","print(\"Tensorflow version \" + tf.__version__)\n","AUTO = tf.data.experimental.AUTOTUNE\n","\n","# little wrinkle: Keras models do not yet work on TPU if eager mode is enabled\n","# tf.enable_eager_execution()"]},{"cell_type":"markdown","id":"c98d425a","metadata":{"id":"c98d425a"},"source":["## Colab-only auth\n","You would need this if you were accessing private GCS buckets. The training data for this exercise is in a public bucket for which authentication is not necessary."]},{"cell_type":"code","execution_count":null,"id":"1e9ede7d","metadata":{"id":"1e9ede7d"},"outputs":[],"source":["# IS_COLAB_BACKEND = 'COLAB_GPU' in os.environ  # this is always set on Colab, the value is 0 or 1 depending on GPU presence\n","# if IS_COLAB_BACKEND:\n","#   from google.colab import auth\n","#   auth.authenticate_user()  # not necessary to access a public bucket but you will probably want to access your private buckets too"]},{"cell_type":"markdown","id":"ec7695a4","metadata":{"id":"ec7695a4"},"source":["## TPU detection"]},{"cell_type":"code","execution_count":null,"id":"8666ffeb","metadata":{"id":"8666ffeb"},"outputs":[],"source":["# TPUClusterResolver() automatically detects a connected TPU on all Gooogle's\n","# platforms: Colaboratory, AI Platform (ML Engine), Kubernetes and Deep Learning\n","# VMs created through the 'ctpu up' utility. If auto-detection is not available,\n","# you can pass the name of your TPU explicitly:\n","# tf.contrib.cluster_resolver.TPUClusterResolver('MY_TPU_NAME')\n","# tip: on a VM created with \"ctpu up\" the TPU has the same name as the VM.\n","\n","try:\n","  tpu = tf.contrib.cluster_resolver.TPUClusterResolver() # TPU detection\n","\n","  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n","except ValueError:\n","  print(\"Running on GPU or CPU\")\n","  tpu = None"]},{"cell_type":"markdown","id":"80c20eaa","metadata":{"id":"80c20eaa"},"source":["## Configuration"]},{"cell_type":"code","execution_count":null,"id":"98f844b7","metadata":{"id":"98f844b7"},"outputs":[],"source":["GCS_PATTERN = 'gs://flowers-public/tfrecords-jpeg-192x192-2/*.tfrec'\n","IMAGE_SIZE = [192, 192]\n","\n","if tpu:\n","  BATCH_SIZE = 128  # On TPU in Keras, this is the per-core batch size. The global batch size is 8x this.\n","else:\n","  BATCH_SIZE = 32  # On Colab/GPU, a higher batch size does not help and sometimes does not fit on the GPU (OOM)\n","\n","VALIDATION_SPLIT = 0.19\n","CLASSES = ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips'] # do not change, maps to the labels in the data (folder names)\n","\n","# splitting data files between training and validation\n","filenames = tf.gfile.Glob(GCS_PATTERN)\n","#random.shuffle(filenames)\n","split = int(len(filenames) * VALIDATION_SPLIT)\n","training_filenames = filenames[split:]\n","validation_filenames = filenames[:split]\n","print(\"Pattern matches {} data files. Splitting dataset into {} training files and {} validation files\".format(len(filenames), len(training_filenames), len(validation_filenames)))\n","validation_steps = int(3670 // len(filenames) * len(validation_filenames)) // BATCH_SIZE  # 3670 is the numer of images in the dataset\n","steps_per_epoch = int(3670 // len(filenames) * len(training_filenames)) // BATCH_SIZE\n","print(\"With a batch size of {}, there will be {} batches per training epoch and {} batch(es) per validation run.\".format(BATCH_SIZE, steps_per_epoch, validation_steps))"]},{"cell_type":"code","execution_count":null,"id":"f922944e","metadata":{"id":"f922944e"},"outputs":[],"source":["#@title display utilities [RUN ME]\n","\n","def dataset_to_numpy_util(dataset, N):\n","  dataset = dataset.batch(N)\n","\n","  if tf.executing_eagerly():\n","    # In eager mode, iterate in the Datset directly.\n","    for images, labels in dataset:\n","      numpy_images = images.numpy()\n","      numpy_labels = labels.numpy()\n","      break;\n","\n","  else: # In non-eager mode, must get the TF note that\n","        # yields the nextitem and run it in a tf.Session.\n","    get_next_item = dataset.make_one_shot_iterator().get_next()\n","    with tf.Session() as ses:\n","      numpy_images, numpy_labels = ses.run(get_next_item)\n","\n","  return numpy_images, numpy_labels\n","\n","def title_from_label_and_target(label, correct_label):\n","  label = np.argmax(label, axis=-1)  # one-hot to class number\n","  correct_label = np.argmax(correct_label, axis=-1) # one-hot to class number\n","  correct = (label == correct_label)\n","  return \"{} [{}{}{}]\".format(CLASSES[label], str(correct), ', shoud be ' if not correct else '',\n","                              CLASSES[correct_label] if not correct else ''), correct\n","\n","def display_one_flower(image, title, subplot, red=False):\n","    plt.subplot(subplot)\n","    plt.axis('off')\n","    plt.imshow(image)\n","    plt.title(title, fontsize=16, color='red' if red else 'black')\n","    return subplot+1\n","\n","def display_9_images_from_dataset(dataset):\n","  subplot=331\n","  plt.figure(figsize=(13,13))\n","  images, labels = dataset_to_numpy_util(dataset, 9)\n","  for i, image in enumerate(images):\n","    title = CLASSES[np.argmax(labels[i], axis=-1)]\n","    subplot = display_one_flower(image, title, subplot)\n","    if i >= 8:\n","      break;\n","\n","  plt.tight_layout()\n","  plt.subplots_adjust(wspace=0.1, hspace=0.1)\n","  plt.show()\n","\n","def display_9_images_with_predictions(images, predictions, labels):\n","  subplot=331\n","  plt.figure(figsize=(13,13))\n","  for i, image in enumerate(images):\n","    title, correct = title_from_label_and_target(predictions[i], labels[i])\n","    subplot = display_one_flower(image, title, subplot, not correct)\n","    if i >= 8:\n","      break;\n","\n","  plt.tight_layout()\n","  plt.subplots_adjust(wspace=0.1, hspace=0.1)\n","  plt.show()\n","\n","def display_training_curves(training, validation, title, subplot):\n","  if subplot%10==1: # set up the subplots on the first call\n","    plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n","    plt.tight_layout()\n","  ax = plt.subplot(subplot)\n","  ax.set_facecolor('#F8F8F8')\n","  ax.plot(training)\n","  ax.plot(validation)\n","  ax.set_title('model '+ title)\n","  ax.set_ylabel(title)\n","  ax.set_xlabel('epoch')\n","  ax.legend(['train', 'valid.'])"]},{"cell_type":"markdown","id":"1e8324a6","metadata":{"id":"1e8324a6"},"source":["## Read images and labels from TFRecords"]},{"cell_type":"code","execution_count":null,"id":"f89c2ce1","metadata":{"id":"f89c2ce1"},"outputs":[],"source":["def read_tfrecord(example):\n","    features = {\n","        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n","        \"class\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means scalar\n","        \"one_hot_class\": tf.io.VarLenFeature(tf.float32),\n","    }\n","    example = tf.parse_single_example(example, features)\n","    image = tf.image.decode_jpeg(example['image'], channels=3)\n","    image = tf.cast(image, tf.float32) / 255.0  # convert image to floats in [0, 1] range\n","    image = tf.reshape(image, [*IMAGE_SIZE, 3]) # explicit size will be needed for TPU\n","    class_label = tf.cast(example['class'], tf.int32)\n","    one_hot_class = tf.sparse.to_dense(example['one_hot_class'])\n","    one_hot_class = tf.reshape(one_hot_class, [5])\n","    return image, one_hot_class\n","\n","def load_dataset(filenames):\n","  # read from TFRecords. For optimal performance, use \"interleave(tf.data.TFRecordDataset, ...)\"\n","  # to read from multiple TFRecord files at once and set the option experimental_deterministic = False\n","  # to allow order-altering optimizations.\n","\n","  option_no_order = tf.data.Options()\n","  option_no_order.experimental_deterministic = False\n","\n","  dataset = tf.data.Dataset.from_tensor_slices(filenames)\n","  dataset = dataset.with_options(option_no_order)\n","  #dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=16)\n","  dataset = dataset.interleave(tf.data.TFRecordDataset, cycle_length=16, num_parallel_calls=AUTO) # faster\n","  dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTO)\n","  return dataset"]},{"cell_type":"code","execution_count":null,"id":"0407ce93","metadata":{"id":"0407ce93"},"outputs":[],"source":["display_9_images_from_dataset(load_dataset(training_filenames))"]},{"cell_type":"markdown","id":"953cc043","metadata":{"id":"953cc043"},"source":["## training and validation datasets"]},{"cell_type":"code","execution_count":null,"id":"60057a9f","metadata":{"id":"60057a9f"},"outputs":[],"source":["def data_augment(image, one_hot_class):\n","    image = tf.image.random_flip_left_right(image)\n","    image = tf.image.random_saturation(image, 0, 2)\n","    return image, one_hot_class\n","\n","def get_batched_dataset(filenames, augment_data):\n","  dataset = load_dataset(filenames)\n","  dataset = dataset.cache() # This dataset fits in RAM\n","  dataset = dataset.repeat()\n","  if augment_data:\n","      dataset = dataset.map(data_augment, num_parallel_calls=AUTO)\n","  dataset = dataset.shuffle(2048)\n","  dataset = dataset.batch(BATCH_SIZE, drop_remainder=True) # drop_remainder will be needed on TPU\n","  dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n","  # For proper ordering of map/batch/repeat/prefetch, see Dataset performance guide: https://www.tensorflow.org/guide/performance/datasets\n","  return dataset\n","\n","def get_training_dataset():\n","  return get_batched_dataset(training_filenames, augment_data=True)\n","\n","def get_validation_dataset():\n","  return get_batched_dataset(validation_filenames, augment_data=False)\n","\n","some_flowers, some_labels = dataset_to_numpy_util(load_dataset(validation_filenames), 8*20)"]},{"cell_type":"markdown","id":"6b5473e1","metadata":{"id":"6b5473e1"},"source":["## Model"]},{"cell_type":"code","execution_count":null,"id":"9e4262cb","metadata":{"id":"9e4262cb"},"outputs":[],"source":["bnmomemtum=0.9\n","def fire(x, squeeze, expand):\n","  y  = tf.keras.layers.Conv2D(filters=squeeze, kernel_size=1, activation='relu', padding='same')(x)\n","  y = tf.keras.layers.BatchNormalization(momentum=bnmomemtum)(y)\n","  y1 = tf.keras.layers.Conv2D(filters=expand//2, kernel_size=1, activation='relu', padding='same')(y)\n","  y1 = tf.keras.layers.BatchNormalization(momentum=bnmomemtum)(y1)\n","  y3 = tf.keras.layers.Conv2D(filters=expand//2, kernel_size=3, activation='relu', padding='same')(y)\n","  y3 = tf.keras.layers.BatchNormalization(momentum=bnmomemtum)(y3)\n","  return tf.keras.layers.concatenate([y1, y3])\n","\n","def fire_module(squeeze, expand):\n","  return lambda x: fire(x, squeeze, expand)\n","\n","x = tf.keras.layers.Input(shape=[*IMAGE_SIZE, 3]) # input is 192x192 pixels RGB\n","\n","y = tf.keras.layers.Conv2D(kernel_size=3, filters=32, padding='same', use_bias=True, activation='relu')(x)\n","y = tf.keras.layers.BatchNormalization(momentum=bnmomemtum)(y)\n","y = fire_module(24, 48)(y)\n","y = tf.keras.layers.MaxPooling2D(pool_size=2)(y)\n","y = fire_module(48, 96)(y)\n","y = tf.keras.layers.MaxPooling2D(pool_size=2)(y)\n","y = fire_module(64, 128)(y)\n","y = tf.keras.layers.MaxPooling2D(pool_size=2)(y)\n","y = fire_module(48, 96)(y)\n","y = tf.keras.layers.MaxPooling2D(pool_size=2)(y)\n","y = fire_module(24, 48)(y)\n","y = tf.keras.layers.GlobalAveragePooling2D()(y)\n","y = tf.keras.layers.Dense(5, activation='softmax')(y)\n","\n","model = tf.keras.Model(x, y)\n","\n","model.compile(\n","  optimizer='adam',\n","  loss= 'categorical_crossentropy',\n","  metrics=['accuracy'])\n","\n","model.summary()"]},{"cell_type":"markdown","id":"1fae58b8","metadata":{"id":"1fae58b8"},"source":["## Training"]},{"cell_type":"code","execution_count":null,"id":"17f813bd","metadata":{"id":"17f813bd"},"outputs":[],"source":["if tpu:\n","  strategy = tf.contrib.tpu.TPUDistributionStrategy(tpu)\n","  tpu_model = tf.contrib.tpu.keras_to_tpu_model(model, strategy=strategy)"]},{"cell_type":"code","execution_count":null,"id":"d32921ba","metadata":{"id":"d32921ba"},"outputs":[],"source":["EPOCHS = 15\n","\n","start_time = time.time()\n","\n","if tpu:\n","\n","  # Little wrinkle: reading directly from dataset object not yet implemented\n","  # for Keras/TPU. Please use a function that returns a dataset.\n","  history = tpu_model.fit(get_training_dataset, steps_per_epoch=steps_per_epoch, epochs=EPOCHS,\n","                          validation_data=get_validation_dataset, validation_steps=validation_steps)\n","else:\n","  history = model.fit(get_training_dataset(), steps_per_epoch=steps_per_epoch, epochs=EPOCHS,\n","                      validation_data=get_validation_dataset(), validation_steps=validation_steps)\n","\n","end_time = time.time()\n","print(\"Time elapsed: \", end_time-start_time, \" sec\")"]},{"cell_type":"code","execution_count":null,"id":"dfd1b255","metadata":{"id":"dfd1b255"},"outputs":[],"source":["print(history.history.keys())\n","display_training_curves(history.history['acc'], history.history['val_acc'], 'accuracy', 211)\n","display_training_curves(history.history['loss'], history.history['val_loss'], 'loss', 212)"]},{"cell_type":"markdown","id":"1283cd0f","metadata":{"id":"1283cd0f"},"source":["## Predictions"]},{"cell_type":"code","execution_count":null,"id":"9f58120a","metadata":{"id":"9f58120a"},"outputs":[],"source":["inference_model = model\n","if tpu:\n","  inference_model.set_weights(tpu_model.get_weights()) # this copies the weights from TPU to CPU"]},{"cell_type":"code","execution_count":null,"id":"6f234202","metadata":{"id":"6f234202"},"outputs":[],"source":["# randomize the input so that you can execute multiple times to change results\n","permutation = np.random.permutation(8*20)\n","some_flowers, some_labels = (some_flowers[permutation], some_labels[permutation])\n","\n","predictions = inference_model.predict(some_flowers, batch_size=16)\n","evaluations = inference_model.evaluate(some_flowers, some_labels, batch_size=16)\n","\n","print(np.array(CLASSES)[np.argmax(predictions, axis=-1)].tolist())\n","print('[val_loss, val_acc]', evaluations)"]},{"cell_type":"code","execution_count":null,"id":"68128b8a","metadata":{"id":"68128b8a"},"outputs":[],"source":["display_9_images_with_predictions(some_flowers, predictions, some_labels)"]},{"cell_type":"markdown","id":"7677e854","metadata":{"id":"7677e854"},"source":["## License"]},{"cell_type":"markdown","id":"f85995fd","metadata":{"id":"f85995fd"},"source":["\n","\n","---\n","\n","\n","author: Martin Gorner<br>\n","twitter: @martin_gorner\n","\n","\n","---\n","\n","\n","Copyright 2019 Google LLC\n","\n","Licensed under the Apache License, Version 2.0 (the \"License\");\n","you may not use this file except in compliance with the License.\n","You may obtain a copy of the License at\n","\n","    http://www.apache.org/licenses/LICENSE-2.0\n","\n","Unless required by applicable law or agreed to in writing, software\n","distributed under the License is distributed on an \"AS IS\" BASIS,\n","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","See the License for the specific language governing permissions and\n","limitations under the License.\n","\n","\n","---\n","\n","\n","This is not an official Google product but sample code provided for an educational purpose\n"]}],"metadata":{"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}