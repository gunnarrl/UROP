{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "608c5033",
   "metadata": {},
   "source": [
    "# CS109A Project Group 21\n",
    "# Baseline Model\n",
    "\n",
    "*****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c298c834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.sparse import csr_matrix\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3e0407",
   "metadata": {},
   "source": [
    "### Importing the relevant datasets\n",
    "\n",
    "First we import two subset of 100 playlists, each subset of 100 playlists to be used for the training and test sets respectively. \n",
    "\n",
    "These playlists are randomly chosen from the full one million playlist dataset that has been matched with the Spotify API data, thus including data on track-specific features such as loudness, speechiness and tempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7599e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"data/subset100playlists.csv\")\n",
    "test_df = pd.read_csv(\"data/subset100playlists_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd66b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a65da3",
   "metadata": {},
   "source": [
    "### Creating the train and test set\n",
    "\n",
    "We then create the train and test set by keeping select numeric features and the track URI, as a way to maintain a unique ID for each song.\n",
    "\n",
    "Specifically, for the test set, we split it into two subsets: calibration (20%) and withheld songs (80%), where the calibration songs are used as inputs to the model to predict songs. These predicted songs are then compared to the withheld songs as a comparison metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ebcf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "df_cleaned= train_df.select_dtypes(include=numerics)\n",
    "\n",
    "var_drop = [\"index\",\"pid\",\"pos\", \"count\", \"Unnamed: 0\"]\n",
    "df_cleaned = df_cleaned.drop(var_drop, axis =1)\n",
    "\n",
    "train = pd.concat([df_cleaned, train_df['track_uri']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bde39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_cleaned = test_df.select_dtypes(include=numerics)\n",
    "\n",
    "test_var_drop = [\"index\",\"pos\", \"count\", \"Unnamed: 0\"]\n",
    "test_df_cleaned = test_df_cleaned.drop(test_var_drop, axis =1)\n",
    "\n",
    "test_df_cleaned = pd.concat([test_df_cleaned, test_df['track_uri']],axis=1)\n",
    "calibration, withheld = train_test_split(test_df_cleaned, test_size=0.8, random_state=209, stratify = test_df_cleaned['pid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6380e1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121b0cfd",
   "metadata": {},
   "source": [
    "### Dropping duplicates\n",
    "In the baseline model, given that we are only looking at predicting songs based on their similarity to other tracks, we can drop duplicates of the same song from the training set. We do so below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0ac73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop_duplicates(subset =\"track_uri\",keep = False, inplace = True) \n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c355c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.set_index('track_uri') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5563f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ad7387",
   "metadata": {},
   "source": [
    "### Fitting the training set to a Nearest Neighbors model\n",
    "\n",
    "This leaves us with 3098 songs in our training set, which we then fit onto an unsupervised Nearest Neighbors learning model, where n_neighbors = 20 and cosine distance is used as a distance of measure. \n",
    "\n",
    "Here, we have set the neighbors search algorithm to auto, so that the algorithm attempts to determine the best approach from the training data across the options of BallTree, KDTree, and a brute-force algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11abbd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot ratings into song features\n",
    "model_knn = NearestNeighbors(metric='cosine', algorithm='auto', n_neighbors=20, n_jobs=-1)# fit the dataset\n",
    "model_knn.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423adbc9",
   "metadata": {},
   "source": [
    "### Creating a function to make recommendations\n",
    "\n",
    "We then proceed to create a function that will take as inputs 1) the Nearest Neighbors model fitted on the training data, 2) a playlist id (to identify the songs in the test set), 3) the number of neighbors to select from and 4) number of recommended songs to predict.\n",
    "\n",
    "This function will return a list of recommended songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4baaadf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_recommendation(model_knn, playlist_id, n_neighbors, n_recommendations):\n",
    "    \n",
    "    calibration_songs = calibration[calibration['pid']==playlist_id]\n",
    "    calibration_songs_clean = calibration_songs.drop(columns=['pid', 'track_uri'])\n",
    "\n",
    "    song_freq_dict = {}\n",
    "\n",
    "    for index, song in calibration_songs_clean.iterrows():\n",
    "        distances, indices = model_knn.kneighbors(song.values.reshape(1,-1), n_neighbors=n_neighbors)\n",
    "\n",
    "        for index in indices[0]:\n",
    "            if song_freq_dict.get(index) is None:\n",
    "                song_freq_dict[index] = 1\n",
    "            else:\n",
    "                song_freq_dict[index] += 1\n",
    "\n",
    "    k = Counter(song_freq_dict) \n",
    "\n",
    "    # Finding n highest values \n",
    "    top_songs = [i[0] for i in k.most_common(n_recommendations)]    \n",
    "\n",
    "    rec_songs = train.iloc[top_songs].index\n",
    "\n",
    "    return rec_songs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290be11b",
   "metadata": {},
   "source": [
    "### Measuring success\n",
    "\n",
    "For starters, we will use the R-precision score to measure how successful our song predictions are. Here, we define a function `r_precision`, which computes number of retrieved relevant tracks divided by the number of known relevant tracks (i.e., the number of withheld tracks). It takes as inputs a list of predicted songs and compares it against a list of the actual songs from the given playlist (\"withheld songs\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97edf8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate r_precision (https://recsys-challenge.spotify.com/rules)\n",
    "#R-precision is the number of retrieved relevant tracks divided by the number of known relevant tracks (i.e., the number of withheld tracks) \n",
    "\n",
    "def r_precision(preds, known):\n",
    "    for i in known:\n",
    "        if i in preds:\n",
    "            song = combined_df[combined_df['track_uri']==i]['track_name']\n",
    "            print(f'{song} appeared in both our predicted playlist and the known list of songs.')\n",
    "    score = np.sum(known.isin(preds))/known.shape[0]\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a219fd62",
   "metadata": {},
   "source": [
    "### Running the baseline model on test data\n",
    "\n",
    "We then run the following code to loop through all the unique playlists in the test set to predict songs based on a random subset of 20% of songs from the given test playlist (`calibration`). The predicted songs are then fed into the R-precision score function together with the remaining 80% of songs from the given test playlist (`withheld`).\n",
    "\n",
    "For testing purposes, we print out the actual track names of the songs being predicted and the withheld songs, so that we can get a qualitative understanding of the songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3051dfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors, n_recommendations = 50, 100\n",
    "r_precision_scores = []\n",
    "\n",
    "#Loop through all unique playlists in test set to identify predicted songs\n",
    "for index, pid in enumerate(withheld['pid'].drop_duplicates()): \n",
    "    print (index, pid)\n",
    "    pred_songs = make_recommendation(model_knn, pid, n_neighbors, n_recommendations)\n",
    "    validation_set = withheld[withheld.pid == pid].track_uri\n",
    "    print(\"Predicted songs\\n\", combined_df[combined_df['track_uri'].isin(pred_songs)]['track_name'])\n",
    "    print(\"Known songs\\n\", test_df[test_df['track_uri'].isin(validation_set)]['track_name'])\n",
    "    \n",
    "    rps = r_precision(list(pred_songs), validation_set)\n",
    "    r_precision_scores.append(rps)\n",
    "    \n",
    "    print(f'Playlist {pid}: The R precision score is {rps}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9696a132",
   "metadata": {},
   "source": [
    "### Measuring success\n",
    "\n",
    "To measure success for the baseline model, we compute the mean of the R-precision scores across all the playlists in the test set. This returns us a value of 0.005, which implies that on average, out of all the withheld songs in the test playlists, we only manage to predict 0.8% of them using our model. This is low -  as a baseline model, it gives us a sense of the challenges that lie ahead in our predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c271b6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_rp = np.mean(r_precision_scores)\n",
    "\n",
    "print('Avg. R-Precision Score: ', avg_rp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2453b8",
   "metadata": {},
   "source": [
    "### Challenges and next steps\n",
    "\n",
    "One of the significant challenges that we have identified could be the fact that the withheld songs in the test data set are not in our original training set. Hence, logically, the model trained on songs in the training set would not be able to return predicted songs that would match 1-to-1 with the withheld songs.\n",
    "\n",
    "To validate this hypothesis, we ran a quick check on the intersection of songs between both sets, and as expected, only 1552 songs in the withheld list of songs, out of a total of 11074 songs, appear in the training set.\n",
    "\n",
    "Going ahead, this will mean possibly expanding the training set to increase the overlap in songs between the two sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64f4b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(lst1, lst2): \n",
    "    lst3 = [value for value in lst1 if value in lst2] \n",
    "    return lst3 \n",
    "  \n",
    "print (len(intersection(list(withheld.track_uri), list(train.index))))\n",
    "print (len(list(withheld.track_uri)))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
