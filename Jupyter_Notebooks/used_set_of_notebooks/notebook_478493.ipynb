{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ed3332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfba75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18fd908",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, classification_report\n",
    "def metrics(y_test, y_pred):\n",
    "    y_pred = y_pred.argmax(axis=1)\n",
    "    print(y_pred)\n",
    "    print(\"Accuracy Score : \", accuracy_score(y_test, y_pred))\n",
    "    print(\"Precision Score : \", precision_score(y_test, y_pred, average=\"weighted\"))\n",
    "    print(\"Classification Report : \\n\", classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix : \\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1295f6ad",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Load the data\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f233a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Always a good idea to look at shape before getting started.\n",
    "print(f\"X train shape : {X_train.shape}\")\n",
    "print(f\"y train shape : {y_train.shape}\")\n",
    "print(f\"X test shape : {X_test.shape}\")\n",
    "print(f\"y test shape : {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bface86",
   "metadata": {},
   "source": [
    "##### Now, if we see training set contains 60000 samples. \n",
    "##### Testing set has 10000. \n",
    "##### As shape of each image is 28 * 28 pixels (picture element) --> can be interpreted as grayscale as no color layer is specified.\n",
    "\n",
    "##### In grayscale 255 --> white , 0 --> black and any other value --> shade of grey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c934054a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All of the above are numpy arrays --> run much faster than python lists.\n",
    "# numpy is implemented in C.\n",
    "\n",
    "# tensorflow is named after \"tensor\" which is a generalised numpy array.\n",
    "\n",
    "print(type(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f362a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalising values as gradient descent works better on small scale data.\n",
    "\n",
    "X_train , X_test = X_train/255, X_test/255\n",
    "\n",
    "# Converting input suitable to CNN architecture.\n",
    "\n",
    "X_train = np.reshape(X_train,newshape=(X_train.shape+(1,)))\n",
    "\n",
    "print(f\"New X_train shape : {X_train.shape}\")\n",
    "\n",
    "X_test = np.reshape(X_test, newshape=(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1))\n",
    "\n",
    "print(f\"New X_test shape : {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e938cf",
   "metadata": {},
   "source": [
    "##### Now, input is suitable for Convolutional neural network.\n",
    "##### Also, it is properly scaled for gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34d9684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying to make output into proper format\n",
    "\n",
    "y_train, y_test = y_train.flatten(), y_test.flatten()\n",
    "\n",
    "print(f\"New shape of y_train {y_train.shape}\")\n",
    "print(f\"New shape of y_test {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30aa992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label mapping\n",
    "labels = '''T-shirt/top\n",
    "Trouser\n",
    "Pullover\n",
    "Dress\n",
    "Coat\n",
    "Sandal\n",
    "Shirt\n",
    "Sneaker\n",
    "Bag\n",
    "Ankle boot'''.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ef4afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting number of classes\n",
    "K = len(set(y_train))\n",
    "print(f\"No. of classes : {K}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e01358b",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Building the model\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fa5e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bbfd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buliding model using keras functional API.\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "input_shape = X_train[0].shape\n",
    "feature_map = [32, 64, 128]\n",
    "dense_size = [512]\n",
    "filter_size= (3,3)\n",
    "\n",
    "i = Input(shape=input_shape)\n",
    "x = Conv2D(filters=feature_map[0], kernel_size=filter_size, activation=\"relu\", strides=2)(i)\n",
    "x = Conv2D(filters=feature_map[1], kernel_size=filter_size, activation=\"relu\", strides=2)(x)\n",
    "x = Conv2D(filters=feature_map[2], kernel_size=filter_size, activation=\"relu\", strides=2)(x)\n",
    "\n",
    "# Dense layer takes flattened input\n",
    "x = Flatten()(x)\n",
    "\n",
    "# Building dense/ fully connected layers from here\n",
    "x = Dense(dense_size[0], activation=\"relu\")(x)\n",
    "x = Dense(K, activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(i, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331ec21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "r = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539a57e8",
   "metadata": {},
   "source": [
    "##### Early Stopping --> Stop when loss of test dataset increases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf252ad",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Visualsing results of model\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8476901b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e1ea0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(r.history[\"accuracy\"], label=\"Accuracy\")\n",
    "plt.plot(r.history[\"val_accuracy\"], label=\"Validation Acc.\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"No. of epochs\")\n",
    "plt.ylabel(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1910897f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(r.history[\"loss\"], label=\"Loss\")\n",
    "plt.plot(r.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac59a34c",
   "metadata": {},
   "source": [
    "### If we observe above model is clearly overfitting. \n",
    "#### We can regularize by providing it with Dropout or some kernel l2 regularizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500484bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = Input(shape=(X_train[0].shape))\n",
    "x = Conv2D(32, (3,3), strides=2, activation=\"relu\")(i)\n",
    "x = Conv2D(64, (3,3), strides=2, activation=\"relu\")(x)\n",
    "x = Conv2D(128, (3,3), strides=2, activation=\"relu\")(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(128, activation=\"relu\")(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(K, activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(i,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ea980d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "r = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb3915d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(r.history[\"accuracy\"], label=\"Accuracy\")\n",
    "plt.plot(r.history[\"val_accuracy\"], label=\"Validation Acc.\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"No. of epochs\")\n",
    "plt.ylabel(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a2bda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(r.history[\"loss\"], label=\"Loss\")\n",
    "plt.plot(r.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1b8800",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea58913e",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Misclassified points\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5ba2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassified_index = np.where(y_pred.argmax(axis=1) != y_test)\n",
    "X_test = X_test * 255\n",
    "misclassified_index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdb2b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.choice(misclassified_index[0])\n",
    "plt.imshow(X_test[i].reshape(28,28), cmap='gray')\n",
    "plt.title(\"True label: %s Predicted: %s\" % (labels[y_test[i]], labels[y_pred.argmax(axis=1)[i]]));"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
