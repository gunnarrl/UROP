{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f7fd437",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6082c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "from skimage.feature import hog\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from scipy.ndimage.measurements import label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccaa4ed",
   "metadata": {},
   "source": [
    "## Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c9b318",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = glob.glob('./vehicles/**/*.png')\n",
    "notcars = glob.glob('./non-vehicles/**/*.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321f9bd6",
   "metadata": {},
   "source": [
    "## Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068c9647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display output images\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 1)\n",
    "ax.xaxis.set_visible(False)\n",
    "ax.yaxis.set_visible(False)\n",
    "img_car = mpimg.imread(cars[np.random.randint(0,len(cars))])\n",
    "plt.title('Vehicle Image', fontsize=20)\n",
    "plt.imshow(img_car)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 2)\n",
    "ax.xaxis.set_visible(False)\n",
    "ax.yaxis.set_visible(False)\n",
    "img_not_car = mpimg.imread(notcars[np.random.randint(0,len(notcars))])\n",
    "plt.title('Non-Vehicle Image', fontsize=20)\n",
    "plt.imshow(img_not_car)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d05715",
   "metadata": {},
   "source": [
    "## Histogram of Gradients (HOG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d428067",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, \n",
    "                        vis=False, feature_vec=True):\n",
    "    # Call with two outputs if vis==True\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient, \n",
    "                                  pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block),\n",
    "                                  block_norm= 'L2-Hys',\n",
    "                                  transform_sqrt=False, \n",
    "                                  visualize=vis, feature_vector=feature_vec)\n",
    "        return features, hog_image\n",
    "    # Otherwise call with one output\n",
    "    else:      \n",
    "        features = hog(img, orientations=orient, \n",
    "                       pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block),\n",
    "                       block_norm= 'L2-Hys',\n",
    "                       transform_sqrt=False, \n",
    "                       visualize=vis, feature_vector=feature_vec)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89b4b28",
   "metadata": {},
   "source": [
    "Visualize HOG on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dd6b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_img = mpimg.imread(cars[np.random.randint(0,len(cars))])\n",
    "_, car_dst = get_hog_features(car_img, 9, 8, 2, vis=True, feature_vec=True)\n",
    "noncar_img = mpimg.imread(notcars[np.random.randint(0,len(notcars))])\n",
    "_, noncar_dst = get_hog_features(noncar_img, 9, 8, 2, vis=True, feature_vec=True)\n",
    "\n",
    "# Visualize \n",
    "f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(10,10))\n",
    "f.subplots_adjust(hspace = .4, wspace=.2)\n",
    "ax1.imshow(car_img)\n",
    "ax1.set_title('Vehicle Image', fontsize=20)\n",
    "ax1.xaxis.set_visible(False)\n",
    "ax1.yaxis.set_visible(False)\n",
    "ax2.imshow(car_dst, cmap='gray')\n",
    "ax2.set_title('Vehicle HOG', fontsize=20)\n",
    "ax2.xaxis.set_visible(False)\n",
    "ax2.yaxis.set_visible(False)\n",
    "ax3.imshow(noncar_img)\n",
    "ax3.set_title('Non-Vehicle Image', fontsize=20)\n",
    "ax3.xaxis.set_visible(False)\n",
    "ax3.yaxis.set_visible(False)\n",
    "ax4.imshow(noncar_dst, cmap='gray')\n",
    "ax4.set_title('Non-Vehicle HOG', fontsize=20)\n",
    "ax4.xaxis.set_visible(False)\n",
    "ax4.yaxis.set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5718a5",
   "metadata": {},
   "source": [
    "## Color transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61937a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_color(image, color_space):\n",
    "    if color_space != 'RGB':\n",
    "        if color_space == 'HSV':\n",
    "            feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "        elif color_space == 'LUV':\n",
    "            feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2LUV)\n",
    "        elif color_space == 'HLS':\n",
    "            feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "        elif color_space == 'YUV':\n",
    "            feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "        elif color_space == 'YCrCb':\n",
    "            feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YCrCb)\n",
    "    else:\n",
    "        feature_image = np.copy(image)\n",
    "    return feature_image\n",
    "\n",
    "def bin_spatial(img, size=(32, 32)):\n",
    "    color1 = cv2.resize(img[:,:,0], size).ravel()\n",
    "    color2 = cv2.resize(img[:,:,1], size).ravel()\n",
    "    color3 = cv2.resize(img[:,:,2], size).ravel()\n",
    "    return np.hstack((color1, color2, color3))\n",
    "                        \n",
    "def color_hist(img, nbins=32):    #bins_range=(0, 256)\n",
    "    # Compute the histogram of the color channels separately\n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=nbins)\n",
    "    channel2_hist = np.histogram(img[:,:,1], bins=nbins)\n",
    "    channel3_hist = np.histogram(img[:,:,2], bins=nbins)\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    \n",
    "    return hist_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c5b6fc",
   "metadata": {},
   "source": [
    "## Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f44f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_heat(heatmap, bbox_list):\n",
    "    # Iterate through list of bboxes\n",
    "    for box in bbox_list:\n",
    "        # Add += 1 for all pixels inside each bbox\n",
    "        # Assuming each \"box\" takes the form ((x1, y1), (x2, y2))\n",
    "        heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "\n",
    "    # Return updated heatmap\n",
    "    return heatmap# Iterate through list of bboxes\n",
    "    \n",
    "def apply_threshold(heatmap, threshold):\n",
    "    # Zero out pixels below the threshold\n",
    "    heatmap[heatmap <= threshold] = 0\n",
    "    # Return thresholded map\n",
    "    return heatmap\n",
    "\n",
    "def draw_labeled_bboxes(img, labels):\n",
    "    # Iterate through all detected cars\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        # Draw the box on the image\n",
    "        cv2.rectangle(img, bbox[0], bbox[1], (0,0,255), 6)\n",
    "    # Return the image\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3bb9b8",
   "metadata": {},
   "source": [
    "## Exctract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790a8c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract features from a list of images\n",
    "# Have this function call bin_spatial() and color_hist()\n",
    "def extract_features(imgs, color_space='RGB', spatial_size=(32, 32),\n",
    "                        hist_bins=32, orient=9, \n",
    "                        pix_per_cell=8, cell_per_block=2, hog_channel=0,\n",
    "                        spatial_feat=True, hist_feat=True, hog_feat=True):\n",
    "    # Create a list to append feature vectors to\n",
    "    features = []\n",
    "    # Iterate through the list of images\n",
    "    for file in imgs:\n",
    "        file_features = []\n",
    "        # Read in each one by one\n",
    "        image = mpimg.imread(file)\n",
    "        \n",
    "        # Apply color conversion if other than 'RGB'\n",
    "        feature_image = convert_color(image, color_space=color_space)     \n",
    "\n",
    "        if spatial_feat == True:\n",
    "            spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "            file_features.append(spatial_features)\n",
    "        if hist_feat == True:\n",
    "            # Apply color_hist()\n",
    "            hist_features = color_hist(feature_image, nbins=hist_bins)\n",
    "            file_features.append(hist_features)\n",
    "        if hog_feat == True:\n",
    "        # Call get_hog_features() with vis=False, feature_vec=True\n",
    "            if hog_channel == 'ALL':\n",
    "                hog_features = []\n",
    "                for channel in range(feature_image.shape[2]):\n",
    "                    hog_features.append(get_hog_features(feature_image[:,:,channel], \n",
    "                                        orient, pix_per_cell, cell_per_block, \n",
    "                                        vis=False, feature_vec=True))\n",
    "                hog_features = np.ravel(hog_features)        \n",
    "            else:\n",
    "                hog_features = get_hog_features(feature_image[:,:,hog_channel], orient, \n",
    "                            pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "            # Append the new feature vector to the features list\n",
    "            file_features.append(hog_features)\n",
    "        features.append(np.concatenate(file_features))        \n",
    "        \n",
    "    # Return list of feature vectors\n",
    "    return features\n",
    "\n",
    "# Feature extraction parameters\n",
    "color_space = 'HSV' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "orient = 9\n",
    "pix_per_cell = 8\n",
    "cell_per_block = 2\n",
    "hog_channel = 'ALL' # Can be 0, 1, 2, or \"ALL\"\n",
    "spatial_size = (32, 32) # Spatial binning dimensions\n",
    "hist_bins = 32\n",
    "spatial_feat = True # Spatial features on or off\n",
    "hist_feat = True # Histogram features on or off\n",
    "hog_feat = True # HOG features on or off\n",
    "\n",
    "t = time.time()\n",
    "car_features = extract_features(cars, color_space=color_space, \n",
    "                        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                        orient=orient, pix_per_cell=pix_per_cell, \n",
    "                        cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                        hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "notcar_features = extract_features(notcars, color_space=color_space, \n",
    "                        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                        orient=orient, pix_per_cell=pix_per_cell, \n",
    "                        cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                        hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to extract features')\n",
    "\n",
    "# Create an array stack of feature vectors\n",
    "X = np.vstack((car_features, notcar_features)).astype(np.float64)\n",
    "\n",
    "# Define the labels vector\n",
    "y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))\n",
    "\n",
    "# Split up data into randomized training and test sets\n",
    "rand_state = np.random.randint(0, 100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=rand_state)\n",
    "\n",
    "# Fit a per-column scaler\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "# Apply the scaler to X\n",
    "X_train = X_scaler.transform(X_train)\n",
    "X_test = X_scaler.transform(X_test)\n",
    "\n",
    "print('Using:', color_space,'color space', orient,'orientations',pix_per_cell,\n",
    "    'pixels per cell and', cell_per_block,'cells per block', hog_channel, 'hog channel',\n",
    "     spatial_size, 'spatial size', hist_bins, 'hist bins')\n",
    "print('Feature vector length:', len(X_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3919c031",
   "metadata": {},
   "source": [
    "## Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c039738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a linear SVC \n",
    "svc = LinearSVC()\n",
    "# Check the training time for the SVC\n",
    "t = time.time()\n",
    "svc.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to train SVC')\n",
    "# Check the score of the SVC\n",
    "print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))\n",
    "# Check the prediction time for a single sample\n",
    "t=time.time()\n",
    "n_predict = 10\n",
    "print('My SVC predicts: ', svc.predict(X_test[0:n_predict]))\n",
    "print('For these',n_predict, 'labels: ', y_test[0:n_predict])\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 5), 'Seconds to predict', n_predict,'labels with SVC')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f66955",
   "metadata": {},
   "source": [
    "## Find Car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efa2c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_car(img, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins, color_space, show_all_rectangles=False):\n",
    "    \"\"\"\n",
    "    Extracts features using hog sub-sampling and makes predictions\n",
    "    \"\"\"\n",
    "    \n",
    "    # I extracted training data from .png images \n",
    "    # (scaled 0 to 1 by mpimg) and the image I \n",
    "    # am searching is a .jpg (scaled 0 to 255)\n",
    "    # Comment the following line if img is .png\n",
    "    img = img.astype(np.float32)/255\n",
    "    \n",
    "    img_tosearch = img[ystart:ystop,:,:]\n",
    "    ctrans_tosearch = convert_color(img_tosearch, color_space=color_space)\n",
    "    if scale != 1:\n",
    "        imshape = ctrans_tosearch.shape\n",
    "        ctrans_tosearch = cv2.resize(ctrans_tosearch, (np.int(imshape[1]/scale), np.int(imshape[0]/scale)))\n",
    "        \n",
    "    ch1 = ctrans_tosearch[:,:,0]\n",
    "    ch2 = ctrans_tosearch[:,:,1]\n",
    "    ch3 = ctrans_tosearch[:,:,2]\n",
    "\n",
    "    # Define blocks and steps\n",
    "    nxblocks = (ch1.shape[1] // pix_per_cell) - cell_per_block + 1\n",
    "    nyblocks = (ch1.shape[0] // pix_per_cell) - cell_per_block + 1 \n",
    "    nfeat_per_block = orient*cell_per_block**2\n",
    "    \n",
    "    # 64 was the orginal sampling rate, with 8 cells and 8 pix per cell\n",
    "    window = 64\n",
    "    nblocks_per_window = (window // pix_per_cell) - cell_per_block + 1\n",
    "    cells_per_step = 2  # Instead of overlap, define how many cells to step\n",
    "    nxsteps = (nxblocks - nblocks_per_window) // cells_per_step + 1\n",
    "    nysteps = (nyblocks - nblocks_per_window) // cells_per_step + 1\n",
    "    \n",
    "    # Compute individual channel HOG features for the entire image\n",
    "    hog1 = get_hog_features(ch1, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog2 = get_hog_features(ch2, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog3 = get_hog_features(ch3, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    \n",
    "    box_list = []\n",
    "        \n",
    "    for xb in range(nxsteps):\n",
    "        for yb in range(nysteps):\n",
    "            ypos = yb*cells_per_step\n",
    "            xpos = xb*cells_per_step\n",
    "            # Extract HOG for this patch\n",
    "            hog_feat1 = hog1[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_feat2 = hog2[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_feat3 = hog3[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_features = np.hstack((hog_feat1, hog_feat2, hog_feat3))\n",
    "\n",
    "            xleft = xpos*pix_per_cell\n",
    "            ytop = ypos*pix_per_cell\n",
    "\n",
    "            # Extract the image patch\n",
    "            subimg = cv2.resize(ctrans_tosearch[ytop:ytop+window, xleft:xleft+window], (64,64))\n",
    "          \n",
    "            # Get color features\n",
    "            spatial_features = bin_spatial(subimg, size=spatial_size)\n",
    "            hist_features = color_hist(subimg, nbins=hist_bins)\n",
    "\n",
    "            # Scale features and make a prediction\n",
    "            test_features = X_scaler.transform(np.hstack((spatial_features, hist_features, hog_features)).reshape(1, -1))    \n",
    "            test_prediction = svc.predict(test_features)\n",
    "            \n",
    "            if test_prediction == 1 or show_all_rectangles:\n",
    "                xbox_left = np.int(xleft*scale)\n",
    "                ytop_draw = np.int(ytop*scale)\n",
    "                win_draw = np.int(window*scale)\n",
    "                box_list.append(((xbox_left, ytop_draw+ystart),(xbox_left+win_draw,ytop_draw+win_draw+ystart)))\n",
    "                #cv2.rectangle(draw_img,(xbox_left, ytop_draw+ystart),(xbox_left+win_draw,ytop_draw+win_draw+ystart),(0,0,255),6)\n",
    "                    \n",
    "    return box_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2866c3",
   "metadata": {},
   "source": [
    "## Search for Best Area\n",
    "\n",
    "Becuase the size and position of cars in the image will be different depending on their distance from the camera, `find_cars` will have to be called a few times with different `ystart`, `ystop`, and `scale` values. These next few blocks of code are for determining the values for these parameters that work best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8097d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boxes(img, bboxes, color=(0, 0, 255), thick=6):\n",
    "    # Make a copy of the image\n",
    "    imcopy = np.copy(img)\n",
    "    random_color = False\n",
    "    # Iterate through the bounding boxes\n",
    "    for bbox in bboxes:\n",
    "        if color == 'random' or random_color:\n",
    "            color = (np.random.randint(0,255), np.random.randint(0,255), np.random.randint(0,255))\n",
    "            random_color = True\n",
    "        # Draw a rectangle given bbox coordinates\n",
    "        cv2.rectangle(imcopy, bbox[0], bbox[1], color, thick)\n",
    "    # Return the image copy with boxes drawn\n",
    "    return imcopy\n",
    "\n",
    "img = mpimg.imread('./test_images/test4.jpg')\n",
    "\n",
    "bboxes = []\n",
    "\n",
    "ystart = 400\n",
    "ystop =  464\n",
    "scale = 1.0\n",
    "    \n",
    "bboxes.append(find_car(img, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins, color_space, show_all_rectangles=True))\n",
    "\n",
    "\n",
    "ystart = 415\n",
    "ystop = 515\n",
    "scale = 1.0\n",
    "\n",
    "bboxes.append(find_car(img, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins, color_space, show_all_rectangles=True))\n",
    "\n",
    "\n",
    "bounding_boxes = [item for sublist in bboxes for item in sublist] \n",
    "img = draw_boxes(img, bounding_boxes, color=(0, 0, 255), thick=2)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(img)\n",
    "print('Number of boxes: ', len(bounding_boxes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0185fb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = mpimg.imread('./test_images/test4.jpg')\n",
    "\n",
    "bboxes = []\n",
    "\n",
    "ystart = 400\n",
    "ystop =  500\n",
    "scale = 1.5\n",
    "    \n",
    "bboxes.append(find_car(img, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins, color_space, show_all_rectangles=True))\n",
    "\n",
    "\n",
    "ystart = 430\n",
    "ystop = 530\n",
    "scale = 1.5\n",
    "\n",
    "bboxes.append(find_car(img, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins, color_space, show_all_rectangles=True))\n",
    "\n",
    "\n",
    "bounding_boxes = [item for sublist in bboxes for item in sublist] \n",
    "img = draw_boxes(img, bounding_boxes, color=(0, 0, 255), thick=2)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(img)\n",
    "print('Number of boxes: ', len(bounding_boxes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40750e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = mpimg.imread('./test_images/test4.jpg')\n",
    "\n",
    "bboxes = []\n",
    "\n",
    "ystart = 400 # 400\n",
    "ystop =  530 # 656\n",
    "scale = 2.0\n",
    "    \n",
    "bboxes.append(find_car(img, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins, color_space, show_all_rectangles=True))\n",
    "\n",
    "\n",
    "ystart = 430\n",
    "ystop = 560\n",
    "scale = 2.0\n",
    "\n",
    "bboxes.append(find_car(img, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins, color_space, show_all_rectangles=True))\n",
    "\n",
    "\n",
    "bounding_boxes = [item for sublist in bboxes for item in sublist] \n",
    "img = draw_boxes(img, bounding_boxes, color=(0, 0, 255), thick=2)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(img)\n",
    "print('Number of boxes: ', len(bounding_boxes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a79fa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = mpimg.imread('./test_images/test4.jpg')\n",
    "\n",
    "bboxes = []\n",
    "\n",
    "ystart = 400\n",
    "ystop =  600\n",
    "scale = 3.0\n",
    "    \n",
    "bboxes.append(find_car(img, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins, color_space, show_all_rectangles=True))\n",
    "\n",
    "\n",
    "ystart = 460\n",
    "ystop = 660\n",
    "scale = 3.0\n",
    "\n",
    "bboxes.append(find_car(img, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins, color_space, show_all_rectangles=True))\n",
    "\n",
    "\n",
    "bounding_boxes = [item for sublist in bboxes for item in sublist] \n",
    "img = draw_boxes(img, bounding_boxes, color=(0, 0, 255), thick=2)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(img)\n",
    "print('Number of boxes: ', len(bounding_boxes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907e7ce8",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f371e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(img, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins, color_space):\n",
    "    \n",
    "    draw_img = np.copy(img)\n",
    "    \n",
    "    bboxes = []\n",
    "\n",
    "    ystart = 400\n",
    "    ystop =  464\n",
    "    scale = 1.0\n",
    "\n",
    "    bboxes.append(find_car(img, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins, color_space))\n",
    "\n",
    "\n",
    "    ystart = 415\n",
    "    ystop = 515\n",
    "    scale = 1.0\n",
    "\n",
    "    bboxes.append(find_car(img, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins, color_space))\n",
    "\n",
    "    ystart = 400\n",
    "    ystop =  500\n",
    "    scale = 1.5\n",
    "\n",
    "    bboxes.append(find_car(img, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins, color_space))\n",
    "\n",
    "\n",
    "    ystart = 430\n",
    "    ystop = 530\n",
    "    scale = 1.5\n",
    "\n",
    "    bboxes.append(find_car(img, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins, color_space))\n",
    "\n",
    "    ystart = 400\n",
    "    ystop =  530\n",
    "    scale = 2.0\n",
    "\n",
    "    bboxes.append(find_car(img, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins, color_space))\n",
    "\n",
    "\n",
    "    ystart = 430\n",
    "    ystop = 560\n",
    "    scale = 2.0\n",
    "\n",
    "    bboxes.append(find_car(img, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins, color_space))\n",
    "\n",
    "    ystart = 400\n",
    "    ystop =  600\n",
    "    scale = 3.0\n",
    "\n",
    "    bboxes.append(find_car(img, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins, color_space))\n",
    "\n",
    "\n",
    "    ystart = 460\n",
    "    ystop = 660\n",
    "    scale = 3.0\n",
    "\n",
    "    bboxes.append(find_car(img, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins, color_space))\n",
    "\n",
    "    box_list = [item for sublist in bboxes for item in sublist]\n",
    "    \n",
    "    heat = np.zeros_like(draw_img[:,:,0]).astype(np.float)\n",
    "    \n",
    "    # Add heat to each box in box list\n",
    "    heat = add_heat(heat,box_list)\n",
    "\n",
    "    # Apply threshold to help remove false positives\n",
    "    heat = apply_threshold(heat,1)\n",
    "    \n",
    "    # Visualize the heatmap when displaying    \n",
    "    heatmap = np.clip(heat, 0, 255)\n",
    "\n",
    "    # Find final boxes from heatmap using label function\n",
    "    labels = label(heatmap)\n",
    "    draw_img = draw_labeled_bboxes(np.copy(draw_img), labels)\n",
    "    \n",
    "    return draw_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82633a6c",
   "metadata": {},
   "source": [
    "## Test pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f4d2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = glob.glob('./test_images/test*.jpg')\n",
    "\n",
    "fig, axs = plt.subplots(3, 2, figsize=(16,14))\n",
    "fig.subplots_adjust(hspace = .004, wspace=.002)\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i, filename in enumerate(test_images):\n",
    "    img = mpimg.imread(filename)\n",
    "    axs[i].imshow(pipeline(img, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins, color_space))\n",
    "    axs[i].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2a05c6",
   "metadata": {},
   "source": [
    "## Test pipeline on video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0b22ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f31e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_video = './output_video.mp4'\n",
    "clip_test = VideoFileClip('test_video.mp4')\n",
    "clip_test_out = clip_test.fl_image(lambda image: pipeline(image, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins, color_space))\n",
    "%time clip_test_out.write_videofile(output_video, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c16011",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_project_video = './output_project_video.mp4'\n",
    "clip_test = VideoFileClip('project_video.mp4')\n",
    "clip_test_out = clip_test.fl_image(lambda image: pipeline(image, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins, color_space))\n",
    "%time clip_test_out.write_videofile(output_project_video, audio=False)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
