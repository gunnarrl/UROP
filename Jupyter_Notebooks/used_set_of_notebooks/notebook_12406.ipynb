{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5982cc83",
   "metadata": {},
   "source": [
    "# Exponential Smoothing Example Code in Python\n",
    "\n",
    "Python Notebook ini berisi contoh kode penerapan Exponential Smooting (ES) dalam bahasa Python. Terdapat beberapa algoritme yang dicontohkan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4366258",
   "metadata": {},
   "source": [
    "## Simple Exponential Smoothing (SES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d62e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SES example\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing\n",
    "from random import random\n",
    "\n",
    "# contrived dataset\n",
    "data = [x + random() for x in range(1, 100)]\n",
    "\n",
    "# fit model\n",
    "model = SimpleExpSmoothing(data)\n",
    "model_fit = model.fit()\n",
    "\n",
    "# make prediction\n",
    "yhat = model_fit.predict(len(data), len(data))\n",
    "print(yhat[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5886377e",
   "metadata": {},
   "source": [
    "# Holt-Winters Exponential Smooting (HWES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c065f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HWES example\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from random import random\n",
    "\n",
    "# contrived dataset\n",
    "data = [x + random() for x in range(1, 100)]\n",
    "\n",
    "# fit model\n",
    "model = ExponentialSmoothing(data)\n",
    "model_fit = model.fit()\n",
    "\n",
    "# make prediction\n",
    "yhat = model_fit.predict(len(data), len(data))\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3301741d",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2f38ba",
   "metadata": {},
   "source": [
    "## More Complicated Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff365a92",
   "metadata": {},
   "source": [
    "Import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0239457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings                                  # `do not disturbe` mode\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np                               # vectors and matrices\n",
    "import pandas                              # tables and data manipulations\n",
    "import matplotlib.pyplot as plt                  # plots\n",
    "import seaborn as sns                            # more plots\n",
    "\n",
    "from dateutil.relativedelta import relativedelta # working with dates with style\n",
    "from scipy.optimize import minimize              # for function minimization\n",
    "\n",
    "import statsmodels.formula.api as smf            # statistics and econometrics\n",
    "import statsmodels.tsa.api as smt\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as scs\n",
    "\n",
    "from itertools import product                    # some useful functions\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e89bad",
   "metadata": {},
   "source": [
    "Load data and Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f34dcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ads = pandas.read_csv('ads.csv', index_col=['Time'], parse_dates=['Time'])\n",
    "currency = pandas.read_csv('currency.csv', index_col=['Time'], parse_dates=['Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57eb1130",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(ads.Ads)\n",
    "plt.title('Ads watched (hourly data)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c9cfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(currency.GEMS_GEMS_SPENT)\n",
    "plt.title('In-game currency spent (daily data)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1263973c",
   "metadata": {},
   "source": [
    "## Exponential Smooting\n",
    "\n",
    "Now, let's see what happens if, instead of weighting the last $k$ values of the time series, we start weighting all available observations while exponentially decreasing the weights as we move further back in time. There exists a formula for **[exponential smoothing](https://en.wikipedia.org/wiki/Exponential_smoothing)** that will help us with this:\n",
    "\n",
    "$$\\hat{y}_{t} = \\alpha \\cdot y_t + (1-\\alpha) \\cdot \\hat y_{t-1} $$\n",
    "\n",
    "Here the model value is a weighted average between the current true value and the previous model values. The $\\alpha$ weight is called a smoothing factor. It defines how quickly we will \"forget\" the last available true observation. The smaller $\\alpha$ is, the more influence the previous observations have and the smoother the series is.\n",
    "\n",
    "Exponentiality is hidden in the recursiveness of the function -- we multiply by $(1-\\alpha)$ each time, which already contains a multiplication by $(1-\\alpha)$ of previous model values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d26a9c",
   "metadata": {},
   "source": [
    "### Function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57341917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_smoothing(series, alpha):\n",
    "    \"\"\"\n",
    "        series - dataset with timestamps\n",
    "        alpha - float [0.0, 1.0], smoothing parameter\n",
    "    \"\"\"\n",
    "    result = [series[0]] # first value is same as series\n",
    "    for n in range(1, len(series)):\n",
    "        result.append(alpha * series[n] + (1 - alpha) * result[n-1])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa26fbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotExponentialSmoothing(series, alphas):\n",
    "    \"\"\"\n",
    "        Plots exponential smoothing with different alphas\n",
    "        \n",
    "        series - dataset with timestamps\n",
    "        alphas - list of floats, smoothing parameters\n",
    "        \n",
    "    \"\"\"\n",
    "    with plt.style.context('seaborn-white'):    \n",
    "        plt.figure(figsize=(15, 7))\n",
    "        for alpha in alphas:\n",
    "            plt.plot(exponential_smoothing(series, alpha), label=\"Alpha {}\".format(alpha))\n",
    "        plt.plot(series.values, \"c\", label = \"Actual\")\n",
    "        plt.legend(loc=\"best\")\n",
    "        plt.axis('tight')\n",
    "        plt.title(\"Exponential Smoothing\")\n",
    "        plt.grid(True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498070e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotExponentialSmoothing(ads.Ads, [0.3, 0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8420ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotExponentialSmoothing(currency.GEMS_GEMS_SPENT, [0.3, 0.05])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190ba71d",
   "metadata": {},
   "source": [
    "## Double exponential smoothing\n",
    "\n",
    "Up to now, the methods that we've discussed have been for a single future point prediction (with some nice smoothing). That is cool, but it is also not enough. Let's extend exponential smoothing so that we can predict two future points (of course, we will also include more smoothing).\n",
    "\n",
    "Series decomposition will help us -- we obtain two components: intercept (i.e. level) $\\ell$ and slope (i.e. trend) $b$. We have learnt to predict intercept (or expected series value) with our previous methods; now, we will apply the same exponential smoothing to the trend by assuming that the future direction of the time series changes depends on the previous weighted changes. As a result, we get the following set of functions:\n",
    "\n",
    "$$\\ell_x = \\alpha y_x + (1-\\alpha)(\\ell_{x-1} + b_{x-1})$$\n",
    "\n",
    "$$b_x = \\beta(\\ell_x - \\ell_{x-1}) + (1-\\beta)b_{x-1}$$\n",
    "\n",
    "$$\\hat{y}_{x+1} = \\ell_x + b_x$$\n",
    "\n",
    "The first one describes the intercept, which, as before, depends on the current value of the series. The second term is now split into previous values of the level and of the trend. The second function describes the trend, which depends on the level changes at the current step and on the previous value of the trend. In this case, the $\\beta$ coefficient is a weight for exponential smoothing. The final prediction is the sum of the model values of the intercept and trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c89648b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_exponential_smoothing(series, alpha, beta):\n",
    "    \"\"\"\n",
    "        series - dataset with timeseries\n",
    "        alpha - float [0.0, 1.0], smoothing parameter for level\n",
    "        beta - float [0.0, 1.0], smoothing parameter for trend\n",
    "    \"\"\"\n",
    "    # first value is same as series\n",
    "    result = [series[0]]\n",
    "    for n in range(1, len(series)+1):\n",
    "        if n == 1:\n",
    "            level, trend = series[0], series[1] - series[0]\n",
    "        if n >= len(series): # forecasting\n",
    "            value = result[-1]\n",
    "        else:\n",
    "            value = series[n]\n",
    "        last_level, level = level, alpha*value + (1-alpha)*(level+trend)\n",
    "        trend = beta*(level-last_level) + (1-beta)*trend\n",
    "        result.append(level+trend)\n",
    "    return result\n",
    "\n",
    "def plotDoubleExponentialSmoothing(series, alphas, betas):\n",
    "    \"\"\"\n",
    "        Plots double exponential smoothing with different alphas and betas\n",
    "        \n",
    "        series - dataset with timestamps\n",
    "        alphas - list of floats, smoothing parameters for level\n",
    "        betas - list of floats, smoothing parameters for trend\n",
    "    \"\"\"\n",
    "    \n",
    "    with plt.style.context('seaborn-white'):    \n",
    "        plt.figure(figsize=(20, 8))\n",
    "        for alpha in alphas:\n",
    "            for beta in betas:\n",
    "                plt.plot(double_exponential_smoothing(series, alpha, beta), label=\"Alpha {}, beta {}\".format(alpha, beta))\n",
    "        plt.plot(series.values, label = \"Actual\")\n",
    "        plt.legend(loc=\"best\")\n",
    "        plt.axis('tight')\n",
    "        plt.title(\"Double Exponential Smoothing\")\n",
    "        plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4fec2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotDoubleExponentialSmoothing(ads.Ads, alphas=[0.9, 0.02], betas=[0.9, 0.02])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45109ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotDoubleExponentialSmoothing(currency.GEMS_GEMS_SPENT, alphas=[0.9, 0.02], betas=[0.9, 0.02])"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
