{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47ffb92e",
   "metadata": {},
   "source": [
    "# OD Backup controller\n",
    "This should develop into the controller run a backup automatically.  Using CDXPBUrner for drive control.\n",
    "\n",
    "- Aim read drive and convert to a stack of disks eg DVD\n",
    "- Want to verify quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a15e787",
   "metadata": {},
   "source": [
    "## CDBurnerXP Driver Controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db96bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from od_media import ODMedia\n",
    "\n",
    "media = ODMedia()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1e6293",
   "metadata": {},
   "source": [
    "## Robot controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a80fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import od_control\n",
    "\n",
    "robot = od_control.ODRobot(media.disk_open, media.disk_close, com_port=\"COM6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbaf7ab",
   "metadata": {},
   "source": [
    "## DVD  control and burning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dc4877",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from odarchive import Archiver, load_archiver_from_json\n",
    "#from h3timeit import h3_timeit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e3922a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ODStatus:\n",
    "    \"\"\"Reads the status of the optical disk in the drive.\n",
    "    Initialisation reads all the state information and then you can use the data as necessary\"\"\"\n",
    "    def __init__(self, media):\n",
    "        # Parse media information\n",
    "        self.number_of_drives = media.number_of_drives\n",
    "        # test = media.disk_type()\n",
    "        #test = \"Todo\"\n",
    "        #if test == '\\rThere was an error obtaining disc info!\\r\\n':\n",
    "        #    self.disk_loaded = False\n",
    "        #else:\n",
    "        #    self.disk_loaded = True\n",
    "        #    \"\"\"Parses disk type into a json object\"\"\"\n",
    "        #    lines = test.split('\\n')\n",
    "        #    print(lines)\n",
    "        #    description=lines[0].split(',')  # First line\n",
    "        #    self.media_type = description[0]\n",
    "        #    self.free_space = int(description[2].strip().split(' ')[0]) * 2048\n",
    "        #    self.capacity = int(lines[3].strip().split(':')[1].strip()) * 2048\n",
    "        #    self.disk_is_blank = self.free_space == self.capacity and self.free_space != 0\n",
    "\n",
    "    def __str__(self):\n",
    "        result = f\"Number of drives = {self.number_of_drives}\\n\"\n",
    "        #if self.disk_loaded:\n",
    "        #    result += f\"Disk Loaded\\n\"\n",
    "        #    result += f\"Size = {self.capacity}\\n\"\n",
    "        #    result += f\"Free space = {self.free_space}\\n\"\n",
    "        #    if self.disk_is_blank:\n",
    "        #        result += f\"Blank disk\\n\"\n",
    "         ##   else:\n",
    "         #       #result += f\"{self.readme}\\n\"\n",
    "         #       result += f\"Media type = {self.media_type}\\n\"\n",
    "\n",
    "        #else:\n",
    "        #    result += f\"No Disk Loaded\\n\"\n",
    "        return result\n",
    "\n",
    "    def _readme(self):\n",
    "        # Assume disk loaded\n",
    "        # look for readme.markdown and then print\n",
    "        with open(\"d:/readme.markdown\",\"r\") as f:\n",
    "            content = f.readlines()\n",
    "        return content\n",
    "\n",
    "\n",
    "a = ODStatus(media)\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13a130f",
   "metadata": {},
   "source": [
    "## Sort disks into blank and used\n",
    "This will take n disks and read them.  If blank they will be put in out bin otherwise a waste place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa4a457",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ODError(Exception):\n",
    "    pass\n",
    "\n",
    "for i in range(9):  \n",
    "    # Check if drive empty\n",
    "    a = ODStatus(media)\n",
    "    if not a.disk_loaded:\n",
    "        robot.load()\n",
    "        a = ODStatus(media)\n",
    "        print(a)\n",
    "    if not a.disk_loaded:\n",
    "        raise ODError(f'On cycle {i} not disk was loaded and it should have been')\n",
    "    if a.disk_is_blank:\n",
    "        print(f'Disk {i} is blank')\n",
    "        robot.unload()\n",
    "    else:\n",
    "        print(f'Disk {i} has data')\n",
    "        robot.unload(destination_bin='waste')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa3634d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# refill in bin\n",
    "for i in range(9):  \n",
    "    robot.unload(source_bin='out', destination_bin='in')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd35006",
   "metadata": {},
   "source": [
    "# A Job\n",
    "- Get a list of dirs (ca 5GB)  (first time will be just two dirs as want to improve disc identification)\n",
    "- Create and archive\n",
    "- create and burn iso's\n",
    "\n",
    "TODO use pyarchive as module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d47872",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "root_path = r'Z:\\Home Pictures'\n",
    "number_start = re.compile('^\\d\\d\\d\\d')\n",
    "\n",
    "def getFolderSize(start_path = '.'):\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(start_path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            total_size += os.path.getsize(fp)\n",
    "    return total_size\n",
    "\n",
    "size_sum = 0\n",
    "results = []\n",
    "with os.scandir(root_path) as it:\n",
    "    for entry in it:\n",
    "        if not entry.is_file():\n",
    "            if number_start.search(entry.name):\n",
    "                print(entry.path)\n",
    "                folder_size = getFolderSize(entry.path) \n",
    "                size_sum += folder_size\n",
    "                results.append([entry.path, folder_size, size_sum])\n",
    "print(results)\n",
    "for i,list in enumerate(results):\n",
    "    if list[2] > 1.5*1E9:\n",
    "        print(i, list)\n",
    "        break\n",
    "# Get the list of directories\n",
    "target_dirs = [d[0] for d in results[:i]]\n",
    "print(target_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c49311f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This should make for easier debugging\n",
    "It creates a single archive and prints out the information for it.\n",
    "On the Z drive\n",
    "timeit started 2018-06-18 11:15:25.988937\n",
    "Initializing file database\n",
    "Number of files = 40,954\n",
    "Data size       = 228,605,334,662\n",
    "Is segmented    = False\n",
    "Number of dirs  = 1458\n",
    "Max dir depth   = 11 (on source file system)\n",
    " Dir =: Z:\\Home Pictures\\H3 to Sort\\2012-06-29\\ManualArchive\\Apalone\\Quotes\\healthMan\\awstats\\awstats\\icon\\flags\n",
    "\n",
    "'test_scan_Z_drive'  436541.60 ms\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def test_create_job():\n",
    "    # Archive part\n",
    "    ar = Archiver()\n",
    "    ar.create_file_database(Path(\"Z:\\\\Home Pictures\\\\2000\"))\n",
    "    ar.save()\n",
    "    ar.convert_to_hash_database(verbose = True)\n",
    "    ar.hash_db.save()  #  Creates catalogue.json\n",
    "    ar.save()\n",
    "    # ar = load_archiver_from_json()  only once catalogue.json has been crate\n",
    "    ar.segment(\"cd\")\n",
    "    ar.save()\n",
    "    ar.hash_db.save()\n",
    "    print(ar.file_db.get_info())\n",
    "\n",
    "def test_create_some_iso():\n",
    "    ar = load_archiver_from_json()  #only once catalogue.json has been crate\n",
    "    print(ar.get_info())\n",
    "    for n in range(ar.last_disc_num):\n",
    "        ar.write_iso(disc_num=n)\n",
    "        filename = f\"new_{n:04}.iso\"\n",
    "        print(f'Written {filename}')\n",
    "\n",
    "def test_burn_some_pictures():\n",
    "    # Check and make sure drive is empty\n",
    "    a = ODStatus(media)\n",
    "    #if a.disk_loaded:\n",
    "    #    print(f'Drive had disk in which is being put into waste bin')\n",
    "    #    robot.unload(destination_bin='waste') \n",
    "    # Archive part\n",
    "    ar = Archiver()\n",
    "    ar.create_file_database(Path(\"Z:\\\\Home Pictures\"))\n",
    "    ar.save()\n",
    "    ar.convert_to_hash_database(verbose = True)\n",
    "    ar.hash_db.save()  #  Creates catalogue.json\n",
    "    ar.save()\n",
    "    # ar = load_archiver_from_json()  only once catalogue.json has been crate\n",
    "    ar.segment(\"bd\")\n",
    "    ar.save()\n",
    "    ar.hash_db.save()\n",
    "    print(ar.file_db.get_info())\n",
    "    for n in range(ar.last_disc_num):\n",
    "        #ar = load_archiver_from_json()\n",
    "        ar.write_iso(disc_num=n)\n",
    "        # TODO make filename part of archiver\n",
    "        filename = f\"new_{n:04}.iso\"\n",
    "        # Load drive and burn disc\n",
    "        robot.load()\n",
    "        media.burn_disk(filename)\n",
    "        #a = ODStatus(media)\n",
    "        robot.unload()\n",
    "        if os.path.isfile(filename):\n",
    "            print(f'File {filename} being deleted after use')\n",
    "            os.remove(filename)\n",
    "        else:\n",
    "            print(f'--- File {filename} missing')\n",
    "        #a = ODStatus(media)\n",
    "        #print(a)\n",
    "        #if a.disk_is_blank:\n",
    "        #    media.burn_disk(filename)\n",
    "        #    robot.unload()\n",
    "        #else:\n",
    "        #    raise ODError(f'Cycle {n} and had non blank disk')        \n",
    "\n",
    "# test_create_job() First part\n",
    "#test_create_some_iso() # second part\n",
    "test_burn_some_pictures() # first second and third parts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f9c688",
   "metadata": {},
   "outputs": [],
   "source": [
    "## If failed but have archive then use this code\n",
    "def test_burn_isos():\n",
    "    # Check and make sure drive is empty\n",
    "    #a = ODStatus(media)\n",
    "    #if a.disk_loaded:\n",
    "    #    print(f'Drive had disk in which is being put into waste bin')\n",
    "    #    robot.unload(destination_bin='waste') \n",
    "    # Archive part\n",
    "    ar = load_archiver_from_json()  # Assume segmented and ready to burn\n",
    "    print(ar.get_info())\n",
    "    for n in (0,): # range(ar.last_disc_num+1):\n",
    "        ar.write_iso(disc_num=n)\n",
    "        # TODO make filename part of archiver\n",
    "        filename = f\"new_{n:04}.iso\"\n",
    "        # Load drive and burn disc\n",
    "        robot.load()\n",
    "        media.burn_disk(filename)\n",
    "        robot.unload()\n",
    "        #if os.path.isfile(filename):\n",
    "        #    print(f'File {filename} being deleted after use')\n",
    "        #    os.remove(filename)\n",
    "        #else:\n",
    "        #    print(f'--- File {filename} missing')\n",
    "        #  #a = ODStatus(media)\n",
    "        #print(a)\n",
    "        #if a.disk_is_blank:\n",
    "        #    media.burn_disk(filename)\n",
    "        #    robot.unload()\n",
    "        #else:\n",
    "        #    raise ODError(f'Cycle {n} and had non blank disk')\n",
    "    # put the drive back\n",
    "#    robot.zero_toolhead()\n",
    "#    robot.rotator.to_bin('od')\n",
    "        \n",
    "test_burn_isos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32f3928",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "robot.load(source_bin='out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ba9625",
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.disk_close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91afc6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reject disk and load new blank\n",
    "robot.unload() #(destination_bin='waste')\n",
    "#robot.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa052e1d",
   "metadata": {},
   "source": [
    "## Temporary playpen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9802a1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.disk_close()\n",
    "a = ODStatus(media)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b7ecd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.disk_open()\n",
    "robot.pickup_from_bin('od')\n",
    "robot.drop_on_bin('in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9677355d",
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.zero_toolhead()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008e5f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.zero_toolhead()\n",
    "robot.rotator.to_bin('od')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
