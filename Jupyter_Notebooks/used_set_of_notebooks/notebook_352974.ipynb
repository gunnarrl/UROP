{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "289eeb35",
   "metadata": {},
   "source": [
    "## Data Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc866693",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "print(os.listdir(\"../input/dataset/dataset\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35776e62",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f8a945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92961be6",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f122ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils import data\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import MultiStepLR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da0a49a",
   "metadata": {},
   "source": [
    "## Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffa9fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot = \"../input/dataset/dataset/\"\n",
    "ckptroot = \"./\"\n",
    "\n",
    "lr = 1e-4\n",
    "weight_decay = 1e-5\n",
    "batch_size = 32\n",
    "num_workers = 8\n",
    "test_size = 0.8\n",
    "shuffle = True\n",
    "\n",
    "epochs = 80\n",
    "start_epoch = 0\n",
    "resume = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1c84ba",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74d3ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toDevice(datas, device):\n",
    "    \"\"\"Enable cuda.\"\"\"\n",
    "    imgs, angles = datas\n",
    "    return imgs.float().to(device), angles.float().to(device)\n",
    "\n",
    "\n",
    "def augment(dataroot, imgName, angle):\n",
    "    \"\"\"Data augmentation.\"\"\"\n",
    "    name = dataroot + 'IMG/' + imgName.split('\\\\')[-1]\n",
    "    current_image = cv2.imread(name)\n",
    "\n",
    "    if current_image is None:\n",
    "        print(name)\n",
    "\n",
    "    current_image = current_image[65:-25, :, :]\n",
    "    if np.random.rand() < 0.5:\n",
    "        current_image = cv2.flip(current_image, 1)\n",
    "        angle = angle * -1.0\n",
    "\n",
    "    return current_image, angle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68099d3b",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221487d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy import signal\n",
    "\n",
    "def load_data(data_dir, test_size):\n",
    "    \"\"\"Load training data and train validation split\"\"\"\n",
    "    # reads CSV file into a single dataframe variable\n",
    "    data_df = pd.read_csv(os.path.join(data_dir, 'driving_log.csv'),\n",
    "                          names=['center', 'left', 'right', 'steering', 'throttle', 'reverse', 'speed'])\n",
    "\n",
    "    # smooth data signal with `savgol_filter`\n",
    "    data_df[\"steering\"] = signal.savgol_filter(data_df[\"steering\"].values.tolist(), 51, 11)\n",
    "\n",
    "    # Divide the data into training set and validation set\n",
    "    train_len = int(test_size * data_df.shape[0])\n",
    "    valid_len = data_df.shape[0] - train_len\n",
    "    trainset, valset = data.random_split(\n",
    "        data_df.values.tolist(), lengths=[train_len, valid_len])\n",
    "\n",
    "    return trainset, valset\n",
    "\n",
    "trainset, valset = load_data(dataroot, test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988152f3",
   "metadata": {},
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de950c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletDataset(data.Dataset):\n",
    "\n",
    "    def __init__(self, dataroot, samples, transform=None):\n",
    "        self.samples = samples\n",
    "        self.dataroot = dataroot\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_samples = self.samples[index]\n",
    "        steering_angle = float(batch_samples[3])\n",
    "\n",
    "        center_img, steering_angle_center = augment(self.dataroot, batch_samples[0], steering_angle)\n",
    "        left_img, steering_angle_left     = augment(self.dataroot, batch_samples[1], steering_angle + 0.4)\n",
    "        right_img, steering_angle_right   = augment(self.dataroot, batch_samples[2], steering_angle - 0.4)\n",
    "\n",
    "        center_img = self.transform(center_img)\n",
    "        left_img   = self.transform(left_img)\n",
    "        right_img  = self.transform(right_img)\n",
    "\n",
    "        return (center_img, steering_angle_center), (left_img, steering_angle_left), (right_img, steering_angle_right)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d700c90a",
   "metadata": {},
   "source": [
    "## Get data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a1679c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"==> Preparing dataset ...\")\n",
    "def data_loader(dataroot, trainset, valset, batch_size, shuffle, num_workers):\n",
    "    \"\"\"Self-Driving vehicles simulator dataset Loader.\n",
    "\n",
    "    Args:\n",
    "        trainset: training set\n",
    "        valset: validation set\n",
    "        batch_size: training set input batch size\n",
    "        shuffle: whether shuffle during training process\n",
    "        num_workers: number of workers in DataLoader\n",
    "\n",
    "    Returns:\n",
    "        trainloader (torch.utils.data.DataLoader): DataLoader for training set\n",
    "        testloader (torch.utils.data.DataLoader): DataLoader for validation set\n",
    "    \"\"\"\n",
    "    transformations = transforms.Compose(\n",
    "        [transforms.Lambda(lambda x: (x / 127.5) - 1.0)])\n",
    "\n",
    "    # Load training data and validation data\n",
    "    training_set = TripletDataset(dataroot, trainset, transformations)\n",
    "    trainloader = DataLoader(training_set,\n",
    "                             batch_size=batch_size,\n",
    "                             shuffle=shuffle,\n",
    "                             num_workers=num_workers)\n",
    "\n",
    "    validation_set = TripletDataset(dataroot, valset, transformations)\n",
    "    valloader = DataLoader(validation_set,\n",
    "                           batch_size=batch_size,\n",
    "                           shuffle=shuffle,\n",
    "                           num_workers=num_workers)\n",
    "\n",
    "    return trainloader, valloader\n",
    "\n",
    "\n",
    "trainloader, validationloader = data_loader(dataroot,\n",
    "                                            trainset, valset,\n",
    "                                            batch_size,\n",
    "                                            shuffle,\n",
    "                                            num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b958ad1",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9e6381",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkNvidia(nn.Module):\n",
    "    \"\"\"NVIDIA model used in the paper.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize NVIDIA model.\n",
    "\n",
    "        NVIDIA model used\n",
    "            Image normalization to avoid saturation and make gradients work better.\n",
    "            Convolution: 5x5, filter: 24, strides: 2x2, activation: ELU\n",
    "            Convolution: 5x5, filter: 36, strides: 2x2, activation: ELU\n",
    "            Convolution: 5x5, filter: 48, strides: 2x2, activation: ELU\n",
    "            Convolution: 3x3, filter: 64, strides: 1x1, activation: ELU\n",
    "            Convolution: 3x3, filter: 64, strides: 1x1, activation: ELU\n",
    "            Drop out (0.5)\n",
    "            Fully connected: neurons: 100, activation: ELU\n",
    "            Fully connected: neurons: 50, activation: ELU\n",
    "            Fully connected: neurons: 10, activation: ELU\n",
    "            Fully connected: neurons: 1 (output)\n",
    "\n",
    "        the convolution layers are meant to handle feature engineering\n",
    "        the fully connected layer for predicting the steering angle.\n",
    "        \"\"\"\n",
    "        super(NetworkNvidia, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 24, 5, stride=2),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(24, 36, 5, stride=2),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(36, 48, 5, stride=2),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(48, 64, 3),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(64, 64, 3),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        self.linear_layers = nn.Sequential(\n",
    "            nn.Linear(in_features=64 * 2 * 33, out_features=100),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(in_features=100, out_features=50),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(in_features=50, out_features=10),\n",
    "            nn.Linear(in_features=10, out_features=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Forward pass.\"\"\"\n",
    "        input = input.view(input.size(0), 3, 70, 320)\n",
    "        output = self.conv_layers(input)\n",
    "        # print(output.shape)\n",
    "        output = output.view(output.size(0), -1)\n",
    "        output = self.linear_layers(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "# Define model\n",
    "print(\"==> Initialize model ...\")\n",
    "model = NetworkNvidia()\n",
    "print(\"==> Initialize model done ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a56757",
   "metadata": {},
   "source": [
    "## Define optimizer and criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802d140d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer and criterion\n",
    "optimizer = optim.Adam(model.parameters(),\n",
    "                       lr=lr,\n",
    "                       weight_decay=weight_decay)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7128a8",
   "metadata": {},
   "source": [
    "## Learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c5ce4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate scheduler\n",
    "scheduler = MultiStepLR(optimizer, milestones=[30, 50], gamma=0.1)\n",
    "\n",
    "# transfer to gpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9349df05",
   "metadata": {},
   "source": [
    "## Resume training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f554b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if resume:\n",
    "    print(\"==> Loading checkpoint ...\")\n",
    "    checkpoint = torch.load(\"../input/pretrainedmodels/both-nvidia-model-61.h5\",\n",
    "                            map_location=lambda storage, loc: storage)\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeda9424",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8918a4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    \"\"\"Trainer.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 ckptroot,\n",
    "                 model,\n",
    "                 device,\n",
    "                 epochs,\n",
    "                 criterion,\n",
    "                 optimizer,\n",
    "                 scheduler,\n",
    "                 start_epoch,\n",
    "                 trainloader,\n",
    "                 validationloader):\n",
    "        \"\"\"Self-Driving car Trainer.\n",
    "\n",
    "        Args:\n",
    "            model:\n",
    "            device:\n",
    "            epochs:\n",
    "            criterion:\n",
    "            optimizer:\n",
    "            start_epoch:\n",
    "            trainloader:\n",
    "            validationloader:\n",
    "\n",
    "        \"\"\"\n",
    "        super(Trainer, self).__init__()\n",
    "\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.epochs = epochs\n",
    "        self.ckptroot = ckptroot\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.start_epoch = start_epoch\n",
    "        self.trainloader = trainloader\n",
    "        self.validationloader = validationloader\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"Training process.\"\"\"\n",
    "        self.model.to(self.device)\n",
    "        for epoch in range(self.start_epoch, self.epochs + self.start_epoch):\n",
    "            self.scheduler.step()\n",
    "            \n",
    "            # Training\n",
    "            train_loss = 0.0\n",
    "            self.model.train()\n",
    "\n",
    "            for local_batch, (centers, lefts, rights) in enumerate(self.trainloader):\n",
    "                # Transfer to GPU\n",
    "                centers, lefts, rights = toDevice(centers, self.device), toDevice(\n",
    "                    lefts, self.device), toDevice(rights, self.device)\n",
    "\n",
    "                # Model computations\n",
    "                self.optimizer.zero_grad()\n",
    "                datas = [centers, lefts, rights]\n",
    "                for data in datas:\n",
    "                    imgs, angles = data\n",
    "                    # print(\"training image: \", imgs.shape)\n",
    "                    outputs = self.model(imgs)\n",
    "                    loss = self.criterion(outputs, angles.unsqueeze(1))\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "\n",
    "                    train_loss += loss.data.item()\n",
    "\n",
    "                if local_batch % 100 == 0:\n",
    "\n",
    "                    print(\"Training Epoch: {} | Loss: {}\".format(epoch, train_loss / (local_batch + 1)))\n",
    "\n",
    "            # Validation\n",
    "            self.model.eval()\n",
    "            valid_loss = 0\n",
    "            with torch.set_grad_enabled(False):\n",
    "                for local_batch, (centers, lefts, rights) in enumerate(self.validationloader):\n",
    "                    # Transfer to GPU\n",
    "                    centers, lefts, rights = toDevice(centers, self.device), toDevice(\n",
    "                        lefts, self.device), toDevice(rights, self.device)\n",
    "\n",
    "                    # Model computations\n",
    "                    self.optimizer.zero_grad()\n",
    "                    datas = [centers, lefts, rights]\n",
    "                    for data in datas:\n",
    "                        imgs, angles = data\n",
    "                        outputs = self.model(imgs)\n",
    "                        loss = self.criterion(outputs, angles.unsqueeze(1))\n",
    "\n",
    "                        valid_loss += loss.data.item()\n",
    "\n",
    "                    if local_batch % 100 == 0:\n",
    "                        print(\"Validation Loss: {}\".format(valid_loss / (local_batch + 1)))\n",
    "\n",
    "            print()\n",
    "            # Save model\n",
    "            if epoch % 5 == 0 or epoch == self.epochs + self.start_epoch - 1:\n",
    "\n",
    "                state = {\n",
    "                    'epoch': epoch + 1,\n",
    "                    'state_dict': self.model.state_dict(),\n",
    "                    'optimizer': self.optimizer.state_dict(),\n",
    "                    'scheduler': self.scheduler.state_dict(),\n",
    "                }\n",
    "\n",
    "                self.save_checkpoint(state)\n",
    "\n",
    "    def save_checkpoint(self, state):\n",
    "        \"\"\"Save checkpoint.\"\"\"\n",
    "        print(\"==> Save checkpoint ...\")\n",
    "        if not os.path.exists(self.ckptroot):\n",
    "            os.makedirs(self.ckptroot)\n",
    "\n",
    "        torch.save(state, self.ckptroot + 'both-nvidia-model-{}.h5'.format(state['epoch']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0026c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"==> Start training ...\")\n",
    "trainer = Trainer(ckptroot,\n",
    "                  model,\n",
    "                  device,\n",
    "                  epochs,\n",
    "                  criterion,\n",
    "                  optimizer,\n",
    "                  scheduler,\n",
    "                  start_epoch,\n",
    "                  trainloader,\n",
    "                  validationloader)\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
