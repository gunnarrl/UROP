{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "414749ce",
   "metadata": {},
   "source": [
    "Deep Learning Models -- A collection of various deep learning architectures, models, and tips for TensorFlow and PyTorch in Jupyter Notebooks.\n",
    "- Author: Sebastian Raschka\n",
    "- GitHub Repository: https://github.com/rasbt/deeplearning-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84eb11ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a 'Sebastian Raschka' -v -p torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13897631",
   "metadata": {},
   "source": [
    "- Runs on CPU or GPU (if available)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df0fe55",
   "metadata": {},
   "source": [
    "# Basic Graph Neural Network with Spectral Graph Convolution on MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121c5cb1",
   "metadata": {},
   "source": [
    "Implementing a very basic graph neural network (GNN) using a spectral graph convolution. \n",
    "\n",
    "Here, the 28x28 image of a digit in MNIST represents the graph, where each pixel (i.e., cell in the grid) represents a particular node. The feature of that node is simply the pixel intensity in range [0, 1]. \n",
    "\n",
    "Here, the adjacency matrix of the pixels is basically just determined by their neighborhood pixels. Using a Gaussian filter, we connect pixels based on their Euclidean distance in the grid.\n",
    "\n",
    "In the related notebook, [./gnn-basic-1.ipynb](./gnn-basic-1.ipynb), we used this adjacency matrix $A$ to compute the output of a layer as \n",
    "\n",
    "$$X^{(l+1)}=A X^{(l)} W^{(l)}.$$\n",
    "\n",
    "Here, $A$ is the $N \\times N$ adjacency matrix, and $X$ is the $N \\times C$ feature matrix (a  2D coordinate array, where $N$ is the total number of pixels -- $28 \\times 28 = 784$ in MNIST). $W$ is the weight matrix of shape $N \\times P$, where $P$ would represent the number of classes if we have only a single hidden layer.\n",
    "\n",
    "In this notebook, we modify this code using spectral graph convolution, i.e.,\n",
    "\n",
    "$$X^{(l+1)}=V\\left(V^{T} X^{(l)} \\odot V^{T} W_{\\text {spectral }}^{(l)}\\right).$$\n",
    "\n",
    "Where $V$ are the eigenvectors of the graph Laplacian $L$, which we can compute from the adjacency matrix $A$. Here, $W_{\\text {spectral }}$ represents the trainable weights (filters).\n",
    "\n",
    "- Inspired by and based on Boris Knyazev's tutorial at https://towardsdatascience.com/tutorial-on-graph-neural-networks-for-computer-vision-and-beyond-part-2-be6d71d70f49."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14ce739",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cb48b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Subset\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13ebd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c27e2d",
   "metadata": {},
   "source": [
    "## Settings and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5534990b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### SETTINGS\n",
    "##########################\n",
    "\n",
    "# Device\n",
    "DEVICE = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Hyperparameters\n",
    "RANDOM_SEED = 1\n",
    "LEARNING_RATE = 0.05\n",
    "NUM_EPOCHS = 50\n",
    "BATCH_SIZE = 128\n",
    "IMG_SIZE = 28\n",
    "\n",
    "# Architecture\n",
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b5d006",
   "metadata": {},
   "source": [
    "## MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2415f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = torch.arange(0, 59000)\n",
    "valid_indices = torch.arange(59000, 60000)\n",
    "\n",
    "custom_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "\n",
    "train_and_valid = datasets.MNIST(root='data', \n",
    "                                 train=True, \n",
    "                                 transform=custom_transform,\n",
    "                                 download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='data', \n",
    "                              train=False, \n",
    "                              transform=custom_transform,\n",
    "                              download=True)\n",
    "\n",
    "train_dataset = Subset(train_and_valid, train_indices)\n",
    "valid_dataset = Subset(train_and_valid, valid_indices)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          num_workers=4,\n",
    "                          shuffle=True)\n",
    "\n",
    "valid_loader = DataLoader(dataset=valid_dataset, \n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          num_workers=4,\n",
    "                          shuffle=False)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         num_workers=4,\n",
    "                         shuffle=False)\n",
    "\n",
    "# Checking the dataset\n",
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6754f4",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78736e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precompute_adjacency_matrix(img_size):\n",
    "    col, row = np.meshgrid(np.arange(img_size), np.arange(img_size))\n",
    "    \n",
    "    # N = img_size^2\n",
    "    # construct 2D coordinate array (shape N x 2) and normalize\n",
    "    # in range [0, 1]\n",
    "    coord = np.stack((col, row), axis=2).reshape(-1, 2) / img_size\n",
    "\n",
    "    # compute pairwise distance matrix (N x N)\n",
    "    dist = cdist(coord, coord, metric='euclidean')\n",
    "    \n",
    "    # Apply Gaussian filter\n",
    "    sigma = 0.05 * np.pi\n",
    "    A = np.exp(- dist / sigma ** 2)\n",
    "    A[A < 0.01] = 0\n",
    "    A = torch.from_numpy(A).float()\n",
    "    \n",
    "    return A\n",
    "\n",
    "    \"\"\"\n",
    "    # Normalization as per (Kipf & Welling, ICLR 2017)\n",
    "    D = A.sum(1)  # nodes degree (N,)\n",
    "    D_hat = (D + 1e-5) ** (-0.5)\n",
    "    A_hat = D_hat.view(-1, 1) * A * D_hat.view(1, -1)  # N,N\n",
    "    \n",
    "    return A_hat\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "def get_graph_laplacian(A):\n",
    "    # From https://towardsdatascience.com/spectral-graph-convolution-\n",
    "    #   explained-and-implemented-step-by-step-2e495b57f801\n",
    "    #\n",
    "    # Computing the graph Laplacian\n",
    "    # A is an adjacency matrix of some graph G\n",
    "    N = A.shape[0] # number of nodes in a graph\n",
    "    D = np.sum(A, 0) # node degrees\n",
    "    D_hat = np.diag((D + 1e-5)**(-0.5)) # normalized node degrees\n",
    "    L = np.identity(N) - np.dot(D_hat, A).dot(D_hat) # Laplacian\n",
    "    return torch.from_numpy(L).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2197b89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = precompute_adjacency_matrix(28)\n",
    "plt.imshow(A, vmin=0., vmax=1.)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ee36a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = get_graph_laplacian(A.numpy())\n",
    "plt.imshow(L, vmin=0., vmax=1.)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e7dc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### MODEL\n",
    "##########################\n",
    "\n",
    "from scipy.sparse.linalg import eigsh\n",
    "        \n",
    "\n",
    "class GraphNet(nn.Module):\n",
    "    def __init__(self, img_size=28, num_filters=2, num_classes=10):\n",
    "        super(GraphNet, self).__init__()\n",
    "        \n",
    "        n_rows = img_size**2\n",
    "        self.fc = nn.Linear(n_rows*num_filters, num_classes, bias=False)\n",
    "\n",
    "        A = precompute_adjacency_matrix(img_size)\n",
    "        L = get_graph_laplacian(A.numpy())\n",
    "        Λ,V = eigsh(L.numpy(), k=20, which='SM') # eigen-decomposition (i.e. find Λ,V)\n",
    "\n",
    "        V = torch.from_numpy(V)\n",
    "        \n",
    "        # Weight matrix\n",
    "        W_spectral = nn.Parameter(torch.ones((img_size**2, num_filters))).float()\n",
    "        torch.nn.init.kaiming_uniform_(W_spectral)\n",
    "        \n",
    "        self.register_buffer('A', A)\n",
    "        self.register_buffer('L', L)\n",
    "        self.register_buffer('V', V)\n",
    "        self.register_buffer('W_spectral', W_spectral)\n",
    "\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        B = x.size(0) # Batch size\n",
    "\n",
    "        ### Reshape eigenvectors\n",
    "        # from [H*W, 20] to [B, H*W, 20]\n",
    "        V_tensor = self.V.unsqueeze(0)\n",
    "        V_tensor = self.V.expand(B, -1, -1)\n",
    "        # from [H*W, 20] to [B, 20, H*W]\n",
    "        V_tensor_T = self.V.T.unsqueeze(0)\n",
    "        V_tensor_T = self.V.T.expand(B, -1, -1)\n",
    "        \n",
    "        ### Reshape inputs\n",
    "        # [B, C, H, W] => [B, H*W, 1]\n",
    "        x_reshape = x.view(B, -1, 1)\n",
    "        \n",
    "        ### Reshape spectral weights\n",
    "        # to size [128, H*W, F]\n",
    "        W_spectral_tensor = self.W_spectral.unsqueeze(0)\n",
    "        W_spectral_tensor = self.W_spectral.expand(B, -1, -1)\n",
    "        \n",
    "        ### Spectral convolution on graphs\n",
    "        # [B, 20, H*W] . [B, H*W, 1]  ==> [B, 20, 1]\n",
    "        X_hat = V_tensor_T.bmm(x_reshape) # 20×1 node features in the \"spectral\" domain\n",
    "        W_hat = V_tensor_T.bmm(W_spectral_tensor)  # 20×F filters in the \"spectral\" domain\n",
    "        Y = V_tensor.bmm(X_hat * W_hat)  # N×F result of convolution\n",
    "\n",
    "        ### Fully connected\n",
    "        logits = self.fc(Y.reshape(B, -1))\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "        return logits, probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdaf43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "model = GraphNet(img_size=IMG_SIZE, num_classes=NUM_CLASSES)\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a1e7f9",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd48e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_acc(model, data_loader, device):\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    for features, targets in data_loader:\n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "        logits, probas = model(features)\n",
    "        _, predicted_labels = torch.max(probas, 1)\n",
    "        num_examples += targets.size(0)\n",
    "        correct_pred += (predicted_labels == targets).sum()\n",
    "    return correct_pred.float()/num_examples * 100\n",
    "    \n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "cost_list = []\n",
    "train_acc_list, valid_acc_list = [], []\n",
    "\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    model.train()\n",
    "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "        \n",
    "        features = features.to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "            \n",
    "        ### FORWARD AND BACK PROP\n",
    "        logits, probas = model(features)\n",
    "        cost = F.cross_entropy(logits, targets)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        cost.backward()\n",
    "        \n",
    "        ### UPDATE MODEL PARAMETERS\n",
    "        optimizer.step()\n",
    "        \n",
    "        #################################################\n",
    "        ### CODE ONLY FOR LOGGING BEYOND THIS POINT\n",
    "        ################################################\n",
    "        cost_list.append(cost.item())\n",
    "        if not batch_idx % 150:\n",
    "            print (f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} | '\n",
    "                   f'Batch {batch_idx:03d}/{len(train_loader):03d} |' \n",
    "                   f' Cost: {cost:.4f}')\n",
    "\n",
    "        \n",
    "\n",
    "    model.eval()\n",
    "    with torch.set_grad_enabled(False): # save memory during inference\n",
    "        \n",
    "        train_acc = compute_acc(model, train_loader, device=DEVICE)\n",
    "        valid_acc = compute_acc(model, valid_loader, device=DEVICE)\n",
    "        \n",
    "        print(f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d}\\n'\n",
    "              f'Train ACC: {train_acc:.2f} | Validation ACC: {valid_acc:.2f}')\n",
    "        \n",
    "        train_acc_list.append(train_acc)\n",
    "        valid_acc_list.append(valid_acc)\n",
    "        \n",
    "    elapsed = (time.time() - start_time)/60\n",
    "    print(f'Time elapsed: {elapsed:.2f} min')\n",
    "  \n",
    "elapsed = (time.time() - start_time)/60\n",
    "print(f'Total Training Time: {elapsed:.2f} min')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46761fa",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e829baaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cost_list, label='Minibatch cost')\n",
    "plt.plot(np.convolve(cost_list, \n",
    "                     np.ones(200,)/200, mode='valid'), \n",
    "         label='Running average')\n",
    "\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.xlabel('Iteration')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338b5540",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1, NUM_EPOCHS+1), train_acc_list, label='Training')\n",
    "plt.plot(np.arange(1, NUM_EPOCHS+1), valid_acc_list, label='Validation')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60aae981",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.set_grad_enabled(False):\n",
    "    test_acc = compute_acc(model=model,\n",
    "                           data_loader=test_loader,\n",
    "                           device=DEVICE)\n",
    "    \n",
    "    valid_acc = compute_acc(model=model,\n",
    "                            data_loader=valid_loader,\n",
    "                            device=DEVICE)\n",
    "    \n",
    "\n",
    "print(f'Validation ACC: {valid_acc:.2f}%')\n",
    "print(f'Test ACC: {test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908de75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%watermark -iv"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
