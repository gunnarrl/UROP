{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a36fb096",
   "metadata": {},
   "source": [
    "<!--BOOK_INFORMATION-->\n",
    "<a href=\"https://www.packtpub.com/big-data-and-business-intelligence/machine-learning-opencv\" target=\"_blank\"><img align=\"left\" src=\"data/cover.jpg\" style=\"width: 76px; height: 100px; background: white; padding: 1px; border: 1px solid black; margin-right:10px;\"></a>\n",
    "*This notebook contains an excerpt from the book [Machine Learning for OpenCV](https://www.packtpub.com/big-data-and-business-intelligence/machine-learning-opencv) by Michael Beyeler.\n",
    "The code is released under the [MIT license](https://opensource.org/licenses/MIT),\n",
    "and is available on [GitHub](https://github.com/mbeyeler/opencv-machine-learning).*\n",
    "\n",
    "*Note that this excerpt contains only the raw code - the book is rich with additional explanations and illustrations.\n",
    "If you find this content useful, please consider supporting the work by\n",
    "[buying the book](https://www.packtpub.com/big-data-and-business-intelligence/machine-learning-opencv)!*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6091442",
   "metadata": {},
   "source": [
    "<!--NAVIGATION-->\n",
    "< [9. Using Deep Learning to Classify Handwritten Digits](09.00-Using-Deep-Learning-to-Classify-Handwritten-Digits.ipynb) | [Contents](../README.md) | [Implementing a Multi-Layer Perceptron (MLP) in OpenCV](09.02-Implementing-a-Multi-Layer-Perceptron-in-OpenCV.ipynb) >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c69463",
   "metadata": {},
   "source": [
    "# Understanding Perceptrons\n",
    "\n",
    "In the 1950s, American psychologist and artificial intelligence researcher Frank Rosenblatt invented an algorithm that would automatically learn the optimal weight coefficients $w_0$ and $w_1$ needed to perform an accurate binary classification: the perceptron learning rule.\n",
    "\n",
    "Rosenblatt's original perceptron algorithm can be summed up as follows:\n",
    "\n",
    "1. Initialize the weights to zero or some small random numbers.\n",
    "2. For each training sample $s_i$, perform the following steps:\n",
    "   1. Compute the predicted target value $ŷ_i$.\n",
    "   2. Compare $ŷ_i$ to the ground truth $y_i$, and update the weights accordingly:\n",
    "      - If the two are the same (correct prediction), skip ahead.\n",
    "      - If the two are different (wrong prediction), push the weight coefficients $w_0$ and $w_1$ towards the positive or negative target class respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b6b71a",
   "metadata": {},
   "source": [
    "## Implemeting our first perceptron\n",
    "\n",
    "Perceptrons are easy enough to be implemented from scratch. We can mimic the typical OpenCV or scikit-learn implementation of a classifier by creating a `Perceptron` object. This will allow us to initialize new perceptron objects that can learn from data via a `fit` method and make predictions via a separate `predict` method.\n",
    "\n",
    "When we initialize a new perceptron object, we want to pass a learning rate (`lr`) and the number of iterations after which the algorithm should terminate (`n_iter`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81d7831",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class Perceptron(object):\n",
    "\n",
    "    def __init__(self, lr=0.01, n_iter=10):\n",
    "        \"\"\"Constructor\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        lr : float\n",
    "            Learning rate.\n",
    "        n_iter : int\n",
    "            Number of iterations after which the algorithm should\n",
    "            terminate.\n",
    "        \"\"\"\n",
    "        self.lr = lr\n",
    "        self.n_iter = n_iter\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict target labels\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like\n",
    "            Feature matrix, <n_samples x n_features>\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        Predicted target labels, +1 or -1.\n",
    "        \n",
    "        Notes\n",
    "        -----\n",
    "        Must run `fit` first.\n",
    "        \"\"\"\n",
    "        # Whenever the term (X * weights + bias) >= 0, we return\n",
    "        # label +1, else we return label -1\n",
    "        return np.where(np.dot(X, self.weights) + self.bias >= 0.0,\n",
    "                        1, -1)\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit the model to data\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like\n",
    "            Feature matrix, <n_samples x n_features>\n",
    "        y : array-like\n",
    "            Vector of target labels, <n_samples x 1>\n",
    "        \"\"\"\n",
    "        self.weights = np.zeros(X.shape[1])\n",
    "        self.bias = 0.0\n",
    "        for _ in range(self.n_iter):\n",
    "            for xi, yi in zip(X, y):\n",
    "                delta = self.lr * (yi - self.predict(xi))\n",
    "                self.weights += delta * xi\n",
    "                self.bias += delta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd06bdd",
   "metadata": {},
   "source": [
    "## Generating a toy dataset\n",
    "\n",
    "To test our perceptron classifier, we need to create some mock data. Let's keep things simple for now and generate 100 data samples (`n_samples`) belonging to one of two blobs (`center`s), again relying on scikit-learn's `make_blobs` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170f4082",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "X, y = make_blobs(n_samples=100, centers=2,\n",
    "                  cluster_std=2.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d010be6f",
   "metadata": {},
   "source": [
    "Adjust the labels so they're either +1 or -1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e0b50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 2 * y - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ddaa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X[:, 0], X[:, 1], s=100, c=y);\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.savefig('perceptron-data.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f9b14d",
   "metadata": {},
   "source": [
    "## Fitting the perceptron to data\n",
    "\n",
    "We can instantiate our perceptron object similar to other classifiers we encountered with\n",
    "OpenCV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf2523f",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Perceptron(lr=0.1, n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7596206b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccb69b9",
   "metadata": {},
   "source": [
    "Let's have a look at the learned weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4818552d",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c37e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133ddcbb",
   "metadata": {},
   "source": [
    "If we plug these values into our equation for $ϕ$, it becomes clear that the perceptron learned\n",
    "a decision boundary of the form $2.2 x_1 - 0.48 x_2 + 0.2 >= 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43d313b",
   "metadata": {},
   "source": [
    "## Evaluating the perceptron classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4480f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(p.predict(X), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddf4992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(classifier, X_test, y_test):\n",
    "    # create a mesh to plot in\n",
    "    h = 0.02  # step size in mesh\n",
    "    x_min, x_max = X_test[:, 0].min() - 1, X_test[:, 0].max() + 1\n",
    "    y_min, y_max = X_test[:, 1].min() - 1, X_test[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    \n",
    "    X_hypo = np.c_[xx.ravel().astype(np.float32),\n",
    "                   yy.ravel().astype(np.float32)]\n",
    "    zz = classifier.predict(X_hypo)\n",
    "    zz = zz.reshape(xx.shape)\n",
    "    \n",
    "    plt.contourf(xx, yy, zz, cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "    plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, s=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd9acfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plot_decision_boundary(p, X, y)\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f973f17",
   "metadata": {},
   "source": [
    "## Applying the perceptron to data that is not linearly separable\n",
    "\n",
    "Since the perceptron is a linear classifier, you can imagine that it would have trouble trying\n",
    "to classify data that is not linearly separable. We can test this by increasing the spread\n",
    "(`cluster_std`) of the two blobs in our toy dataset so that the two blobs start overlapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67410b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_blobs(n_samples=100, centers=2,\n",
    "                  cluster_std=5.2, random_state=42)\n",
    "y = 2 * y - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77ad2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X[:, 0], X[:, 1], s=100, c=y);\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c23bea",
   "metadata": {},
   "source": [
    "So what would happen if we applied the perceptron classifier to this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342671a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Perceptron(lr=0.1, n_iter=10)\n",
    "p.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653b6001",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(p.predict(X), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8a042f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plot_decision_boundary(p, X, y)\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405f40a2",
   "metadata": {},
   "source": [
    "Fortunately, there are ways to make the perceptron more powerful and ultimately create\n",
    "nonlinear decision boundaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7aed8a",
   "metadata": {},
   "source": [
    "<!--NAVIGATION-->\n",
    "< [9. Using Deep Learning to Classify Handwritten Digits](09.00-Using-Deep-Learning-to-Classify-Handwritten-Digits.ipynb) | [Contents](../README.md) | [Implementing a Multi-Layer Perceptron (MLP) in OpenCV](09.02-Implementing-a-Multi-Layer-Perceptron-in-OpenCV.ipynb) >"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
