{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72ffbb13",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis for Crimes in Chicago in 2018\n",
    "\n",
    "\n",
    "\n",
    "## Copy from s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b600bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "bucket = \"sagemaker-chicago-data\"\n",
    "key = \"Crimes_-_2018.csv\"\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "s3.Bucket(bucket).download_file(key, \"crimes_2018.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ee4eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Data/crimes_2018.csv\", index_col = \"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b535347",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365ed924",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cea067",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Primary Type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494a865e",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Based on a few simple lines of code, we can conclude the following. From January through September of 2018, there were over 180,000 criminal events in Chicago. Specifically they can be broken down as following\n",
    "- 122 kidnappings\n",
    "- 1,054 sexual assaults\n",
    "- 396 homicides\n",
    "- 6,823 motor vehicle thefts\n",
    "- 3,815 weapons violations\n",
    "- 34,903 cases of battery\n",
    "- 44,086 cases of theft\n",
    "    \n",
    "Each crime is recorded with 22 columns, described as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db823c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_row_headers(df):\n",
    "    for h in list(df):\n",
    "        print (h)\n",
    "print_row_headers(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae75087",
   "metadata": {},
   "source": [
    "## For a criminal prediction project, we will only consider this data set the \"Y\", or the target variable.\n",
    "\n",
    "That means we only need to keep records indicating that this crime occured. Let's drop everything else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbdfc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_list = [\"Case Number\", \"Date\", \"Block\", \"Primary Type\", \"Description\", \"Location Description\", \"Arrest\", \"Year\", \"Location\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bca4bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df = df[keep_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1450124",
   "metadata": {},
   "source": [
    "## Now let's remove the rows with missing values on those reduced columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9e9e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for h in list(reduced_df):\n",
    "    print (h)\n",
    "    print (df[h].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846d9ab0",
   "metadata": {},
   "source": [
    "It appears that we have 426 rows missing a location description, and 935 rows missing a location. Before we drop them, we need to make sure they are not correlated with our outcome variables, ie crime. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d71af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_location = df.loc[ df[\"Location Description\"].isna() > 0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823e99c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7c544c",
   "metadata": {},
   "source": [
    "Most of the rows missing the location description appear to be about finacial crimes, ie financial identity theft. This indicates that if we want to build a prediction model for financial crimes, we would not be able to use the location description, becaause it is closely correlated with the outcome variable. Dropping it would introduce sample bias into our model.\n",
    "\n",
    "For this demonstration we are only going to model the following criminal activities:\n",
    "- Kidnapping\n",
    "- Sexual Assault\n",
    "- Homocide\n",
    "- Moto Vehicle Theft\n",
    "- Weapons Violations\n",
    "- Battery\n",
    "- Theft\n",
    "\n",
    "Because Location Description is not correlated with any of these columns, we are good to drop the 496 rows that are missing Location Description. This will allow us to utilize the rest of the information contained in the Location Description column, without introducing bias into our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da72323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df = df[ (df[\"Location Description\"]).isna() == False ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae3b11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If this returns a 0, then our row removal step was successful\n",
    "df[\"Location Description\"].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5a3a89",
   "metadata": {},
   "source": [
    "Moving on to the location column. Effectively we have 935 rows that are missing locations, and we need to decide if we will simply drop them. In order to make that decision, we need to know if they are correlated with the outcome variable, crime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24da20fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_geo = df.loc[ df[\"Location\"].isna() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9c6723",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_geo[\"Primary Type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05aa7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_geo[\"Description\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fd9d2a",
   "metadata": {},
   "source": [
    "It appears that most of our 900 + rows with missing values for location are about theft under $500. That also happens to be our largest prediction category, with almost 17,000 records in that category. Given this magnitude, I am not concerned about introducing downward bias into the model against petty theft. We'll drop those rows as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ecf26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Description\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01bc22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[ (df[\"Location\"]).isna() == False ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43da8dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If this returns a 0, our removal was successful\n",
    "df[\"Location\"].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117db1a8",
   "metadata": {},
   "source": [
    "# Great! We've reduced our data set and removed the empty rows, let's write that to a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88438aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../Data/crimes_2018_reduced.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93e9ede",
   "metadata": {},
   "source": [
    "Another very helpful step is wrapping all of these steps as a single Python function, so we can more easily use it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78eb6e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(f_name):\n",
    "    \n",
    "    df = pd.read_csv(f_name, index_col = \"ID\")\n",
    "    \n",
    "    # keep a subset of columns\n",
    "    keep_list = [\"Case Number\", \"Date\", \"Block\", \"Primary Type\", \"Description\", \"Location Description\", \"Arrest\", \"Year\", \"Location\"]\n",
    "    reduced_df = df[keep_list]\n",
    "\n",
    "    # drop rows that are missing Location Description\n",
    "    df = df[ (df[\"Location Description\"]).isna() == False ]\n",
    "    \n",
    "    # drop rows that are missing Location, geo coordinates\n",
    "    df = df[ (df[\"Location\"]).isna() == False ]\n",
    "    \n",
    "    # write to disk\n",
    "    df.to_csv(\"../Data/crimes_2018_reduced.csv\")\n",
    "\n",
    "main(\"../Data/crimes_2018.csv\")   "
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
