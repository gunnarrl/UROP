{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4592af74",
   "metadata": {},
   "source": [
    "# Digit Recognizer \n",
    "A fast.ai implementation for the MNIST Digit Recognizer competition on kaggle. https://www.kaggle.com/c/digit-recognizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21157895",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.metrics import accuracy,error_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f342b3",
   "metadata": {},
   "source": [
    "Below is a custom `ImageItemList` that allows us to load the kaggle datasets. Essentially, the images are stored as a label plus a pixel array wrapped up in a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5b5e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in newer versions of fastai this is just called ImageList now\n",
    "class CustomImageItemList(ImageItemList):\n",
    "    def open(self, fn):\n",
    "        img = fn.reshape(28,28)\n",
    "        img = np.stack((img,)*3, axis=-1) # convert to 3 channels\n",
    "        return Image(pil2tensor(img, dtype=np.float32))\n",
    "\n",
    "    @classmethod\n",
    "    def from_csv_custom(cls, path:PathOrStr, csv_name:str, imgIdx:int=1, header:str='infer', **kwargs)->'ItemList':\n",
    "        df = pd.read_csv(Path(path)/csv_name, header=header)\n",
    "        res = super().from_df(df, path=path, cols=0, **kwargs)\n",
    "        # convert pixels to an ndarray\n",
    "        res.items = df.iloc[:,imgIdx:].apply(lambda x: x.values / 255.0, axis=1).values\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935aaaf2",
   "metadata": {},
   "source": [
    "## Training\n",
    "found something somewhere that caused me to set `num_workers` equal to zero. Was getting an error and at the end of the day it seems it was pytorch/windows thing and that was the work around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3f2a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: there are no labels in a test set, so we set the imgIdx to begin at the 0 col\n",
    "test = CustomImageItemList.from_csv_custom(path='./data', csv_name='test.csv', imgIdx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321e4d3a",
   "metadata": {},
   "source": [
    "todo: need to look into how I'm generating transforms for data augmentation - for some reason transforms are hurting performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fdb674",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = get_transforms(do_flip=False)\n",
    "data = (CustomImageItemList.from_csv_custom(path='./data', csv_name='train.csv')\n",
    "                           .random_split_by_pct(.2)\n",
    "                           .label_from_df(cols='label')\n",
    "                           .add_test(test, label=0)\n",
    "                           .transform(tfms)\n",
    "                           .databunch(bs=64, num_workers=0)\n",
    "                           .normalize(imagenet_stats))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bf52bc",
   "metadata": {},
   "source": [
    "## Resnet34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a067022a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_cnn(data, arch=models.resnet34, metrics=[accuracy,error_rate])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34467d3f",
   "metadata": {},
   "source": [
    "**Stage 1:** basic model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563856cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bbb325",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-2\n",
    "learn.fit_one_cycle(8, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e327ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('resnet34-stage-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ef6789",
   "metadata": {},
   "source": [
    "**Stage 2:** unfreezing the entire model to try and tweak things to squeeze out just a bit of extra performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b04da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('resnet34-stage-1')\n",
    "learn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c586ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e16938c",
   "metadata": {},
   "source": [
    "## Resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dadd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_cnn(data, arch=models.resnet50, metrics=[accuracy,error_rate])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e424981e",
   "metadata": {},
   "source": [
    "**Stage 1:** basic model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523b9da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3ad99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-2\n",
    "learn.fit_one_cycle(8, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73951c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('resnet50-stage-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2888891c",
   "metadata": {},
   "source": [
    "**Stage 2:** unfreezing the entire model to try and tweak things to squeeze out just a bit of extra performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddd52ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('stage1-resnet50')\n",
    "learn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afd2b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76af2650",
   "metadata": {},
   "source": [
    "## Interpreting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9564bacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_cnn(data, arch=models.resnet50, metrics=[accuracy,error_rate])\n",
    "learn.load('resnet50-stage-1')\n",
    "learn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fac28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690500be",
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67eb5943",
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.most_confused()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33cdeb3",
   "metadata": {},
   "source": [
    "## Generate Competition File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25a2c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, *_ = learn.get_preds(DatasetType.Test)\n",
    "labels = np.argmax(predictions, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a348b140",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame({'ImageId': list(range(1,len(labels)+1)), 'Label': labels})\n",
    "res_df.to_csv(f'./data/digit-recognition-submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
