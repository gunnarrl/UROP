{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e071d2a2",
   "metadata": {},
   "source": [
    "# Importing data from csv files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cd776e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset is taken from kaggle thus is divided into 3 files.\n",
    "train=pd.read_csv(r'train.csv')\n",
    "test=pd.read_csv(r'test.csv')\n",
    "gender_submission=pd.read_csv(r'gender_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544e5516",
   "metadata": {},
   "source": [
    "# Pre-Processing testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fb7fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gender_submission file consist the output of testing dataset thus mergeing that data with out output data file.\n",
    "test.insert(1, \"Survived\", gender_submission['Survived'], True) \n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a194bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac47831c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking the columns which are needed for classification and ignoring the columns like PassengerID,Name,Ticket,Fare and Cabin \n",
    "train=train[['Survived','Pclass','Sex','SibSp','Parch','Embarked']]\n",
    "test=test[['Survived','Pclass','Sex','SibSp','Parch','Embarked']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb58933",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Droping the Null value rows and performing one hot encoding\n",
    "train.dropna()\n",
    "train=pd.get_dummies(train)\n",
    "test=pd.get_dummies(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903c76f3",
   "metadata": {},
   "source": [
    "# Pre-Processed Dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b79e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88308ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f45947",
   "metadata": {},
   "source": [
    "## Making y_train and y_test from train and test DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa427a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=train['Survived']\n",
    "train.drop(['Survived'], axis=1)\n",
    "\n",
    "y_test=test['Survived']\n",
    "test.drop(['Survived'], axis=1)\n",
    "\n",
    "print(len(y_train))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f892594",
   "metadata": {},
   "source": [
    "# Accuracy Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9325ff2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred,y_test):\n",
    "    from sklearn.metrics import accuracy_score,confusion_matrix, f1_score\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    print(\"accuracy score:\",accuracy_score(y_test, y_pred))\n",
    "    print(\"confusion matrix:\\n\",confusion_matrix(y_test, y_pred))\n",
    "    print(\"f1 score:\",f1_score(y_test, y_pred, average='macro'))\n",
    "    # using heatmat to plot accuracy\n",
    "    a=np.array(y_pred).reshape(-1,1)\n",
    "    b=np.array(y_test).reshape(-1,1)\n",
    "    df=pd.DataFrame(np.append(a,b,axis=1))\n",
    "    df.columns=[\"predicted_vals\",\"true_vals\"]\n",
    "    cor = df.corr()\n",
    "    sns.heatmap(cor)\n",
    "    #to use scatter plot uncomment the below given code\n",
    "    #plt.scatter(y_test,y_pred)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d857ac",
   "metadata": {},
   "source": [
    "# 1) Using RandomForestClassifier from sklearn.ensemble to generate, fit the model and predict the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4699a9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=100, bootstrap = True, max_features = 'sqrt')\n",
    "model.fit(train,y_train)\n",
    "y_pred_randF= model.predict(test)\n",
    "y_pred_randF=y_pred_randF.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9c34c0",
   "metadata": {},
   "source": [
    "# 2) Using Naive Bayes from sklearn.ensemble to generate, fit the model and predict the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fda185f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "y_pred_naiveBayes = gnb.fit(train, y_train).predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e2fa42",
   "metadata": {},
   "source": [
    "# 3) Using Support Vector Machine from sklearn.ensemble to generate, fit the model and predict the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44528a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC()\n",
    "clf.fit(train, y_train)\n",
    "y_pred_SVM=clf.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74be453",
   "metadata": {},
   "source": [
    "# 4) Using Stochastic Gradient Descent from sklearn.ensemble to generate, fit the model and predict the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ede30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=5)\n",
    "clf.fit(train, y_train)\n",
    "SGDClassifier(max_iter=5)\n",
    "y_pred_SGD=clf.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbc6360",
   "metadata": {},
   "source": [
    "# 5) Using Stochastic Gradient Descent from sklearn.ensemble to generate, fit the model and predict the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358ed46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=2)\n",
    "neigh.fit(train,y_train)\n",
    "y_pred_KNN=neigh.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fc197d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Random Forest Accuracy\")\n",
    "accuracy(y_pred_randF,y_test)\n",
    "print(\"\\nNaive Bayes Accuracy\")\n",
    "accuracy(y_pred_naiveBayes,y_test)\n",
    "print(\"\\nSupport Vector Machine Accuracy\")\n",
    "accuracy(y_pred_SVM,y_test)\n",
    "print(\"\\nStochastic Gradient Decent Accuracy\")\n",
    "accuracy(y_pred_SGD,y_test)\n",
    "print(\"\\n KNN Accuracy\")\n",
    "accuracy(y_pred_KNN,y_test)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
