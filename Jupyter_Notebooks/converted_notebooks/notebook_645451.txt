# Imports here
%matplotlib inline
%config InlineBackend.figure_format = 'retina'

import matplotlib.pyplot as plt

import torch
from torch import nn, optim
import torch.nn.functional as F
from torchvision import datasets, transforms, models

import numpy as np
from collections import OrderedDict
from pprint import pprint
import operator
import copy
from PIL import Image
import json
import os
import random


data_dir = 'flowers'
train_dir = data_dir + '/train'
valid_dir = data_dir + '/valid'
test_dir = data_dir + '/test'

# TODO: Define your transforms for the training, validation, and testing sets
train_transforms = transforms.Compose([transforms.RandomRotation(30),
                                       transforms.RandomResizedCrop(224),
                                       transforms.RandomHorizontalFlip(),
                                       transforms.ToTensor(),
                                       transforms.Normalize([0.485, 0.456, 0.406], 
                                                            [0.229, 0.224, 0.225])])

test_transforms = transforms.Compose([transforms.Resize(256),
                                      transforms.CenterCrop(224),
                                      transforms.ToTensor(),
                                      transforms.Normalize([0.485, 0.456, 0.406], 
                                                           [0.229, 0.224, 0.225])])

validation_transforms = transforms.Compose([transforms.Resize(256),
                                            transforms.CenterCrop(224),
                                            transforms.ToTensor(),
                                            transforms.Normalize([0.485, 0.456, 0.406], 
                                                                 [0.229, 0.224, 0.225])])


# TODO: Load the datasets with ImageFolder
train_data = datasets.ImageFolder(train_dir, transform=train_transforms)
validation_data = datasets.ImageFolder(valid_dir, transform=validation_transforms)
test_data = datasets.ImageFolder(test_dir ,transform = test_transforms)

# TODO: Using the image datasets and the trainforms, define the dataloaders
trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)
vloader = torch.utils.data.DataLoader(validation_data, batch_size =64,shuffle = True)
testloader = torch.utils.data.DataLoader(test_data, batch_size = 64, shuffle = True)

import json

with open('cat_to_name.json', 'r') as f:
    cat_to_name = json.load(f)

# TODO: Build and train your network
def create_model(arch, hidden_units, output_size, dropout):
    # Download pretrained model from given architecture:
    model = arch(pretrained=True)
    # Freeze parameters so we don't backprop through them
    for param in model.parameters():
        param.requires_grad = False
    # Change the classifier to fit our needs, according to given parameters
    for i in range(4):
        if type(model.classifier[i]) == torch.nn.modules.linear.Linear:
            input_size = model.classifier[i].in_features
            break
            
    layer_sizes = [input_size] + hidden_units
    layers = [[('linear_{}'.format(i), nn.Linear(layer_sizes[i], layer_sizes[i+1])),
        ('relu_{}'.format(i), nn.ReLU()),
        ('dropout_{}'.format(i), nn.Dropout(dropout))] for i in range(len(layer_sizes)-1)]
    layers = [item for sublist in layers for item in sublist]
    layers += [('linear', nn.Linear(layer_sizes[-1], output_size)), ('logsoftmax', nn.LogSoftmax(dim=1))]

    model.classifier = nn.Sequential(OrderedDict(layers))
    return model

# Create our model
arch = models.vgg11_bn
hidden_units = [128]
output_size = len(cat_to_name)
dropout = 0.4

model = create_model(arch, hidden_units, output_size, dropout)
criterion = nn.NLLLoss()

# device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)



print("Training model")

lr = 0.0005 
optimizer = optim.Adam(model.classifier.parameters(), lr=lr)

epochs = 5
steps = 0
running_loss = 0
print_every = 1

# with active_session():    
for epoch in range(epochs):
    for inputs, labels in trainloader:
        steps += 1
        inputs, labels = inputs.to(device), labels.to(device)

        optimizer.zero_grad()

        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma = 0.95)

        logps = model.forward(inputs)
        loss = criterion(logps, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

        valid_loss = 0
        accuracy = 0
        model.eval()
        with torch.no_grad():
            for inputs, labels in vloader:
                inputs, labels = inputs.to(device), labels.to(device)
                logps = model.forward(inputs)
                batch_loss = criterion(logps, labels)

                valid_loss += batch_loss.item()

                # Calculate accuracy
                ps = torch.exp(logps)
                top_p, top_class = ps.topk(1, dim=1)
                equals = top_class == labels.view(*top_class.shape)
                accuracy += torch.mean(equals.type(torch.FloatTensor)).item()

        scheduler.step()


        if steps % print_every == 0:
            print(f"Epoch {epoch+1}/{epochs}  "
                  f"Training loss:       {running_loss/print_every:.3f}  "
                  f"Validation loss:     {valid_loss/len(vloader):.3f}  "
                  f"Validation accuracy: {accuracy/len(vloader) * 100:.2f}%")
            running_loss = 0
            model.train()

print("Training Ends")

# TODO: Do validation on the test set
test_loss = 0
accuracy = 0
model.eval()

with torch.no_grad():
    for inputs, labels in testloader:
        inputs, labels = inputs.to(device), labels.to(device)
        logps = model.forward(inputs)
        ps = torch.exp(logps)
        top_p, top_class = ps.topk(1, dim=1)
        equals = top_class == labels.view(*top_class.shape)
        accuracy += torch.mean(equals.type(torch.FloatTensor)).item()

print(f"Test accuracy: {accuracy/len(vloader) * 100}%")
    
    
    

# TODO: Save the checkpoint 
for i in range(4):
        if type(model.classifier[i]) == torch.nn.modules.linear.Linear:
            input_size = model.classifier[i].in_features
            break

checkpoint = {'input_size': input_size,
              'hidden_units': hidden_units,
              'output_size': len(cat_to_name),
              'dropout': dropout,
              'model_state_dict': model.state_dict(),
              'optimizer_state_dict': optimizer.state_dict(),
              'class_to_idx' : train_data.class_to_idx,
              'epoch': epoch,
              'arch': arch,
              'learning_rate': lr}

torch.save(checkpoint, 'checkpoint.pth')


model.class_to_idx = train_data.class_to_idx

# TODO: Write a function that loads a checkpoint and rebuilds the model
def load_model(checkpoint):
    model = create_model(checkpoint["arch"], checkpoint["hidden_units"], checkpoint["output_size"], 
                         checkpoint["dropout"])
    # for param in model.parameters():
    #    param.requires_grad = False
    
    model.load_state_dict(checkpoint['model_state_dict'])
    model.class_to_idx = checkpoint["class_to_idx"]
    
    lr = checkpoint["learning_rate"]
    op = optim.Adam(model.classifier.parameters(), lr=lr)
    op.load_state_dict(checkpoint['optimizer_state_dict'])
    
    return model, op

checkpoint = torch.load('checkpoint.pth')
ep = checkpoint['epoch']

loaded_model, loaded_optimizer = load_model(checkpoint)


def process_image(image):
    ''' Scales, crops, and normalizes a PIL image for a PyTorch model,
        returns an Numpy array
    ''' 
    # Open the image
    im = Image.open(image)
    
    # Resize the image, where the shortest side is 256 pixels, keeping aspect ratio
    size = (256, 256)
    im = im.resize(size)
   
    # Center crop 224x224
    w, h = im.size  
    crop_size = 224
    left = (w - crop_size)/2
    top = (h - crop_size)/2
    right = (w + crop_size)/2
    bottom = (h + crop_size)/2
    im = im.crop((left, top, right, bottom))
    
    # Convert to numpy array and normalize
    means = [0.485, 0.456, 0.406]
    sds = [0.229, 0.224, 0.225]
    np_image = np.array(im)
    np_image = np.true_divide(np_image, 255)
    for i in range(3):
        np_image[i,:,:] = (np_image[i,:,:] - means[i]) / sds[i]
    
    return np_image.transpose()

def imshow(image, ax=None, title=None):
    """Imshow for Tensor."""
    if ax is None:
        _, ax = plt.subplots()
    
    if title is not None:
        ax.set_title(title)
        
    ax.set_axis_off()
    
    # PyTorch tensors assume the color channel is the first dimension
    # but matplotlib assumes is the third dimension
    image = image.transpose((1, 2, 0))
    
    # Undo preprocessing
    means = np.array([0.485, 0.456, 0.406])
    sds = np.array([0.229, 0.224, 0.225])
    for i in range(3):
        image[i,:,:] = ((image[i,:,:] - means[i]) / sds[i])
    
    # Image needs to be clipped between 0 and 1 or it looks like noise when displayed
    image = np.clip(image, 0, 1)
    
    ax.imshow(image)
    
    return ax


# Test it 
im_path = os.path.join(train_dir, "1", "image_06745.jpg")
proc_im = process_image(im_path)
imshow(proc_im)

def predict(image_path, model, topk=5):
    ''' Predict the class (or classes) of an image using a trained deep learning model.
    '''
    model.to(device);
    image = process_image(image_path)
    model.eval()
    with torch.no_grad():
        image_t = torch.from_numpy(image)
        #print(image.shape)
        image_t = image_t.unsqueeze_(0)
        image_t = image_t.float()
        
        image_t = image_t.to(device)
        logps = model.forward(image_t)
        
        #calculating 
        ps = torch.exp(logps)
        top_p, top_class = ps.topk(5)
        top_p = top_p.cpu().numpy().tolist()[0]
        top_class = top_class.cpu().numpy().tolist()[0]
        #print(top_p, top_class)
                       
        #Converting class number to Flower anme using dict  cat_to_name       
        list_str = [cat_to_name.get(str(x)) for x in top_class]
        
        fig,(ax1,ax2) = plt.subplots(2, 1, sharex = False, sharey = False,figsize= (4,8))
        
        #sending plt and getting plt in return
        ax1 = imshow(image,ax1)
        #printing top Class Name
        ax1.set_title(list_str[0])
        #setting axis without ticks
        #https://stackoverflow.com/questions/37039685/hide-axis-values-in-matplotlib/37045694
        ax1.set_yticklabels([])
        ax1.set_xticklabels([])
        
        print(list_str)
        
             
        
        #plotting 5 classes and probabilties
        ax2.barh(list_str,top_p)

# TODO: Display an image along with the top 5 classes
predict(data_dir + '/test/1/image_06764.jpg', model)
