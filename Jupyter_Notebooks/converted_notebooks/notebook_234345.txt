import azureml.core
import pandas as pd
import numpy as np
import os
import logging
import warnings
# Squash warning messages for cleaner output in the notebook
warnings.showwarning = lambda *args, **kwargs: None


from azureml.core.workspace import Workspace
from azureml.core.experiment import Experiment
from azureml.train.automl import AutoMLConfig
from azureml.train.automl.run import AutoMLRun
from sklearn.metrics import mean_absolute_error, mean_squared_error

ws = Workspace.from_config()

# choose a name for the run history container in the workspace
experiment_name = 'automl-ojsalesforecasting'
# project folder
project_folder = './sample_projects/automl-local-ojsalesforecasting'

experiment = Experiment(ws, experiment_name)

output = {}
output['SDK version'] = azureml.core.VERSION
output['Subscription ID'] = ws.subscription_id
output['Workspace'] = ws.name
output['Resource Group'] = ws.resource_group
output['Location'] = ws.location
output['Project Directory'] = project_folder
output['Run History Name'] = experiment_name
pd.set_option('display.max_colwidth', -1)
pd.DataFrame(data=output, index=['']).T

time_column_name = 'WeekStarting'
data = pd.read_csv("dominicks_OJ.csv", parse_dates=[time_column_name])
data.head()

grain_column_names = ['Store', 'Brand']
nseries = data.groupby(grain_column_names).ngroups
print('Data contains {0} individual time-series.'.format(nseries))

ntest_periods = 20

def split_last_n_by_grain(df, n):
    """
    Group df by grain and split on last n rows for each group
    """
    df_grouped = (df.sort_values(time_column_name) # Sort by ascending time
                  .groupby(grain_column_names, group_keys=False))
    df_head = df_grouped.apply(lambda dfg: dfg.iloc[:-n])
    df_tail = df_grouped.apply(lambda dfg: dfg.iloc[-n:])
    return df_head, df_tail

X_train, X_test = split_last_n_by_grain(data, ntest_periods)

nvalidation_periods = 20
X_train, X_validate = split_last_n_by_grain(X_train, nvalidation_periods)

target_column_name = 'Quantity'
y_train = X_train.pop(target_column_name).values
y_validate = X_validate.pop(target_column_name).values 

automl_settings = {
    'time_column_name': time_column_name,
    'grain_column_names': grain_column_names,
    'drop_column_names': ['logQuantity']
}

automl_config = AutoMLConfig(task='forecasting',
                             debug_log='automl_oj_sales_errors.log',
                             primary_metric='normalized_root_mean_squared_error',
                             iterations=10,
                             X=X_train,
                             y=y_train,
                             X_valid=X_validate,
                             y_valid=y_validate,
                             enable_ensembling=False,
                             path=project_folder,
                             verbosity=logging.INFO,
                            **automl_settings)

local_run = experiment.submit(automl_config, show_output=True)

best_run, fitted_pipeline = local_run.get_output()
fitted_pipeline.steps

y_test = X_test.pop(target_column_name).values

X_test.head()

y_pred = fitted_pipeline.predict(X_test)

def MAPE(actual, pred):
    """
    Calculate mean absolute percentage error.
    Remove NA and values where actual is close to zero
    """
    not_na = ~(np.isnan(actual) | np.isnan(pred))
    not_zero = ~np.isclose(actual, 0.0)
    actual_safe = actual[not_na & not_zero]
    pred_safe = pred[not_na & not_zero]
    APE = 100*np.abs((actual_safe - pred_safe)/actual_safe)
    return np.mean(APE)

print("[Test Data] \nRoot Mean squared error: %.2f" % np.sqrt(mean_squared_error(y_test, y_pred)))
print('mean_absolute_error score: %.2f' % mean_absolute_error(y_test, y_pred))
print('MAPE: %.2f' % MAPE(y_test, y_pred))
